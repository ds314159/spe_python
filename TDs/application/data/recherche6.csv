titre	auteur	co_auteurs	date	texte	url	catégorie	source	id_post_reddit	subreddit	upvotes	score	nombre_commentaires	flairs
Towards Memory Safe Python Enclave for Security Sensitive Computation	Huibo Wang	Mingshen Sun, Qian Feng, Pei Wang, Tongxin Li, Yu Ding	2020-05-12 18:19:08	Intel SGX Guard eXtensions (SGX), a hardware-supported trusted execution environment (TEE), is designed to protect security-sensitive applications. However, since enclave applications are developed with memory unsafe languages such as C/C++, traditional memory corruption is not eliminated in SGX. Rust-SGX is the first toolkit providing enclave developers with a memory-language. However, Rust is considered a Systems language and has become the right choice for concurrent applications and web browsers. Many application domains such as Big Data, Machine Learning, Robotics, Computer Vision are more commonly developed in the python programming language. Therefore, Python application developers cannot benefit from secure enclaves like Intel SGX and rust-SGX. To fill this gap, we propose Python-SGX, which is a memory-safe SGX SDK providing enclave developers a memory-safe Python development environment. The key idea is to enable memory-safe Python language in SGX by solving the following key challenges: (1) defining a memory-safe Python interpreter (2)replacing unsafe elements of Python interpreter with safe ones,(3) achieving comparable performance to non-enclave Python applications, and (4) not introducing any unsafe new code or libraries into SGX. We propose to build Python-SGX with PyPy, a Python interpreter written by RPython, which is a subset of Python, and tame unsafe parts in PyPy by formal verification, security hardening, and memory safe language. We have implemented python-SGX and tested it with a series of benchmarks programs. Our evaluation results show that Python-SGX does not cause significant overhead.	http://arxiv.org/abs/2005.05996v1	cs	arxiv					0.0	
Want Drugs? Use Python	Michał Nowotka	George Papadatos, Mark Davies, Nathan Dedman, Anne Hersey	2016-07-01 19:02:36	We describe how Python can be leveraged to streamline the curation, modelling and dissemination of drug discovery data as well as the development of innovative, freely available tools for the related scientific community. We look at various examples, such as chemistry toolkits, machine-learning applications and web frameworks and show how Python can glue it all together to create efficient data science pipelines.	http://arxiv.org/abs/1607.00378v1	cs	arxiv					0.0	
How fast can we make interpreted Python?	Russell Power	Alex Rubinsteyn	2013-06-25 17:57:00	Python is a popular dynamic language with a large part of its appeal coming from powerful libraries and extension modules. These augment the language and make it a productive environment for a wide variety of tasks, ranging from web development (Django) to numerical analysis (NumPy). Unfortunately, Python's performance is quite poor when compared to modern implementations of languages such as Lua and JavaScript.   Why does Python lag so far behind these other languages? As we show, the very same API and extension libraries that make Python a powerful language also make it very difficult to efficiently execute. Given that we want to retain access to the great extension libraries that already exist for Python, how fast can we make it?   To evaluate this, we designed and implemented Falcon, a high-performance bytecode interpreter fully compatible with the standard CPython interpreter. Falcon applies a number of well known optimizations and introduces several new techniques to speed up execution of Python bytecode. In our evaluation, we found Falcon an average of 25% faster than the standard Python interpreter on most benchmarks and in some cases about 2.5X faster.	http://arxiv.org/abs/1306.6047v2	cs	arxiv					0.0	
"An Analysis of Python's Topics, Trends, and Technologies Through Mining
  Stack Overflow Discussions"	Hamed Tahmooresi	Abbas Heydarnoori, Alireza Aghamohammadi	2020-04-14 02:59:16	Python is a popular, widely used, and general-purpose programming language. In spite of its ever-growing community, researchers have not performed much analysis on Python's topics, trends, and technologies which provides insights for developers about Python community trends and main issues. In this article, we examine the main topics related to this language being discussed by developers on one of the most popular Q\&A websites, Stack Overflow, as well as temporal trends through mining 2461876 posts. To be more useful for the software engineers, we study what Python provides as the alternative to popular technologies offered by common programming languages like Java. Our results indicate that discussions about Python standard features, web programming, and scientific programming. Programming in areas such as mathematics, data science, statistics, machine learning, natural language processing (NLP), and so forth. are the most popular areas in the Python community. At the same time, areas related to scientific programming are steadily receiving more attention from the Python developers.	http://arxiv.org/abs/2004.06280v1	cs	arxiv					0.0	
Design and Implementation of a Simple Web Search Engine	Andri Mirzal	Aucun	2011-12-13 06:46:26	We present a simple web search engine for indexing and searching html documents using python programming language. Because python is well known for its simple syntax and strong support for main operating systems, we hope it will be beneficial for learning information retrieval techniques, especially web search engine technology.	http://arxiv.org/abs/1112.2807v2	cs	arxiv					0.0	
FastWARC: Optimizing Large-Scale Web Archive Analytics	Janek Bevendorff	Martin Potthast, Benno Stein	2021-11-22 10:35:02	Web search and other large-scale web data analytics rely on processing archives of web pages stored in a standardized and efficient format. Since its introduction in 2008, the IIPC's Web ARCive (WARC) format has become the standard format for this purpose. As a list of individually compressed records of HTTP requests and responses, it allows for constant-time random access to all kinds of web data via off-the-shelf open source parsers in many programming languages, such as WARCIO, the de-facto standard for Python. When processing web archives at the terabyte or petabyte scale, however, even small inefficiencies in these tools add up quickly, resulting in hours, days, or even weeks of wasted compute time. Reviewing the basic components of WARCIO and analyzing its bottlenecks, we proceed to build FastWARC, a new high-performance WARC processing library for Python, written in C++/Cython, which yields performance improvements by factors of 1.6-8x.	http://arxiv.org/abs/2112.03103v1	cs	arxiv					0.0	
"iMedBot: A Web-based Intelligent Agent for Healthcare Related Prediction
  and Deep Learning"	Chuhan Xu	Xia Jiang	2022-10-07 19:27:05	Background: Breast cancer is a multifactorial disease, genetic and environmental factors will affect its incidence probability. Breast cancer metastasis is one of the main cause of breast cancer related deaths reported by the American Cancer Society (ACS). Method: the iMedBot is a web application that we developed using the python Flask web framework and deployed on Amazon Web Services. It contains a frontend and a backend. The backend is supported by a python program we developed using the python Keras and scikit-learn packages, which can be used to learn deep feedforward neural network (DFNN) models. Result: the iMedBot can provide two main services: 1. it can predict 5-, 10-, or 15-year breast cancer metastasis based on a set of clinical information provided by a user. The prediction is done by using a set of DFNN models that were pretrained, and 2. It can train DFNN models for a user using user-provided dataset. The model trained will be evaluated using AUC and both the AUC value and the AUC ROC curve will be provided. Conclusion: The iMedBot web application provides a user-friendly interface for user-agent interaction in conducting personalized prediction and model training. It is an initial attempt to convert results of deep learning research into an online tool that may stir further research interests in this direction. Keywords: Deep learning, Breast Cancer, Web application, Model training.	http://arxiv.org/abs/2210.05671v1	cs	arxiv					0.0	
psrqpy: a python interface for querying the ATNF pulsar catalogue	Matthew Pitkin	Aucun	2018-06-05 11:48:48	This Python module provides an interface for querying the Australia Telescope National Facility (ATNF) pulsar catalogue (Manchester et al. 2005). The intended users are astronomers wanting to extract data from the catalogue through a script rather than having to download and parse text tables output using the standard web interface. It allows users to access information, such as pulsar frequencies and sky locations, on all pulsars in the catalogue. Querying of the catalogue can easily be incorporated into Python scripts.	http://dx.doi.org/10.21105/joss.00538	cs	arxiv					0.0	
Using Python to Dive into Signalling Data with CellNOpt and BioServices	Thomas Cokelaer	Julio Saez-Rodriguez	2014-12-19 15:43:09	Systems biology is an inter-disciplinary field that studies systems of biological components at different scales, which may be molecules, cells or entire organism. In particular, systems biology methods are applied to understand functional deregulations within human cells (e.g., cancers). In this context, we present several python packages linked to CellNOptR (R package), which is used to build predictive logic models of signalling networks by training networks (derived from literature) to signalling (phospho-proteomic) data. The first package (cellnopt.wrapper) is a wrapper based on RPY2 that allows a full access to CellNOptR functionalities within Python. The second one (cellnopt.core) was designed to ease the manipulation and visualisation of data structures used in CellNOptR, which was achieved by using Pandas, NetworkX and matplotlib. Systems biology also makes extensive use of web resources and services. We will give an overview and status of BioServices, which allows one to access programmatically to web resources used in life science and how it can be combined with CellNOptR.	http://arxiv.org/abs/1412.6386v1	cs	arxiv					0.0	
Network visualizations with Pyvis and VisJS	Giancarlo Perrone	Jose Unpingco, Haw-minn Lu	2020-06-02 17:32:32	Pyvis is a Python module that enables visualizing and interactively manipulating network graphs in the Jupyter notebook, or as a standalone web application. Pyvis is built on top of the powerful and mature VisJS JavaScript library, which allows for fast and responsive interactions while also abstracting away the low-level JavaScript and HTML. This means that elements of the rendered graph visualization, such as node/edge attributes can be specified within Python and shipped to the JavaScript layer for VisJS to render. This declarative approach makes it easy to quickly explore graph visualizations and investigate data relationships. In addition, Pyvis is highly customizable so that colors, sizes, and hover tooltips can be assigned to the rendered graph. The network graph layout is controlled by a front-end physics engine that is configurable from a Python interface, allowing for the detailed placement of the graph elements. In this paper, we outline use cases for Pyvis with specific examples to highlight key features for any analysis workflow. A brief overview of Pyvis' implementation describes how the Python front-end binding uses simple Pyvis calls.	http://arxiv.org/abs/2006.04951v1	cs	arxiv					0.0	
BlackWatch: Increasing Attack Awareness Within Web Applications	Calum C. Hall	Lynsay A. Shepherd, Natalie Coull	2019-01-14 11:33:53	Web applications are relied upon by many for the services they provide. It is essential that applications implement appropriate security measures to prevent security incidents. Currently, web applications focus resources towards the preventative side of security. Whilst prevention is an essential part of the security process, developers must also implement a level of attack awareness into their web applications. Being able to detect when an attack is occurring provides applications with the ability to execute responses against malicious users in an attempt to slow down or deter their attacks. This research seeks to improve web application security by identifying malicious behaviour from within the context of web applications using our tool BlackWatch. The tool is a Python-based application which analyses suspicious events occurring within client web applications, with the objective of identifying malicious patterns of behaviour. Based on the results from a preliminary study, BlackWatch was effective at detecting attacks from both authenticated, and unauthenticated users. Furthermore, user tests with developers indicated BlackWatch was user friendly, and was easy to integrate into existing applications. Future work seeks to develop the BlackWatch solution further for public release.	http://dx.doi.org/10.3390/fi11020044	cs	arxiv					0.0	
"Do Fewer Tiers Mean Fewer Tears? Eliminating Web Stack Components to
  Improve Interoperability"	Adrian Ramsingh	Jeremy Singer, Phil Trinder	2022-07-16 21:15:21	Web applications are structured as multi-tier stacks of components. Each component may be written in a different language and interoperate using a variety of protocols. Such interoperation increases developer effort, can introduce security vulnerabilities, may reduce performance and require additional resources. A range of approaches have been explored to minimise web stack interoperation.   This paper explores a pragmatic approach to reducing web stack interoperation, namely eliminating a tier/component. That is, we explore the implications of eliminating the Apache web server in a JAPyL web stack: Jupyter Notebook, Apache, Python, Linux, and replacing it with PHP libraries. We conduct a systematic study to investigate the implications for web stack performance, resource consumption, security, and programming effort.	http://arxiv.org/abs/2207.08019v1	cs	arxiv					0.0	
PyXNAT: XNAT in Python	Yannick Schwartz	Alexis Barbot, Benjamin Thyreau, Vincent Frouin, Gaël Varoquaux, Aditya Siram, Daniel Marcus, Jean-Baptiste Poline	2013-01-29 15:42:18	As neuroimaging databases grow in size and complexity, the time researchers spend investigating and managing the data increases to the expense of data analysis. As a result, investigators rely more and more heavily on scripting using high-level languages to automate data management and processing tasks. For this, a structured and programmatic access to the data store is necessary. Web services are a first step toward this goal. They however lack in functionality and ease of use because they provide only low level interfaces to databases. We introduce here PyXNAT, a Python module that interacts with The Extensible Neuroimaging Archive Toolkit (XNAT) through native Python calls across multiple operating systems. The choice of Python enables PyXNAT to expose the XNAT Web Services and unify their features with a higher level and more expressive language. PyXNAT provides XNAT users direct access to all the scientific packages in Python. Finally PyXNAT aims to be efficient and easy to use, both as a backend library to build XNAT clients and as an alternative frontend from the command line.	http://dx.doi.org/10.3389/fninf.2012.00012	cs	arxiv					0.0	
AMP: A Science-driven Web-based Application for the TeraGrid	Matthew Woitaszek	Travis Metcalfe, Ian Shorrock	2010-11-29 19:09:28	The Asteroseismic Modeling Portal (AMP) provides a web-based interface for astronomers to run and view simulations that derive the properties of Sun-like stars from observations of their pulsation frequencies. In this paper, we describe the architecture and implementation of AMP, highlighting the lightweight design principles and tools used to produce a functional fully-custom web-based science application in less than a year. Targeted as a TeraGrid science gateway, AMP's architecture and implementation are intended to simplify its orchestration of TeraGrid computational resources. AMP's web-based interface was developed as a traditional standalone database-backed web application using the Python-based Django web development framework, allowing us to leverage the Django framework's capabilities while cleanly separating the user interface development from the grid interface development. We have found this combination of tools flexible and effective for rapid gateway development and deployment.	http://dx.doi.org/10.1145/1658260.1658262	cs	arxiv					0.0	
"OBA: An Ontology-Based Framework for Creating REST APIs for Knowledge
  Graphs"	Daniel Garijo	Maximiliano Osorio	2020-07-17 19:46:18	In recent years, Semantic Web technologies have been increasingly adopted by researchers, industry and public institutions to describe and link data on the Web, create web annotations and consume large knowledge graphs like Wikidata and DBPedia. However, there is still a knowledge gap between ontology engineers, who design, populate and create knowledge graphs; and web developers, who need to understand, access and query these knowledge graphs but are not familiar with ontologies, RDF or SPARQL. In this paper we describe the Ontology-Based APIs framework (OBA), our approach to automatically create REST APIs from ontologies while following RESTful API best practices. Given an ontology (or ontology network) OBA uses standard technologies familiar to web developers (OpenAPI Specification, JSON) and combines them with W3C standards (OWL, JSON-LD frames and SPARQL) to create maintainable APIs with documentation, units tests, automated validation of resources and clients (in Python, Javascript, etc.) for non Semantic Web experts to access the contents of a target knowledge graph. We showcase OBA with three examples that illustrate the capabilities of the framework for different ontologies.	http://arxiv.org/abs/2007.09206v1	cs	arxiv					0.0	
"An Empirical Analysis of Vulnerabilities in Python Packages for Web
  Applications"	Jukka Ruohonen	Aucun	2018-10-31 14:41:12	This paper examines software vulnerabilities in common Python packages used particularly for web development. The empirical dataset is based on the PyPI package repository and the so-called Safety DB used to track vulnerabilities in selected packages within the repository. The methodological approach builds on a release-based time series analysis of the conditional probabilities for the releases of the packages to be vulnerable. According to the results, many of the Python vulnerabilities observed seem to be only modestly severe; input validation and cross-site scripting have been the most typical vulnerabilities. In terms of the time series analysis based on the release histories, only the recent past is observed to be relevant for statistical predictions; the classical Markov property holds.	http://dx.doi.org/10.1109/IWESEP.2018.00013	cs	arxiv					0.0	
DeepOnto: A Python Package for Ontology Engineering with Deep Learning	Yuan He	Jiaoyan Chen, Hang Dong, Ian Horrocks, Carlo Allocca, Taehun Kim, Brahmananda Sapkota	2023-07-06 15:35:02	"Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more ""Pythonic"" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning methodologies, primarily pre-trained LMs. In this paper, we also demonstrate the practical utility of Deeponto through two use-cases: the Digital Health Coaching in Samsung Research UK and the Bio-ML track of the Ontology Alignment Evaluation Initiative (OAEI)."	http://arxiv.org/abs/2307.03067v1	cs	arxiv					0.0	
"ELATE: An open-source online application for analysis and visualization
  of elastic tensors"	Romain Gaillac	Pluton Pullumbi, François-Xavier Coudert	2016-02-19 15:09:29	We report on the implementation of a tool for the analysis of second-order elastic stiffness tensors, provided with both an open-source Python module and a standalone online application providing visualization tools of anisotropic mechanical properties. After describing the software features, how we compute the conventional elastic constants and how we represent them graphically, we explain our technical choices for the implementation. In particular, we focus on why a Python module is used to generate the HTML web page with embedded Javascript for dynamical plots.	http://dx.doi.org/10.1088/0953-8984/28/27/275201	cs	arxiv					0.0	
API Blender: A Uniform Interface to Social Platform APIs	Georges Gouriten	Pierre Senellart	2013-01-10 11:19:25	With the growing success of the social Web, most Web developers have to interact with at least one social Web platform, which implies studying the related API specifications. These are often only informally described, may contain errors, lack harmonization, and generally speaking make the developer's work difficult. Most attempts to solve this problem, proposing formal description languages for Web service APIs, have had limited success outside of B2B applications; we believe it is due to their top-down nature. In addition, a programmer dealing with one or several of these APIs has to deal with a number of related tasks such as data integration, requests chaining, or policy management, that are cumbersome to implement. Inspired by the SPORE project, we present API Blender, an open-source solution to describe, interact with, and integrate the most common social Web APIs. In this perspective, we first introduce two new lightweight description formats for requests and services and demonstrate their relevance with respect to current platform APIs. We present our Python implementation of API Blender and its features regarding authentication, policy management and multi-platform data integration.	http://arxiv.org/abs/1301.2086v1	cs	arxiv					0.0	
"Nifty Web Apps: Build a Web App for Any Text-Based Programming
  Assignment"	Kevin Lin	Sumant Guha, Joe Spaniac, Andy Zheng	2020-10-09 16:43:47	While many students now interact with web apps across a variety of smart devices, the vast majority of our Nifty Assignments still present traditional user interfaces such as console input/output and desktop GUI. In this tutorial session, participants will learn to build simple web apps for programming assignments that execute student-written code to dynamically respond to user interactions resulting in a more modern app experience. Our approach requires up to 75% less code than similar desktop GUI apps while requiring few (if any) modifications to existing assignments. Instructors and students alike can run and modify these web apps on their own computers or deploy their apps online for access from any smart device at no cost. The tutorial presents examples from CS1 and CS2 courses in Python and Java, but the ideas apply generally.	http://dx.doi.org/10.1145/3408877.3432580	cs	arxiv					0.0	
"Web-Based Implementation of Travelling Salesperson Problem Using Genetic
  Algorithm"	Aryo Pinandito	Novanto Yudistira, Fajar Pradana	2018-02-09 07:30:38	The world is connected through the Internet. As the abundance of Internet users connected into the Web and the popularity of cloud computing research, the need of Artificial Intelligence (AI) is demanding. In this research, Genetic Algorithm (GA) as AI optimization method through natural selection and genetic evolution is utilized. There are many applications of GA such as web mining, load balancing, routing, and scheduling or web service selection. Hence, it is a challenging task to discover whether the code mainly server side and web based language technology affects the performance of GA. Travelling Salesperson Problem (TSP) as Non Polynomial-hard (NP-hard) problem is provided to be a problem domain to be solved by GA. While many scientists prefer Python in GA implementation, another popular high-level interpreter programming language such as PHP (PHP Hypertext Preprocessor) and Ruby were benchmarked. Line of codes, file sizes, and performances based on GA implementation and runtime were found varies among these programming languages. Based on the result, the use of Ruby in GA implementation is recommended.	http://arxiv.org/abs/1802.03155v1	cs	arxiv					0.0	
"Benchmarking Web-testing - Selenium versus Watir and the Choice of
  Programming Language and Browser"	Miikka Kuutila	Mika Mäntylä, Päivi Raulamo-Jurvanen	2016-11-02 13:00:08	Context: Selenium is claimed to be the most popular software test automation tool. Past academic works have mainly neglected testing tools in favor of more methodological topics. Objective: We investigated the performance of web-testing tools, to provide empirical evidence supporting choices in software test tool selection and configuration. Method: We used 4*5 factorial design to study 20 different configurations for testing a web-store. We studied 5 programming language bindings (C#, Java, Python, and Ruby for Selenium, while Watir supports Ruby only) and 4 browsers (Google Chrome, Internet Explorer, Mozilla Firefox and Opera). Performance was measured with execution time, memory usage, length of the test scripts and stability of the tests. Results: Considering all measures the best configuration was Selenium with Python language binding for Chrome. Selenium with Python bindings was the best option for all browsers. The effect size of the difference between the slowest and fastest configuration was very high (Cohens d=41.5, 91% increase in execution time). Overall Internet Explorer was the fastest browser while having the worst results in the stability. Conclusions: We recommend benchmarking tools before adopting them. Weighting of factors, e.g. how much test stability is one willing to sacrifice for faster performance, affects the decision.	http://arxiv.org/abs/1611.00578v1	cs	arxiv					0.0	
"MeSH Suggester: A Library and System for MeSH Term Suggestion for
  Systematic Review Boolean Query Construction"	Shuai Wang	Hang Li, Guido Zuccon	2022-12-18 05:32:19	Boolean query construction is often critical for medical systematic review literature search. To create an effective Boolean query, systematic review researchers typically spend weeks coming up with effective query terms and combinations. One challenge to creating an effective systematic review Boolean query is the selection of effective MeSH Terms to include in the query. In our previous work, we created neural MeSH term suggestion methods and compared them to state-of-the-art MeSH term suggestion methods. We found neural MeSH term suggestion methods to be highly effective.   In this demonstration, we build upon our previous work by creating (1) a Web-based MeSH term suggestion prototype system that allows users to obtain suggestions from a number of underlying methods and (2) a Python library that implements ours and others' MeSH term suggestion methods and that is aimed at researchers who want to further investigate, create or deploy such type of methods. We describe the architecture of the web-based system and how to use it for the MeSH term suggestion task. For the Python library, we describe how the library can be used for advancing further research and experimentation, and we validate the results of the methods contained in the library on standard datasets. Our web-based prototype system is available at http://ielab-mesh-suggest.uqcloud.net, while our Python library is at https://github.com/ielab/meshsuggestlib.	http://dx.doi.org/10.1145/3503516.3503530	cs	arxiv					0.0	
Creating RESTful APIs over SPARQL endpoints using RAMOSE	Marilena Daquino	Ivan Heibi, Silvio Peroni, David Shotton	2020-07-31 13:53:29	Semantic Web technologies are widely used for storing RDF data and making them available on the Web through SPARQL endpoints, queryable using the SPARQL query language. While the use of SPARQL endpoints is strongly supported by Semantic Web experts, it hinders broader use of RDF data by common Web users, engineers and developers unfamiliar with Semantic Web technologies, who normally rely on Web RESTful APIs for querying Web-available data and creating applications over them. To solve this problem, we have developed RAMOSE, a generic tool developed in Python to create REST APIs over SPARQL endpoints. Through the creation of source-specific textual configuration files, RAMOSE enables the querying of SPARQL endpoints via simple Web RESTful API calls that return either JSON or CSV-formatted data, thus hiding all the intrinsic complexities of SPARQL and RDF from common Web users. We provide evidence that the use of RAMOSE to provide REST API access to RDF data within OpenCitations triplestores is beneficial in terms of the number of queries made by external users to such RDF data using the RAMOSE API compared with the direct access via the SPARQL endpoint. Our findings show the importance for suppliers of RDF data of having an alternative API access service, which enables its use by those with no (or little) experience in Semantic Web technologies and the SPARQL query language. RAMOSE can be used both to query any SPARQL endpoint and to query any other Web API, and thus it represents an easy generic technical solution for service providers who wish to create an API service to access Linked Data stored as RDF in a conventional triplestore.	http://arxiv.org/abs/2007.16079v4	cs	arxiv					0.0	
Plat_Forms -- a contest: The web development platform comparison	Lutz Prechelt	Aucun	2008-05-06 06:53:01	"""Plat_Forms"" is a competition in which top-class teams of three programmers compete to implement the same requirements for a web-based system within 30 hours, each team using a different technology platform (Java EE, .NET, PHP, Perl, Python, or Ruby on Rails). The results will provide new insights into the real (rather than purported) pros, cons, and emergent properties of each platform. The evaluation will analyze many aspects of each solution, both external (usability, functionality, reliability, performance, etc.) and internal (structure, understandability, flexibility, etc.)."	http://arxiv.org/abs/0805.0650v1	cs	arxiv					0.0	
"Student's opinions about System for automatic assessment of programming
  tasks Projekt Tomo"	Gregor Jerše	Matija Lokar	2017-02-17 07:12:02	In a previous paper a web service called Projekt Tomo intended to ease the process of learning programming for teachers and students has been described. Since the service received a very warm welcome from teachers and students alike we decided to collect additional information on the students' view of the service in order to improve it even further.   In the paper we briefly present our web service and a detailed analysis of the questionnaire handed out to the students of the highschool level programming course in Python.	http://arxiv.org/abs/1702.05240v1	cs	arxiv					0.0	
Web interface for reflectivity fitting	Mathieu Doucet	Ricardo Miguel Ferraz Leal, Tanner C. Hobson	2017-10-13 14:50:42	The Liquids Reflectometer at Oak Ridge National Laboratory provides neutron reflectivity capability for an average of about 30 experiments each year. In recent years, there has been a large effort to streamline the data processing and analysis for the instrument. While much of the data reduction can be automated, data analysis remains something that needs to be done by scientists. For this purpose, we present a reflectivity fitting web interface that captures the process of setting up and executing fits while reducing the need for installing software or writing Python scripts.	http://arxiv.org/abs/1710.06767v1	cs	arxiv					0.0	
"FitsMap: A Simple, Lightweight Tool For Displaying Interactive
  Astronomical Image and Catalog Data"	Ryan Hausen	Brant Robertson	2022-01-28 18:18:32	The visual inspection of image and catalog data continues to be a valuable aspect of astronomical data analysis. As the scale of astronomical image and catalog data continues to grow, visualizing the data becomes increasingly difficult. In this work, we introduce FitsMap, a simple, lightweight tool for visualizing astronomical image and catalog data. FitsMap only requires a simple web server and can scale to over gigapixel images with tens of millions of sources. Further, the web-based visualizations can be viewed performantly on mobile devices. FitsMap is implemented in Python and is open source (https://github.com/ryanhausen/fitsmap).	http://arxiv.org/abs/2201.12308v1	cs	arxiv					0.0	
Static Analysis for AWS Best Practices in Python Code	Rajdeep Mukherjee	Omer Tripp, Ben Liblit, Michael Wilson	2022-05-09 17:26:10	"Amazon Web Services (AWS) is a comprehensive and broadly adopted cloud provider, offering over 200 fully featured services, including compute, database, storage, networking and content delivery, machine learning, Internet of Things and many others. AWS SDKs provide access to AWS services through API endpoints. However, incorrect use of these APIs can lead to code defects, crashes, performance issues, and other problems.   This paper presents automated static analysis rules, developed in the context of a commercial service for detection of code defects and security vulnerabilities, to identify deviations from AWS best practices in Python applications that use the AWS SDK. Such applications use the AWS SDK for Python, called ""Boto3"", to access AWS cloud services. However, precise static analysis of Python applications that use cloud SDKs requires robust type inference for inferring the types of cloud service clients. The dynamic style of Boto3 APIs poses unique challenges for type resolution, as does the interprocedural style in which service clients are used in practice. In support of our best-practices goal, we present a layered strategy for type inference that combines multiple type-resolution and tracking strategies in a staged manner. From our experiments across >3,000 popular Python GitHub repos that make use of the AWS SDK, our layered type inference system achieves 85% precision and 100% recall in inferring Boto3 clients in Python client code.   Additionally, we present a representative sample of eight AWS best-practice rules that detect a wide range of issues including pagination, polling, and batch operations. We have assessed the efficacy of these rules based on real-world developer feedback. Developers have accepted more than 85% of the recommendations made by five out of eight Python rules, and almost 83% of all recommendations."	http://arxiv.org/abs/2205.04432v1	cs	arxiv					0.0	
Gradual Soundness: Lessons from Static Python	Kuang-Chen Lu	Ben Greenman, Carl Meyer, Dino Viehland, Aniket Panse, Shriram Krishnamurthi	2022-06-28 08:53:44	Context: Gradually-typed languages allow typed and untyped code to interoperate, but typically come with significant drawbacks. In some languages, the types are unreliable; in others, communication across type boundaries can be extremely expensive; and still others allow only limited forms of interoperability. The research community is actively seeking a sound, fast, and expressive approach to gradual typing.   Inquiry: This paper describes Static Python, a language developed by engineers at Instagram that has proven itself sound, fast, and reasonably expressive in production. Static Python's approach to gradual types is essentially a programmer-tunable combination of the concrete and transient approaches from the literature. Concrete types provide full soundness and low performance overhead, but impose nonlocal constraints. Transient types are sound in a shallow sense and easier to use; they help to bridge the gap between untyped code and typed concrete code.   Approach: We evaluate the language in its current state and develop a model that captures the essence of its approach to gradual types. We draw upon personal communication, bug reports, and the Static Python regression test suite to develop this model.   Knowledge: Our main finding is that the gradual soundness that arises from a mix of concrete and transient types is an effective way to lower the maintenance cost of the concrete approach. We also find that method-based JIT technology can eliminate the costs of the transient approach. On a more technical level, this paper describes two contributions: a model of Static Python and a performance evaluation of Static Python. The process of formalization found several errors in the implementation, including fatal errors.   Grounding: Our model of Static Python is implemented in PLT Redex and tested using property-based soundness tests and 265 tests from the Static Python regression suite. This paper includes a small core of the model to convey the main ideas of the Static Python approach and its soundness. Our performance claims are based on production experience in the Instagram web server. Migrations to Static Python in the server have caused a 3.7\% increase in requests handled per second at maximum CPU load.   Importance: Static Python is the first sound gradual language whose piece-meal application to a realistic codebase has consistently improved performance. Other language designers may wish to replicate its approach, especially those who currently maintain unsound gradual languages and are seeking a path to soundness.	http://dx.doi.org/10.22152/programming-journal.org/2023/7/2	cs	arxiv					0.0	
Sourcerer's Apprentice and the study of code snippet migration	Stephen Romansky	Cheng Chen, Baljeet Malhotra, Abram Hindle	2018-07-31 23:12:45	On the worldwide web, not only are webpages connected but source code is too. Software development is becoming more accessible to everyone and the licensing for software remains complicated. We need to know if software licenses are being maintained properly throughout their reuse and evolution. This motivated the development of the Sourcerer's Apprentice, a webservice that helps track clone relicensing, because software typically employ software licenses to describe how their software may be used and adapted. But most developers do not have the legal expertise to sort out license conflicts. In this paper we put the Apprentice to work on empirical studies that demonstrate there is much sharing between StackOverflow code and Python modules and Python documentation that violates the licensing of the original Python modules and documentation: software snippets shared through StackOverflow are often being relicensed improperly to CC-BY-SA 3.0 without maintaining the appropriate attribution. We show that many snippets on StackOverflow are inappropriately relicensed by StackOverflow users, jeopardizing the status of the software built by companies and developers who reuse StackOverflow snippets.	http://arxiv.org/abs/1808.00106v1	cs	arxiv					0.0	
"Solar-MACH: An open-source tool to analyze solar magnetic connection
  configurations"	Jan Gieseler	Nina Dresing, Christian Palmroos, Johan L. Freiherr von Forstner, Daniel J. Price, Rami Vainio, Athanasios Kouloumvakos, Laura Rodríguez-García, Domenico Trotta, Vincent Génot, Arnaud Masson, Markus Roth, Astrid Veronig	2022-10-03 11:04:24	The Solar MAgnetic Connection HAUS tool (Solar-MACH) is an open-source tool completely written in Python that derives and visualizes the spatial configuration and solar magnetic connection of different observers (i.e., spacecraft or planets) in the heliosphere at different times. For doing this, the magnetic connection in the interplanetary space is obtained by the classic Parker Heliospheric Magnetic Field (HMF). In close vicinity of the Sun, a Potential Field Source Surface (PFSS) model can be applied to connect the HMF to the solar photosphere. Solar-MACH is especially aimed at providing publication-ready figures for the analyses of Solar Energetic Particle events (SEPs) or solar transients such as Coronal Mass Ejections (CMEs). It is provided as an installable Python package (listed on PyPI and conda-forge), but also as a web tool at solar-mach.github.io that completely runs in any web browser and requires neither Python knowledge nor installation. The development of Solar-MACH is open to everyone and takes place on GitHub, where the source code is publicly available under the BSD 3-Clause License. Established Python libraries like sunpy and pfsspy are utilized to obtain functionalities when possible. In this article, the Python code of Solar-MACH is explained, and its functionality is demonstrated using real science examples. In addition, we introduce the overarching SERPENTINE project, the umbrella under which the recent development took place.	http://dx.doi.org/10.3389/fspas.2022.1058810	cs	arxiv					0.0	
"Online characterization of planetary surfaces: PlanetServer, an
  open-source analysis and visualization tool"	R. Marco Figuera	B. Pham Huu, A. P. Rossi, M. Minin, J. Flahaut, A. Halder	2017-01-06 11:40:27	The lack of open-source tools for hyperspectral data visualization and analysiscreates a demand for new tools. In this paper we present the new PlanetServer,a set of tools comprising a web Geographic Information System (GIS) and arecently developed Python Application Programming Interface (API) capableof visualizing and analyzing a wide variety of hyperspectral data from differentplanetary bodies. Current WebGIS open-source tools are evaluated in orderto give an overview and contextualize how PlanetServer can help in this mat-ters. The web client is thoroughly described as well as the datasets availablein PlanetServer. Also, the Python API is described and exposed the reason ofits development. Two different examples of mineral characterization of differenthydrosilicates such as chlorites, prehnites and kaolinites in the Nili Fossae areaon Mars are presented. As the obtained results show positive outcome in hyper-spectral analysis and visualization compared to previous literature, we suggestusing the PlanetServer approach for such investigations.	http://dx.doi.org/10.1016/j.pss.2017.09.007	cs	arxiv					0.0	
TensorFlow.js: Machine Learning for the Web and Beyond	Daniel Smilkov	Nikhil Thorat, Yannick Assogba, Ann Yuan, Nick Kreeger, Ping Yu, Kangyi Zhang, Shanqing Cai, Eric Nielsen, David Soergel, Stan Bileschi, Michael Terry, Charles Nicholson, Sandeep N. Gupta, Sarah Sirajuddin, D. Sculley, Rajat Monga, Greg Corrado, Fernanda B. Viégas, Martin Wattenberg	2019-01-16 15:43:58	TensorFlow.js is a library for building and executing machine learning algorithms in JavaScript. TensorFlow.js models run in a web browser and in the Node.js environment. The library is part of the TensorFlow ecosystem, providing a set of APIs that are compatible with those in Python, allowing models to be ported between the Python and JavaScript ecosystems. TensorFlow.js has empowered a new set of developers from the extensive JavaScript community to build and deploy machine learning models and enabled new classes of on-device computation. This paper describes the design, API, and implementation of TensorFlow.js, and highlights some of the impactful use cases.	http://arxiv.org/abs/1901.05350v2	cs	arxiv					0.0	
"Securing Your Collaborative Jupyter Notebooks in the Cloud using
  Container and Load Balancing Services"	Haw-minn Lu	Adrian Kwong, Jose Unpingco	2020-06-02 17:52:32	Jupyter has become the go-to platform for developing data applications but data and security concerns, especially when dealing with healthcare, have become paramount for many institutions and applications dealing with sensitive information. How then can we continue to enjoy the data analysis and machine learning opportunities provided by Jupyter and the Python ecosystem while guaranteeing auditable compliance with security and privacy concerns? We will describe the architecture and implementation of a cloud based platform based on Jupyter that integrates with Amazon Web Services (AWS) and uses containerized services without exposing the platform to the vulnerabilities present in Kubernetes and JupyterHub. This architecture addresses the HIPAA requirements to ensure both security and privacy of data. The architecture uses an AWS service to provide JSON Web Tokens (JWT) for authentication as well as network control. Furthermore, our architecture enables secure collaboration and sharing of Jupyter notebooks. Even though our platform is focused on Jupyter notebooks and JupyterLab, it also supports R-Studio and bespoke applications that share the same authentication mechanisms. Further, the platform can be extended to other cloud services other than AWS.	http://arxiv.org/abs/2006.01818v1	cs	arxiv					0.0	
AutoClassWeb: a simple web interface for Bayesian clustering	Pierre Poulain	Jean-Michel Camadro	2022-02-21 14:14:18	Objective: Data clustering is a common exploration step in the omics era, notably in genomics and proteomics where many genes or proteins can bequantified from one or more experiments. Bayesian clustering is a powerful algorithm that can classify several thousands of genes or proteins. AutoClass C, its original implementation, handles missing data, automatically determines the best number of clusters but is not user-friendly.Results: We developed an online tool called AutoClassWeb, which provides an easy-to-use web interface for Bayesian clustering with AutoClass. Input data are entered as TSV files. Results are provided in formats that ease further analyses with spreadsheet programs or with programming languages, such as Python or R. AutoClassWeb is implemented in Python and is published under the 3-Clauses BSD license. The source code is available athttps://github.com/pierrepo/autoclassweb along with a detailed documentation.	http://arxiv.org/abs/2202.10253v2	cs	arxiv					0.0	
"The Burke-Gaffney Observatory: A fully roboticized remote-access
  observatory with a low resolution spectrograph"	C. Ian Short	David J. Lane, Tiffany Fields	2023-07-13 18:47:23	We describe the current state of the Burke-Gaffney Observatory (BGO) at Saint Mary's University - a unique fully roboticized remote-access observatory that allows students to carry out imaging, photometry, and spectroscopy projects remotely from anywhere in the world via a web browser or social media. Stellar spectroscopy is available with the ALPY 600 low resolution grism spectrograph equipped with a CCD detector. We describe our custom CCD spectroscopy reduction procedure written in the Python programming language and demonstrate the quality of fits of synthetic spectra computed with the ChromaStarServer (CSS) code to BGO spectra. The facility along with the accompanying Python BGO spectroscopy reduction package and the CSS spectrum synthesis code provide an accessible means for students anywhere to carry our projects at the undergraduate honours level. BGO web pages for potential observers are at the site: observatory.smu.ca/bgo-useme. All codes are available from the OpenStars www site: openstars.smu.ca/	http://arxiv.org/abs/2307.07022v2	cs	arxiv					0.0	
"Filtergraph: A Flexible Web Application for Instant Data Visualization
  of Astronomy Datasets"	Dan Burger	Keivan G. Stassun, Joshua Pepper, Robert J. Siverd, Martin A. Paegert, Nathan M. De Lee	2012-12-18 19:00:06	Filtergraph is a web application being developed by the Vanderbilt Initiative in Data-intensive Astrophysics (VIDA) to flexibly handle a large variety of astronomy datasets. While current datasets at Vanderbilt are being used to search for eclipsing binaries and extrasolar planets, this system can be easily reconfigured for a wide variety of data sources. The user loads a flat-file dataset into Filtergraph which instantly generates an interactive data portal that can be easily shared with others. From this portal, the user can immediately generate scatter plots, histograms, and tables based on the dataset. Key features of the portal include the ability to filter the data in real time through user-specified criteria, the ability to select data by dragging on the screen, and the ability to perform arithmetic operations on the data in real time. The application is being optimized for speed in the context of very large datasets: for instance, plot generated from a stellar database of 3.1 million entries render in less than 2 seconds on a standard web server platform. This web application has been created using the Web2py web framework based on the Python programming language. Filtergraph is freely available at http://filtergraph.vanderbilt.edu/.	http://arxiv.org/abs/1212.4458v3	cs	arxiv					0.0	
Web-based Argumentation	Kenrick	Aucun	2016-12-14 03:21:32	"Assumption-Based Argumentation (ABA) is an argumentation framework that has been proposed in the late 20th century. Since then, there was still no solver implemented in a programming language which is easy to setup and no solver have been interfaced to the web, which impedes the interests of the public. This project aims to implement an ABA solver in a modern programming language that performs reasonably well and interface it to the web for easier access by the public. This project has demonstrated the novelty of development of an ABA solver, that computes conflict-free, stable, admissible, grounded, ideal, and complete semantics, in Python programming language which can be used via an easy-to-use web interface for visualization of the argument and dispute trees. Experiments were conducted to determine the project's best configurations and to compare this project with proxdd, a state-of-the-art ABA solver, which has no web interface and computes less number of semantics. From the results of the experiments, this project's best configuration is achieved by utilizing ""pickle"" technique and tree caching technique. Using this project's best configuration, this project achieved a lower average runtime compared to proxdd. On other aspect, this project encountered more cases with exceptions compared to proxdd, which might be caused by this project computing more semantics and hence requires more resources to do so. Hence, it can be said that this project run comparably well to the state-of-the-art ABA solver proxdd. Future works of this project include computational complexity analysis and efficiency analysis of algorithms implemented, implementation of more semantics in argumentation framework, and usability testing of the web interface."	http://arxiv.org/abs/1612.04469v1	cs	arxiv					0.0	
"Web application for galaxy-targeted follow-up of electromagnetic
  counterparts to gravitational wave sources"	L. Salmon	L. Hanlon, R. M. Jeffrey, A. Martin-Carrillo	2019-12-16 11:48:02	The Laser Interferometer Gravitational Wave Observatory (LIGO) and Virgo Collaboration's Observing Run 3 has demanded the development of widely-applicable tools for gravitational wave follow-up. These tools must address the main challenges of the multi-messenger era, namely covering large localisation regions and quickly identifying decaying transients. To address these challenges, we present a public web interface to assist astronomers in conducting galaxy-targeted follow-up of gravitational wave events by offering a fast and public list of targets post-gravitational wave trigger. After a gravitational wave trigger, the back-end galaxy retrieval algorithm identifies and scores galaxies based on the LIGO and Virgo computed probabilities and properties of the galaxies taken from the Galaxy List for the Advanced Detector Era (GLADE) V2 galaxy catalogue. Within minutes, the user can retrieve, download, and limit ranked galaxy lists from the web application. The algorithm and website have been tested on past gravitational wave events, and execution times have been analysed. The algorithm is being triggered automatically during Observing Run 3 and its features will be extended if needed. The web application was developed using the Python based Flask web framework. The web application is freely available and publicly accessible at gwtool.watchertelescope.ie.	http://dx.doi.org/10.1051/0004-6361/201936573	cs	arxiv					0.0	
SCONCE: A cosmic web finder for spherical and conic geometries	Yikun Zhang	Rafael S. de Souza, Yen-Chi Chen	2022-07-14 15:33:32	The latticework structure known as the cosmic web provides a valuable insight into the assembly history of large-scale structures. Despite the variety of methods to identify the cosmic web structures, they mostly rely on the assumption that galaxies are embedded in a Euclidean geometric space. Here we present a novel cosmic web identifier called SCONCE (Spherical and CONic Cosmic wEb finder) that inherently considers the 2D (RA,DEC) spherical or the 3D (RA,DEC,$z$) conic geometry. The proposed algorithms in SCONCE generalize the well-known subspace constrained mean shift (SCMS) method and primarily address the predominant filament detection problem. They are intrinsic to the spherical/conic geometry and invariant to data rotations. We further test the efficacy of our method with an artificial cross-shaped filament example and apply it to the SDSS galaxy catalogue, revealing that the 2D spherical version of our algorithms is robust even in regions of high declination. Finally, using N-body simulations from Illustris, we show that the 3D conic version of our algorithms is more robust in detecting filaments than the standard SCMS method under the redshift distortions caused by the peculiar velocities of halos. Our cosmic web finder is packaged in python as SCONCE-SCMS and has been made publicly available.	http://dx.doi.org/10.1093/mnras/stac2504	cs	arxiv					0.0	
"Atomic Simulation Recipes -- a Python framework and library for
  automated workflows"	Morten Gjerding	Thorbjørn Skovhus, Asbjørn Rasmussen, Fabian Bertoldo, Ask Hjorth Larsen, Jens Jørgen Mortensen, Kristian Sommer Thygesen	2021-04-27 19:03:29	The Atomic Simulation Recipes (ASR) is an open source Python framework for working with atomistic materials simulations in an efficient and sustainable way that is ideally suited for high-throughput projects. Central to ASR is the concept of a Recipe: a high-level Python script that performs a well defined simulation task robustly and accurately while keeping track of the data provenance. The ASR leverages the functionality of the Atomic Simulation Environment (ASE) to interface with external simulation codes and attain a high abstraction level. We provide a library of Recipes for common simulation tasks employing density functional theory and many-body perturbation schemes. These Recipes utilize the GPAW electronic structure code, but may be adapted to other simulation codes with an ASE interface. Being independent objects with automatic data provenance control, Recipes can be freely combined through Python scripting giving maximal freedom for users to build advanced workflows. ASR also implements a command line interface that can be used to run Recipes and inspect results. The ASR Migration module helps users maintain their data while the Database and App modules makes it possible to create local databases and present them as customized web pages.	http://arxiv.org/abs/2104.13431v1	cs	arxiv					0.0	
astroquery: An Astronomical Web-Querying Package in Python	Adam Ginsburg	Brigitta M. Sipőcz, C. E. Brasseur, Philip S. Cowperthwaite, Matthew W. Craig, Christoph Deil, James Guillochon, Giannina Guzman, Simon Liedtke, Pey Lian Lim, Kelly E. Lockhart, Michael Mommert, Brett M. Morris, Henrik Norman, Madhura Parikh, Magnus V. Persson, Thomas P. Robitaille, Juan-Carlos Segovia, Leo P. Singer, Erik J. Tollerud, Miguel de Val-Borro, Ivan Valtchanov, Julien Woillez, the Astroquery collaboration	2019-01-14 19:08:51	astroquery is a collection of tools for requesting data from databases hosted on remote servers with interfaces exposed on the internet, including those with web pages but without formal application program interfaces (APIs). These tools are built on the Python requests package, which is used to make HTTP requests, and astropy, which provides most of the data parsing functionality. astroquery modules generally attempt to replicate the web page interface provided by a given service as closely as possible, making the transition from browser-based to command-line interaction easy. astroquery has received significant contributions from throughout the astronomical community, including several significant contributions from telescope archives. astroquery enables the creation of fully reproducible workflows from data acquisition through publication. This paper describes the philosophy, basic structure, and development model of the astroquery package. The complete documentation for astroquery can be found at http://astroquery.readthedocs.io/.	http://dx.doi.org/10.3847/1538-3881/aafc33	cs	arxiv					0.0	
"The cosmic spiderweb: equivalence of cosmic, architectural, and origami
  tessellations"	Mark C. Neyrinck	Johan Hidding, Marina Konstantatou, Rien van de Weygaert	2017-10-12 13:34:33	For over twenty years, the term 'cosmic web' has guided our understanding of the large-scale arrangement of matter in the cosmos, accurately evoking the concept of a network of galaxies linked by filaments. But the physical correspondence between the cosmic web and structural-engineering or textile 'spiderwebs' is even deeper than previously known, and extends to origami tessellations as well. Here we explain that in a good structure-formation approximation known as the adhesion model, threads of the cosmic web form a spiderweb, i.e. can be strung up to be entirely in tension. The correspondence is exact if nodes sampling voids are included, and if structure is excluded within collapsed regions (walls, filaments and haloes), where dark-matter multistreaming and baryonic physics affect the structure. We also suggest how concepts arising from this link might be used to test cosmological models: for example, to test for large-scale anisotropy and rotational flows in the cosmos.	http://dx.doi.org/10.1098/rsos.171582	cs	arxiv					0.0	
Comparative review of selected Internet communication protocols	Łukasz Kamiński	Maciej Kozłowski, Daniel Sporysz, Katarzyna Wolska, Patryk Zaniewski, Radosław Roszczyk	2022-12-14 19:49:57	With a large variety of communication methods and protocols, many software architects face the problem of choosing the best way for services to share information. For communication technology to be functional and practical, it should enable developers to define a complete set of CRUD methods for the processed data. The research team compared the most commonly used data transfer protocols and concepts in this paper: REST, WebSocket, gRPC GraphQL and SOAP. To do that, a set of web servers was implemented in Python, each using one of the examined technologies. Then, the team performed an automated benchmark measuring time and data transfer overhead for a set of defined operations: creating an entity, retrieving a list of 100 entities and fetching details of one entity. Tests were designed to avoid the results being interfered by database connection or docker-compose environment characteristics. The research team has concluded that gRPC was the most efficient and reliable data transfer method. On the other hand, GraphQL turned out to be the slowest communication method of all. Moreover, its server and client libraries caused the most problems with proper usage in a web server. SOAP did not participate in benchmarking due to limited compatibility with Python and a lack of popularity in modern web solutions.	http://arxiv.org/abs/2212.07475v1	cs	arxiv					0.0	
"JClarens: A Java Framework for Developing and Deploying Web Services for
  Grid Computing"	Michael Thomas	Conrad Steenberg, Frank van Lingen, Harvey Newman, Julian Bunn, Arshad Ali, Richard McClatchey, Ashiq Anjum, Tahir Azim, Waqas ur Rehman, Faisal Khan, Jang Uk In	2005-04-11 21:45:07	High Energy Physics (HEP) and other scientific communities have adopted Service Oriented Architectures (SOA) as part of a larger Grid computing effort. This effort involves the integration of many legacy applications and programming libraries into a SOA framework. The Grid Analysis Environment (GAE) is such a service oriented architecture based on the Clarens Grid Services Framework and is being developed as part of the Compact Muon Solenoid (CMS) experiment at the Large Hadron Collider (LHC) at European Laboratory for Particle Physics (CERN). Clarens provides a set of authorization, access control, and discovery services, as well as XMLRPC and SOAP access to all deployed services. Two implementations of the Clarens Web Services Framework (Python and Java) offer integration possibilities for a wide range of programming languages. This paper describes the Java implementation of the Clarens Web Services Framework called JClarens. and several web services of interest to the scientific and Grid community that have been deployed using JClarens.	http://arxiv.org/abs/cs/0504044v1	cs	arxiv					0.0	
"Filtergraph: An Interactive Web Application for Visualization of
  Astronomy Datasets"	Dan Burger	Keivan G. Stassun, Joshua Pepper, Robert J. Siverd, Martin Paegert, Nathan M. De Lee, William H. Robinson	2013-07-15 16:02:24	Filtergraph is a web application being developed and maintained by the Vanderbilt Initiative in Data-intensive Astrophysics (VIDA) to flexibly and rapidly visualize a large variety of astronomy datasets of various formats and sizes. The user loads a flat-file dataset into Filtergraph which automatically generates an interactive data portal that can be easily shared with others. From this portal, the user can immediately generate scatter plots of up to 5 dimensions as well as histograms and tables based on the dataset. Key features of the portal include intuitive controls with auto-completed variable names, the ability to filter the data in real time through user-specified criteria, the ability to select data by dragging on the screen, and the ability to perform arithmetic operations on the data in real time. To enable seamless data visualization and exploration, changes are quickly rendered on screen and visualizations can be exported as high quality graphics files. The application is optimized for speed in the context of large datasets: for instance, a plot generated from a stellar database of 3.1 million entries renders in less than 2 seconds on a standard web server platform. This web application has been created using the Web2py web framework based on the Python programming language. Filtergraph is free to use at http://filtergraph.vanderbilt.edu/.	http://arxiv.org/abs/1307.4000v2	cs	arxiv					0.0	
Youpi, a Web-based Astronomical Image Processing Pipeline	M. Monnerville	G. Sémah	2010-06-05 22:27:14	"Youpi stands for ""YOUpi is your processing PIpeline"". It is a portable, easy to use web application providing high level functionalities to perform data reduction on scientific FITS images. It is built on top of open source processing tools that are released to the community by Terapix, in order to organize your data on a computer cluster, to manage your processing jobs in real time and to facilitate teamwork by allowing fine-grain sharing of results and data. On the server side, Youpi is written in the Python programming language and uses the Django web framework. On the client side, Ajax techniques are used along with the Prototype and script.aculo.us Javascript librairies."	http://arxiv.org/abs/1006.1074v1	cs	arxiv					0.0	
"Prototyping the graphical user interface for the operator of the
  Cherenkov Telescope Array"	Iftach Sadeh	Igor Oya, Joseph Schwarz, Emmanuel Pietriga	2016-08-11 20:00:11	The Cherenkov Telescope Array (CTA) is a planned gamma-ray observatory. CTA will incorporate about 100 imaging atmospheric Cherenkov telescopes (IACTs) at a Southern site, and about 20 in the North. Previous IACT experiments have used up to five telescopes. Subsequently, the design of a graphical user interface (GUI) for the operator of CTA involves new challenges. We present a GUI prototype, the concept for which is being developed in collaboration with experts from the field of Human-Computer Interaction. The prototype is based on Web technology; it incorporates a Python web server, Web Sockets and graphics generated with the d3.js Javascript library.	http://dx.doi.org/10.1117/12.2231606	cs	arxiv					0.0	
"RaDMaX online: a web-based program for the determination of strain and
  damage profiles in irradiated crystals using X-ray diffraction"	Alexandre Boulle	Vincent Mergnac	2019-11-15 08:55:10	RaDMaX online is a major update to the previously published RaDMaX (Radiation Damage in Materials analysed with X-ray diffraction) software [Souilah, Boulle & Debelle, J. Appl. Cryst. (2016) 49, 311-316]. This program features a user friendly interface that allows to retrieve strain and disorder depth-profiles in irradiated crystals from the simulation of X-ray diffraction data recorded in symmetrical $\theta/2\theta$ mode. As compared to its predecessor, RaDMaX online has been entirely rewritten in order to be able to run within a simple web browser, therefore avoiding the necessity to install any programming environment on the users' computers. The RaDMaX online web-application is written in Python and developed within a Jupyter notebook implementing graphical widgets and interactive plots. RaDMaX online is free and open source (CeCILL license) and can be accessed on the internet at: https://aboulle.github.io/RaDMaX-online/.	http://dx.doi.org/10.1107/S1600576720002514	cs	arxiv					0.0	
"Inscriptis -- A Python-based HTML to text conversion library optimized
  for knowledge extraction from the Web"	Albert Weichselbraun	Aucun	2021-07-12 12:40:43	Inscriptis provides a library, command line client and Web service for converting HTML to plain text. Its development has been triggered by the need to obtain accurate text representations for knowledge extraction tasks that preserve the spatial alignment of text without drawing upon heavyweight, browser-based solutions such as Selenium. In contrast to related software packages, Inscriptis (i) provides a layout-aware conversion of HTML that more closely resembles the rendering obtained from standard Web browsers; and (ii) supports annotation rules, i.e., user-provided mappings that allow for annotating the extracted text based on structural and semantic information encoded in HTML tags and attributes. These unique features ensure that downstream knowledge extraction components can operate on accurate text representations, and may even use information on the semantics and structure of the original HTML document.	http://dx.doi.org/10.21105/joss.03557	cs	arxiv					0.0	
DataLab: A Platform for Data Analysis and Intervention	Yang Xiao	Jinlan Fu, Weizhe Yuan, Vijay Viswanathan, Zhoumianze Liu, Yixin Liu, Graham Neubig, Pengfei Liu	2022-02-25 18:32:19	Despite data's crucial role in machine learning, most existing tools and research tend to focus on systems on top of existing data rather than how to interpret and manipulate data. In this paper, we propose DataLab, a unified data-oriented platform that not only allows users to interactively analyze the characteristics of data, but also provides a standardized interface for different data processing operations. Additionally, in view of the ongoing proliferation of datasets, \toolname has features for dataset recommendation and global vision analysis that help researchers form a better view of the data ecosystem. So far, DataLab covers 1,715 datasets and 3,583 of its transformed version (e.g., hyponyms replacement), where 728 datasets support various analyses (e.g., with respect to gender bias) with the help of 140M samples annotated by 318 feature functions. DataLab is under active development and will be supported going forward. We have released a web platform, web API, Python SDK, PyPI published package and online documentation, which hopefully, can meet the diverse needs of researchers.	http://arxiv.org/abs/2202.12875v1	cs	arxiv					0.0	
Clarens Client and Server Applications	Conrad D. Steenberg	Eric Aslakson, Julian J. Bunn, Harvey B. Newman, Michael Thomas, Frank van Lingen	2003-05-30 20:25:50	Several applications have been implemented with access via the Clarens web service infrastructure, including virtual organization management, JetMET physics data analysis using relational databases, and Storage Resource Broker (SRB) access. This functionality is accessible transparently from Python scripts, the Root analysis framework and from Java applications and browser applets.	http://arxiv.org/abs/cs/0306001v2	cs	arxiv					0.0	
Algorithmic Programming Language Identification	David Klein	Kyle Murray, Simon Weber	2011-06-21 00:37:23	Motivated by the amount of code that goes unidentified on the web, we introduce a practical method for algorithmically identifying the programming language of source code. Our work is based on supervised learning and intelligent statistical features. We also explored, but abandoned, a grammatical approach. In testing, our implementation greatly outperforms that of an existing tool that relies on a Bayesian classifier. Code is written in Python and available under an MIT license.	http://arxiv.org/abs/1106.4064v2	cs	arxiv					0.0	
Asymptotic connectivity for the network of RNA secondary structures	Peter Clote	Aucun	2015-08-16 12:07:38	Given an RNA sequence a, consider the network G = (V;E), where the set V of nodes consists of all secondary structures of a, and whose edge set E consists of all edges connecting two secondary structures whose base pair distance is 1. Define the network connectivity, or expected network degree, as the average number of edges incident to vertices of G. Using algebraic combinatorial methods, we prove that the asymptotic connectivity of length n homopolymer sequences is 0:473418 ? n. This raises the question of what other network properties are characteristic of the network of RNA secondary structures. Programs in Python, C and Mathematica are available at the web site http://bioinformatics.bc.edu/clotelab/ RNAexpNumNbors.	http://arxiv.org/abs/1508.03815v1	cs	arxiv					0.0	
Open Astronomy Catalogs API	James Guillochon	Philip S. Cowperthwaite	2018-04-28 20:46:07	We announce the public release of the application program interface (API) for the Open Astronomy Catalogs (OACs), the OACAPI. The OACs serve near-complete collections of supernova, tidal disruption, kilonova, and fast stars data (including photometry, spectra, radio, and X-ray observations) via a user-friendly web interface that displays the data interactively and offers full data downloads. The OACAPI, by contrast, enables users to specifically download particular pieces of the OAC dataset via a flexible programmatic syntax, either via URL GET requests, or via a module within the astroquery Python package.	http://arxiv.org/abs/1804.10847v1	cs	arxiv					0.0	
GuiTeNet: A graphical user interface for tensor networks	Lisa Sahlmann	Christian B. Mendl	2018-07-30 18:09:13	We introduce a graphical user interface for constructing arbitrary tensor networks and specifying common operations like contractions or splitting, denoted GuiTeNet. Tensors are represented as nodes with attached legs, corresponding to the ordered dimensions of the tensor. GuiTeNet visualizes the current network, and instantly generates Python/NumPy source code for the hitherto sequence of user actions. Support for additional programming languages is planned for the future. We discuss the elementary operations on tensor networks used by GuiTeNet, together with high-level optimization strategies. The software runs directly in web browsers and is available online at http://guitenet.org.	http://dx.doi.org/10.5334/jors.304	cs	arxiv					0.0	
Extensive Online Shock Model Database	A. Alarie	C. Morisset	2019-08-22 19:59:13	We present a new database of fully radiative shock models calculated with the shock and photoionization code MAPPINGS V. The database architecture is built to contain diverse shock grids comprising of multiple shock parameters. It can be easily accessible through the MySQL protocol. Intensities of spectral lines from infrared to X-rays are stored along with other useful outputs such as the ionic fractions/temperature, integrated densities, etc. A web page was created in other to explore interactively the database as it evolves with time. Examples of its usage is given using the Python language.	http://dx.doi.org/10.22201/ia.01851101p.2019.55.02.21	cs	arxiv					0.0	
DQM Tools and Techniques of the SND Detector	K. V. Pugachev	T. V. Dimova, L. V. Kardapoltsev, A. A. Korol, D. P. Kovrizhin, D. A. Shtol	2020-05-15 08:17:07	SND detector operates at the VEPP-2000 collider (BINP, Novosibirsk). To improve events selection for physical analysis and facilitate online detector control we developed new data quality monitoring (DQM) system. The system includes online and reprocess control modules, automatic decision making scripts, interactive (web based) and program (python) access to various quality estimates. This access is implemented with node.js server with data in RDBMS MySQL. We describe here general system logics, its components and some implementation details.	http://arxiv.org/abs/2005.14143v2	cs	arxiv					0.0	
MUDES: Multilingual Detection of Offensive Spans	Tharindu Ranasinghe	Marcos Zampieri	2021-02-18 23:19:00	The interest in offensive content identification in social media has grown substantially in recent years. Previous work has dealt mostly with post level annotations. However, identifying offensive spans is useful in many ways. To help coping with this important challenge, we present MUDES, a multilingual system to detect offensive spans in texts. MUDES features pre-trained models, a Python API for developers, and a user-friendly web-based interface. A detailed description of MUDES' components is presented in this paper.	http://arxiv.org/abs/2102.09665v2	cs	arxiv					0.0	
"Using Glowscript to Teach Numerical Modeling in Undergraduate Biology
  Education"	Joshua G. Schreibeis	Olivia M. Merideth, Gavin A. Buxton	2022-04-26 15:24:12	Mathematical and numerical modeling is an increasingly important, yet often neglected, topic for biology students. We have found Glowscript to facilitate teaching and introducing computer simulations to students. In particular, the built-in the graphics and graphing capabilities can provide students with immediate feedback. Glowscript is a web-based form of visual Python that runs in a standard browser, and students can easily embed their simulations in external websites. Here we show various examples of how Glowscript is implemented in an undergraduate computational biology course. We hope these examples inspire others to adopt Glowscript in their science classrooms.	http://arxiv.org/abs/2204.12911v1	cs	arxiv					0.0	
HHLPy: Practical Verification of Hybrid Systems using Hoare Logic	Huanhuan Sheng	Alexander Bentkamp, Bohua Zhan	2022-10-31 09:20:00	We present a tool for verification of hybrid systems expressed in the sequential fragment of HCSP (Hybrid Communicating Sequential Processes). The tool permits annotating HCSP programs with pre- and postconditions, invariants, and proof rules for reasoning about ordinary differential equations. Verification conditions are generated from the annotations following the rules of hybrid Hoare logic. We designed labeling and highlighting mechanisms to distinguish and visualize different verification conditions. The tool is implemented in Python and has a web-based user interface. We evaluated the effectiveness of the tool on translations of Simulink/Stateflow models and on KeYmaera X benchmarks.	http://arxiv.org/abs/2210.17163v2	cs	arxiv					0.0	
ANITA: Analytic Tableau Proof Assistant	Davi Romero Vasconcelos	Aucun	2023-03-10 11:36:29	This work presents the system ANITA (Analytic Tableau Proof Assistant) developed for teaching analytic tableaux to computer science students. The tool is written in Python and can be used as a desktop application, or in a web platform. This paper describes the logical system of the tool, explains how the tool is used and compares it to several similar tools. ANITA has already been used in logic courses and an evaluation of the tool is presented.	http://dx.doi.org/10.4204/EPTCS.375.4	cs	arxiv					0.0	
cesium: Open-Source Platform for Time-Series Inference	Brett Naul	Stéfan van der Walt, Arien Crellin-Quick, Joshua S. Bloom, Fernando Pérez	2016-09-15 04:09:48	Inference on time series data is a common requirement in many scientific disciplines and internet of things (IoT) applications, yet there are few resources available to domain scientists to easily, robustly, and repeatably build such complex inference workflows: traditional statistical models of time series are often too rigid to explain complex time domain behavior, while popular machine learning packages require already-featurized dataset inputs. Moreover, the software engineering tasks required to instantiate the computational platform are daunting. cesium is an end-to-end time series analysis framework, consisting of a Python library as well as a web front-end interface, that allows researchers to featurize raw data and apply modern machine learning techniques in a simple, reproducible, and extensible way. Users can apply out-of-the-box feature engineering workflows as well as save and replay their own analyses. Any steps taken in the front end can also be exported to a Jupyter notebook, so users can iterate between possible models within the front end and then fine-tune their analysis using the additional capabilities of the back-end library. The open-source packages make us of many use modern Python toolkits, including xarray, dask, Celery, Flask, and scikit-learn.	http://arxiv.org/abs/1609.04504v1	cs	arxiv					0.0	
PyPhi: A toolbox for integrated information theory	William G. P. Mayner	William Marshall, Larissa Albantakis, Graham Findlay, Robert Marchman, Giulio Tononi	2017-12-27 18:01:12	Integrated information theory provides a mathematical framework to fully characterize the cause-effect structure of a physical system. Here, we introduce PyPhi, a Python software package that implements this framework for causal analysis and unfolds the full cause-effect structure of discrete dynamical systems of binary elements. The software allows users to easily study these structures, serves as an up-to-date reference implementation of the formalisms of integrated information theory, and has been applied in research on complexity, emergence, and certain biological questions. We first provide an overview of the main algorithm and demonstrate PyPhi's functionality in the course of analyzing an example system, and then describe details of the algorithm's design and implementation.   PyPhi can be installed with Python's package manager via the command 'pip install pyphi' on Linux and macOS systems equipped with Python 3.4 or higher. PyPhi is open-source and licensed under the GPLv3; the source code is hosted on GitHub at https://github.com/wmayner/pyphi . Comprehensive and continually-updated documentation is available at https://pyphi.readthedocs.io/ . The pyphi-users mailing list can be joined at https://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical interface to the software is available at http://integratedinformationtheory.org/calculate.html .	http://dx.doi.org/10.1371/journal.pcbi.1006343	cs	arxiv					0.0	
"DataSist: A Python-based library for easy data analysis, visualization
  and modeling"	Rising Odegua	Festus Ikpotokin	2019-11-09 10:05:38	A large amount of data is produced every second from modern information systems such as mobile devices, the world wide web, Internet of Things, social media, etc. Analysis and mining of this massive data requires a lot of advanced tools and techniques. Therefore, big data analytics and mining is currently an active and trending area of research because of the enormous benefits businesses and organizations derive from it. Numerous tools like Pandas, Numpy, STATA, SPSS, have been created to help analyze and mine these huge outburst of data and some have become so popular and widely used in the field. This paper presents a new python-based library, DataSist, which offers high level, intuitive and easy to use functions, and methods that helps data scientists/analyst to quickly analyze, mine and visualize big data sets. The objectives of this project were to (i) design a python library to aid data analysis process by abstracting low level syntax, (ii) increase productivity of data scientist by making them focus on what to do rather than how to do it. This project shows that data analysis can be automated and much faster when we abstract certain functions, and will serve as an important tool in the workflow of data scientists.	http://arxiv.org/abs/1911.03655v2	cs	arxiv					0.0	
"RACS2: A Framework of Remote Autonomous Control System for Telescope
  Observation and its application"	Zhi-yue Wang	Guang-yu Zhang, Jian Wang, Qian Zhang, Zhe Genga, Ze-yu Zhu, Jia-Yao Gu, Zhen-hao Zheng, Lu-cheng Zhu, Kun Ge, Hong-fei Zhang	2022-06-23 02:04:11	As the demand of astronomical observation rising, the telescope systems are becoming more and more complex. Thus, the observatory control software needs to be more intelligent, they have to control each instrument inside the observatory, finish the observation tasks autonomously, and report the information to users if needed. We developed a distributed autonomous observatory control framework named Remote Autonomous Control System 2nd, RACS2 to meet these requirements. The RACS2 framework uses decentralized distributed architecture, instrument control software and system service such as observation control service are implemented as different components. The communication between components is implemented based on a high-performance serialization library and a light-weighted messaging library.The interfaces towards python and Experimental Physics and Industrial Control System (EPICS) are implemented, so the RACS2 framework can communicate with EPICS based device control software and python-based software. Several system components including log, executor, scheduler and other modules are developed to help observation. Observation tasks can be programmed with python language, and the plans are scheduled by the scheduler component to achieve autonomous observation.A set of web service is implemented based on the FastAPI framework, with which user can control and manage the framework remotely.Based on the RACS2 framework, we have implemented the DATs telescope's observation system and the space object observation system.We performed remote autonomous observation and received many data with these systems.	http://arxiv.org/abs/2206.11451v1	cs	arxiv					0.0	
"The Graphical User Interface of the Operator of the Cherenkov Telescope
  Array"	Iftach Sadeh	Igor Oya, Joseph Schwarz, Emmanuel Pietriga, Dejan Dezman	2017-10-19 12:31:14	The Cherenkov Telescope Array (CTA) is the next generation gamma-ray observatory. CTA will incorporate about 100 imaging atmospheric Cherenkov telescopes (IACTs) at a southern site, and about 20 in the north. Previous IACT experiments have used up to five telescopes. Subsequently, the design of a graphical user interface (GUI) for the operator of CTA poses an interesting challenge. In order to create an effective interface, the CTA team is collaborating with experts from the field of Human-Computer Interaction. We present here our GUI prototype. The back-end of the prototype is a Python Web server. It is integrated with the observation execution system of CTA, which is based on the Alma Common Software (ACS). The back-end incorporates a redis database, which facilitates synchronization of GUI panels. redis is also used to buffer information collected from various software components and databases. The front-end of the prototype is based on Web technology. Communication between Web server and clients is performed using Web Sockets, where graphics are generated with the d3.js Javascript library.	http://dx.doi.org/10.18429/JACoW-ICALEPCS2017-TUBPL06	cs	arxiv					0.0	
"BioKlustering: a web app for semi-supervised learning of maximally
  imbalanced genomic data"	Samuel Ozminkowski	Yuke Wu, Liule Yang, Zhiwen Xu, Luke Selberg, Chunrong Huang, Claudia Solis-Lemus	2022-09-23 17:23:59	Summary: Accurate phenotype prediction from genomic sequences is a highly coveted task in biological and medical research. While machine-learning holds the key to accurate prediction in a variety of fields, the complexity of biological data can render many methodologies inapplicable. We introduce BioKlustering, a user-friendly open-source and publicly available web app for unsupervised and semi-supervised learning specialized for cases when sequence alignment and/or experimental phenotyping of all classes are not possible. Among its main advantages, BioKlustering 1) allows for maximally imbalanced settings of partially observed labels including cases when only one class is observed, which is currently prohibited in most semi-supervised methods, 2) takes unaligned sequences as input and thus, allows learning for widely diverse sequences (impossible to align) such as virus and bacteria, 3) is easy to use for anyone with little or no programming expertise, and 4) works well with small sample sizes.   Availability and Implementation: BioKlustering (https://bioklustering.wid.wisc.edu) is a freely available web app implemented with Django, a Python-based framework, with all major browsers supported. The web app does not need any installation, and it is publicly available and open-source (https://github.com/solislemuslab/bioklustering).	http://arxiv.org/abs/2209.11730v2	cs	arxiv					0.0	
The Next Generation of the Montage Image Mosaic Toolkit	G. Bruce Berriman	J. C. Good, B. Rusholme, T. Robitaille	2016-08-08 22:50:57	"The scientific computing landscape has evolved dramatically in the past few years, with new schemes for organizing and storing data that reflect the growth in size and complexity of astronomical data sets. In response to this changing landscape, we are, over the next two years, deploying the next generation of the Montage toolkit ([ascl:1010.036]). The first release (October 2015) supports multi-dimensional data sets (""data cubes""), and insertion of XMP/AVM tags that allows images to ""drop-in"" to the WWT. The same release offers a beta-version of web-based interactive visualization of images; this includes wrappers for visualization in Python. Subsequent releases will support HEALPix (now standard in cosmic background experiments); incorporation of Montage into package managers (which enable automated management of software builds), and support for a library that will enable Montage to be called directly from Python. This next generation toolkit will inherit the architectural benefits of the current engine - component based tools, ANSI-C portability across Unix platforms and scalability for distributed processing. With the expanded functionality under development, Montage can be viewed not simply as a mosaic engine, but as a scalable, portable toolkit for managing, organizing and processing images."	http://arxiv.org/abs/1608.02649v1	cs	arxiv					0.0	
Coffea -- Columnar Object Framework For Effective Analysis	Nicholas Smith	Lindsey Gray, Matteo Cremonesi, Bo Jayatilaka, Oliver Gutsche, Allison Hall, Kevin Pedro, Maria Acosta, Andrew Melo, Stefano Belforte, Jim Pivarski	2020-08-28 15:47:22	The coffea framework provides a new approach to High-Energy Physics analysis, via columnar operations, that improves time-to-insight, scalability, portability, and reproducibility of analysis. It is implemented with the Python programming language, the scientific python package ecosystem, and commodity big data technologies. To achieve this suite of improvements across many use cases, coffea takes a factorized approach, separating the analysis implementation and data delivery scheme. All analysis operations are implemented using the NumPy or awkward-array packages which are wrapped to yield user code whose purpose is quickly intuited. Various data delivery schemes are wrapped into a common front-end which accepts user inputs and code, and returns user defined outputs. We will discuss our experience in implementing analysis of CMS data using the coffea framework along with a discussion of the user experience and future directions.	http://dx.doi.org/10.1051/epjconf/202024506012	cs	arxiv					0.0	
Galvanalyser: A Battery Test Database	Adam Lewis-Douglas	Luke Pitt, David A. Howey	2020-10-28 13:22:44	Performance and lifetime testing of batteries requires considerable effort and expensive specialist equipment. A wide range of potentiostats and battery testers are available on the market, but there is no standardisation of data exchange and data storage between them. To address this, we present Galvanalyser, a battery test database developed to manage the growing challenges of collating, managing and accessing data produced by multiple different battery testers. Collation is managed by a client-side application, the `Harvester', which pushes new data up to a PostgreSQL database on a server. Data access is possible in two ways: firstly, a web application allows data to be searched and viewed in a browser, with the option to plot data; secondly, a Python application programming interface (API) can connect directly to the database and pull requested data sets into Python. We hope to make Galvanalyser openly available soon. If you wish to test the system, please contact us for early access.	http://arxiv.org/abs/2010.14959v1	cs	arxiv					0.0	
"Brain Predictability toolbox: a Python library for neuroimaging based
  machine learning"	Sage Hahn	Dekang Yuan, Wesley Thompson, Max M Owens, Nicholas Allgaier, Hugh Garavan	2020-11-03 14:06:43	Summary Brain Predictability toolbox (BPt) represents a unified framework of machine learning (ML) tools designed to work with both tabulated data (in particular brain, psychiatric, behavioral, and physiological variables) and neuroimaging specific derived data (e.g., brain volumes and surfaces). This package is suitable for investigating a wide range of different neuroimaging based ML questions, in particular, those queried from large human datasets.   Availability and Implementation BPt has been developed as an open-source Python 3.6+ package hosted at https://github.com/sahahn/BPt under MIT License, with documentation provided at https://bpt.readthedocs.io/en/latest/, and continues to be actively developed. The project can be downloaded through the github link provided. A web GUI interface based on the same code is currently under development and can be set up through docker with instructions at https://github.com/sahahn/BPt_app.   Contact Please contact Sage Hahn at sahahn@uvm.edu	http://arxiv.org/abs/2011.01715v1	cs	arxiv					0.0	
Answers from the void: VIDE and its applications	P. M. Sutter	N. Hamaus, A. Pisani, G. Lavaux, B. D. Wandelt	2014-09-24 15:37:52	We discuss various applications of VIDE, the Void IDentification and Examination toolkit, an open-source Python/C++ code for finding cosmic voids in galaxy redshift surveys and N-body simulations. Based on a substantially enhanced version of ZOBOV, VIDE not only finds voids, but also summarizes their properties, extracts statistical information, and provides a Python-based platform for more detailed analysis, such as manipulating void catalogs and particle members, filtering, plotting, computing clustering statistics, stacking, comparing catalogs, and fitting density profiles. VIDE also provides significant additional functionality for pre-processing inputs: for example, VIDE can work with volume- or magnitude-limited galaxy samples with arbitrary survey geometries, or dark matter particles or halo catalogs in a variety of common formats. It can also randomly subsample inputs and includes a Halo Occupation Distribution model for constructing mock galaxy populations. VIDE has been used for a wide variety of applications, from discovering a universal density profile to estimating primordial magnetic fields, and is publicly available at http://bitbucket.org/cosmicvoids/vide_public and http://www.cosmicvoids.net.	http://dx.doi.org/10.1017/S1743921316010516	cs	arxiv					0.0	
"DeepDIVA: A Highly-Functional Python Framework for Reproducible
  Experiments"	Michele Alberti	Vinaychandran Pondenkandath, Marcel Würsch, Rolf Ingold, Marcus Liwicki	2018-04-23 20:00:42	We introduce DeepDIVA: an infrastructure designed to enable quick and intuitive setup of reproducible experiments with a large range of useful analysis functionality. Reproducing scientific results can be a frustrating experience, not only in document image analysis but in machine learning in general. Using DeepDIVA a researcher can either reproduce a given experiment with a very limited amount of information or share their own experiments with others. Moreover, the framework offers a large range of functions, such as boilerplate code, keeping track of experiments, hyper-parameter optimization, and visualization of data and results. To demonstrate the effectiveness of this framework, this paper presents case studies in the area of handwritten document analysis where researchers benefit from the integrated functionality. DeepDIVA is implemented in Python and uses the deep learning framework PyTorch. It is completely open source, and accessible as Web Service through DIVAServices.	http://arxiv.org/abs/1805.00329v1	cs	arxiv					0.0	
Awkward Arrays in Python, C++, and Numba	Jim Pivarski	Peter Elmer, David Lange	2020-01-15 16:48:07	The Awkward Array library has been an important tool for physics analysis in Python since September 2018. However, some interface and implementation issues have been raised in Awkward Array's first year that argue for a reimplementation in C++ and Numba. We describe those issues, the new architecture, and present some examples of how the new interface will look to users. Of particular importance is the separation of kernel functions from data structure management, which allows a C++ implementation and a Numba implementation to share kernel functions, and the algorithm that transforms record-oriented data into columnar Awkward Arrays.	http://dx.doi.org/10.1051/epjconf/202024505023	cs	arxiv					0.0	
"The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a
  Focus on Reproducibility and Transferability"	Mehdi Ali	Hajira Jabeen, Charles Tapley Hoyt, Jens Lehman	2020-01-28 19:12:37	There is an emerging trend of embedding knowledge graphs (KGs) in continuous vector spaces in order to use those for machine learning tasks. Recently, many knowledge graph embedding (KGE) models have been proposed that learn low dimensional representations while trying to maintain the structural properties of the KGs such as the similarity of nodes depending on their edges to other nodes. KGEs can be used to address tasks within KGs such as the prediction of novel links and the disambiguation of entities. They can also be used for downstream tasks like question answering and fact-checking. Overall, these tasks are relevant for the semantic web community. Despite their popularity, the reproducibility of KGE experiments and the transferability of proposed KGE models to research fields outside the machine learning community can be a major challenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge graph embeddings that we have developed with a strong focus on reproducibility and transferability. The KEEN Universe currently consists of the Python packages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge EmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the community.	http://arxiv.org/abs/2001.10560v1	cs	arxiv					0.0	
JS-son -- A Lean, Extensible JavaScript Agent Programming Library	Timotheus Kampik	Juan Carlos Nieves	2020-03-10 13:27:59	A multitude of agent-oriented software engineering frameworks exist, most of which are developed by the academic multi-agent systems community. However, these frameworks often impose programming paradigms on their users that are challenging to learn for engineers who are used to modern high-level programming languages such as JavaScript and Python. To show how the adoption of agent-oriented programming by the software engineering mainstream can be facilitated, we provide a lean JavaScript library prototype for implementing reasoning-loop agents. The library focuses on core agent programming concepts and refrains from imposing further restrictions on the programming approach. To illustrate its usefulness, we show how the library can be applied to multi-agent systems simulations on the web, deployed to cloud-hosted function-as-a-service environments, and embedded in Python-based data science tools.	http://arxiv.org/abs/2003.04690v1	cs	arxiv					0.0	
Towards a Hardware DSL Ecosystem : RubyRTL and Friends	Jean-Christophe Le Lann	Hannah Badier, Florent Kermarrec	2020-04-21 09:34:49	For several years, hardware design has been undergoing a surprising revival: fueled by open source initiatives, various tools and architectures have recently emerged. This resurgence also involves new hardware description languages. Inspired by the Migen Python community, we present RubyRTL, a novel internal domain-specific language for hardware design embedded in the Ruby language. Ruby -- which is best known in the field of web design -- has proven to be an excellent solution for the design of such DSLs, because of its meta-programming features. This paper presents the main aspects of RubyRTL, along with illustrating examples. We also propose a language-neutral interchange format, named Sexpir, that allows to seamlessly exchange RTL designs between Migen Python DSL and RubyRTL. This paves the way for interactions between various agile communities in the field of open source hardware design.	http://arxiv.org/abs/2004.09858v1	cs	arxiv					0.0	
IntelliCode Compose: Code Generation Using Transformer	Alexey Svyatkovskiy	Shao Kun Deng, Shengyu Fu, Neel Sundaresan	2020-05-16 15:47:53	In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments.   In this paper, we introduce IntelliCode Compose $-$ a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, $C\#$, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook.   Our best model yields an average edit similarity of $86.7\%$ and a perplexity of 1.82 for Python programming language.	http://arxiv.org/abs/2005.08025v2	cs	arxiv					0.0	
Little Ball of Fur: A Python Library for Graph Sampling	Benedek Rozemberczki	Oliver Kiss, Rik Sarkar	2020-06-08 01:35:24	Sampling graphs is an important task in data mining. In this paper, we describe Little Ball of Fur a Python library that includes more than twenty graph sampling algorithms. Our goal is to make node, edge, and exploration-based network sampling techniques accessible to a large number of professionals, researchers, and students in a single streamlined framework. We created this framework with a focus on a coherent application public interface which has a convenient design, generic input data requirements, and reasonable baseline settings of algorithms. Here we overview these design foundations of the framework in detail with illustrative code snippets. We show the practical usability of the library by estimating various global statistics of social networks and web graphs. Experiments demonstrate that Little Ball of Fur can speed up node and whole graph embedding techniques considerably with mildly deteriorating the predictive value of distilled features.	http://arxiv.org/abs/2006.04311v2	cs	arxiv					0.0	
The jsRealB Text Realizer: Organization and Use Cases -- Revised version	Guy Lapalme	Aucun	2020-12-31 03:32:58	This paper describes the design principles behind jsRealB (Version 4.0), a surface realizer written JavaScript for English or French sentences from a specification inspired by the constituent syntax formalism but for which a dependency-based input notation is also available. jsRealB can be used either within a web page or as a node.js module. We show that the seemingly simple process of text realization involves many interesting implementation challenges in order to take into account the specifics of each language. jsRealB has a large coverage of English and French and has been used to develop realistic data-to-text applications and to reproduce existing literary texts and sentences from Universal Dependency annotations. Its source code and that of its applications are available on GitHub. The port of this approach to Python (pyrealb) is also presented.	http://arxiv.org/abs/2012.15425v2	cs	arxiv					0.0	
"T-NER: An All-Round Python Library for Transformer-based Named Entity
  Recognition"	Asahi Ushio	Jose Camacho-Collados	2022-09-09 15:00:38	Language model (LM) pretraining has led to consistent improvements in many NLP downstream tasks, including named entity recognition (NER). In this paper, we present T-NER (Transformer-based Named Entity Recognition), a Python library for NER LM finetuning. In addition to its practical utility, T-NER facilitates the study and investigation of the cross-domain and cross-lingual generalization ability of LMs finetuned on NER. Our library also provides a web app where users can get model predictions interactively for arbitrary text, which facilitates qualitative model evaluation for non-expert programmers. We show the potential of the library by compiling nine public NER datasets into a unified format and evaluating the cross-domain and cross-lingual performance across the datasets. The results from our initial experiments show that in-domain performance is generally competitive across datasets. However, cross-domain generalization is challenging even with a large pretrained LM, which has nevertheless capacity to learn domain-specific features if fine-tuned on a combined dataset. To facilitate future research, we also release all our LM checkpoints via the Hugging Face model hub.	http://dx.doi.org/10.18653/v1/2021.eacl-demos.7	cs	arxiv					0.0	
"NeuroEvo: A Cloud-based Platform for Automated Design and Training of
  Neural Networks using Evolutionary and Particle Swarm Algorithms"	Philip Schroeder	Aucun	2022-10-01 14:10:43	Evolutionary algorithms (EAs) provide unique advantages for optimizing neural networks in complex search spaces. This paper introduces a new web platform, NeuroEvo (neuroevo.io), that allows users to interactively design and train neural network classifiers using evolutionary and particle swarm algorithms. The classification problem and training data are provided by the user and, upon completion of the training process, the best classifier is made available to download and implement in Python, Java, and JavaScript. NeuroEvo is a cloud-based application that leverages GPU parallelization to improve the speed with which the independent evolutionary steps, such as mutation, crossover, and fitness evaluation, are executed across the population. This paper outlines the training algorithms and opportunities for users to specify design decisions and hyperparameter settings. The algorithms described in this paper are also made available as a Python package, neuroevo (PyPI: https://pypi.org/project/neuroevo/).	http://arxiv.org/abs/2210.00286v1	cs	arxiv					0.0	
"Robust Chauvenet Rejection: Powerful, but Easy to Use Outlier Detection
  for Heavily Contaminated Data Sets"	Nicholas Konz	Daniel E. Reichart	2023-01-19 01:10:51	In Maples et al. (2018) we introduced Robust Chauvenet Outlier Rejection, or RCR, a novel outlier rejection technique that evolves Chauvenet's Criterion by sequentially applying different measures of central tendency and empirically determining the rejective sigma value. RCR is especially powerful for cleaning heavily-contaminated samples, and unlike other methods such as sigma clipping, it manages to be both accurate and precise when characterizing the underlying uncontaminated distributions of data sets, by using decreasingly robust but increasingly precise statistics in sequence. For this work, we present RCR from a software standpoint, newly implemented as a Python package while maintaining the speed of the C++ original. RCR has been well-tested, calibrated and simulated, and it can be used for both one-dimensional outlier rejection and $n$-dimensional model-fitting, with or without weighted data. RCR is free to use for academic and non-commercial purposes, and the code, documentation and accompanying web calculator can be found and easily used online at https://github.com/nickk124/RCR	http://arxiv.org/abs/2301.07838v1	cs	arxiv					0.0	
"SWRC Fit and unsatfit for parameter determination of unsaturated soil
  properties"	Katsutoshi Seki	Aucun	2023-02-01 14:35:21	SWRC Fit and unsatfit are programs developed for determining parameters of the water retention and the unsaturated hydraulic conductivity functions of soils for analyzing water movement in the unsaturated soil. The SWRC Fit is a web application for drawing SWRC (soil water retention curves) of various soil hydraulic models from the measured data with just one click, available at https://purl.org/net/swrc/. The SWRC Fit depends on the Python library unsatfit that implements various types of soil hydraulic models to determine water retention and hydraulic conductivity parameters by nonlinear least-square optimization. The implemented models are classified as DF3 (Brooks and Corey, van Genuchten, Kosugi) models, DF4 (Fredlund, Fayer, Peters, bimodal-CH) models, and DF5 (bimodal) models by the degree of freedom of the water retention functions. Most of the hydraulic conductivity functions are derived from the water retention function and the general hydraulic conductivity function. A modified model to suppress extreme changes in hydraulic conductivity in the near-saturated range can be applied to any hydraulic model. The algorithm that was proved to work with various types of soils in Seki et al. (2023) is provided as the sample Python codes. This paper describes how to use SWRC Fit and unsatfit.	http://arxiv.org/abs/2302.00472v1	cs	arxiv					0.0	
"PyPoll: A python library automating mining of networks, discussions and
  polarization on Twitter"	Dimitrios Panteleimon Giakatos	Pavlos Sermpezis, Athena Vakali	2023-03-11 18:43:21	Today online social networks have a high impact in our society as more and more people use them for communicating with each other, express their opinions, participating in public discussions, etc. In particular, Twitter is one of the most popular social network platforms people mainly use for political discussions. This attracted the interest of many research studies that analyzed social phenomena on Twitter, by collecting data, analysing communication patterns, and exploring the structure of user networks. While previous works share many common methodologies for data collection and analysis, these are mainly re-implemented every time by researchers in a custom way. In this paper, we introduce PyPoll an open-source Python library that operationalizes common analysis tasks for Twitter discussions. With PyPoll users can perform Twitter graph mining, calculate the polarization index and generate interactive visualizations without needing third-party tools. We believe that PyPoll can help researchers automate their tasks by giving them methods that are easy to use. Also, we demonstrate the use of the library by presenting two use cases; the PyPoll visualization app, an online application for graph visualizing and sharing, and the Political Lighthouse, a Web portal for displaying the polarization in various political topics on Twitter.	http://arxiv.org/abs/2303.06478v1	cs	arxiv					0.0	
"MiSTree: a Python package for constructing and analysing Minimum
  Spanning Trees"	Krishna Naidoo	Aucun	2019-10-18 18:00:02	The minimum spanning tree (MST), a graph constructed from a distribution of points, draws lines between pairs of points so that all points are linked in a single skeletal structure that contains no loops and has minimal total edge length. The MST has been used in a broad range of scientific fields such as particle physics (to distinguish classes of events in collider collisions), in astronomy (to detect mass segregation in star clusters) and cosmology (to search for filaments in the cosmic web). Its success in these fields has been driven by its sensitivity to the spatial distribution of points and the patterns within. MiSTree, a public Python package, allows a user to construct the MST in a variety of coordinates systems, including Celestial coordinates used in astronomy. The package enables the MST to be constructed quickly by initially using a k-nearest neighbour graph (kNN, rather than a matrix of pairwise distances) which is then fed to Kruskal's algorithm to construct the MST. MiSTree enables a user to measure the statistics of the MST and provides classes for binning the MST statistics (into histograms) and plotting the distributions. Applying the MST will enable the inclusion of high-order statistics information from the cosmic web which can provide additional information to improve cosmological parameter constraints. This information has not been fully exploited due to the computational cost of calculating N-point statistics. MiSTree was designed to be used in cosmology but could be used in any field which requires extracting non-Gaussian information from point distributions. The source code for MiSTree is available on GitHub at https://github.com/knaidoo29/mistree	http://dx.doi.org/10.21105/joss.01721	cs	arxiv					0.0	
"AiiDAlab -- an ecosystem for developing, executing, and sharing
  scientific workflows"	Aliaksandr V. Yakutovich	Kristjan Eimre, Ole Schütt, Leopold Talirz, Carl S. Adorf, Casper W. Andersen, Edward Ditler, Dou Du, Daniele Passerone, Berend Smit, Nicola Marzari, Giovanni Pizzi, Carlo A. Pignedoli	2020-09-29 20:58:23	Cloud platforms allow users to execute tasks directly from their web browser and are a key enabling technology not only for commerce but also for computational science. Research software is often developed by scientists with limited experience in (and time for) user interface design, which can make research software difficult to install and use for novices. When combined with the increasing complexity of scientific workflows (involving many steps and software packages), setting up a computational research environment becomes a major entry barrier. AiiDAlab is a web platform that enables computational scientists to package scientific workflows and computational environments and share them with their collaborators and peers. By leveraging the AiiDA workflow manager and its plugin ecosystem, developers get access to a growing range of simulation codes through a python API, coupled with automatic provenance tracking of simulations for full reproducibility. Computational workflows can be bundled together with user-friendly graphical interfaces and made available through the AiiDAlab app store. Being fully compatible with open-science principles, AiiDAlab provides a complete infrastructure for automated workflows and provenance tracking, where incorporating new capabilities becomes intuitive, requiring only Python knowledge.	http://dx.doi.org/10.1016/j.commatsci.2020.110165	cs	arxiv					0.0	
"A scalable transient detection pipeline for the Australian SKA
  Pathfinder VAST survey"	Sergio Pintaldi	Adam Stewart, Andrew O'Brien, David Kaplan, Tara Murphy	2021-01-14 22:50:59	"The Australian Square Kilometre Array Pathfinder (ASKAP) collects images of the sky at radio wavelengths with an unprecedented field of view, combined with a high angular resolution and sub-millijansky sensitivities. The large quantity of data produced is used by the ASKAP Variables and Slow Transients (VAST) survey science project to study the dynamic radio sky. Efficient pipelines are vital in such research, where searches often form a `needle in a haystack' type of problem to solve. However, the existing pipelines developed among the radio-transient community are not suitable for the scale of ASKAP datasets.   In this paper we provide a technical overview of the new ""VAST Pipeline"": a modern and scalable Python-based data pipeline for transient searches, using up-to-date dependencies and methods. The pipeline allows source association to be performed at scale using the Pandas DataFrame interface and the well-known Astropy crossmatch functions. The Dask Python framework is used to parallelise operations as well as scale them both vertically and horizontally, by means of a cluster of workers. A modern web interface for data exploration and querying has also been developed using the latest Django web framework combined with Bootstrap."	http://arxiv.org/abs/2101.05898v2	cs	arxiv					0.0	
"Unsub Extender: a Python-based web application for visualizing Unsub
  data"	Eric Schares	Aucun	2021-09-01 16:21:10	This article introduces Unsub Extender, a free tool to help libraries analyze their Unsub data export files. Unsub is a collection development dashboard that gathers and forecasts journal-level usage metrics to provide academic libraries with deeper measurements than traditional cost-per-use. Unsub gives libraries richer and more nuanced data to analyze their subscriptions, but it does not include a way to easily visualize the complex and interrelated data points it provides. Unsub Extender (https://unsubextender.lib.iastate.edu) is a free Python-based web application that takes an Unsub export file and automates the creation of interactive plots and visualizations. The tool loads with example data to explore, and users upload their specific Unsub file to quickly populate the pre-made plots with actual data. Graphs are interactive, live-updating, and support zoom, click-and-drag, and hover. Filters are specified through sliders to model scenarios and focus on areas of interest. A drop-down menu allows users to change a journal's decision status, and graphs update automatically. After evaluating journals, users can export the modified dataset to save their decisions. Unsub Extender proposes best practice in analyzing the increasingly common Unsub export file. It simplifies the analysis, eliminates duplication of effort, and enables libraries worldwide to make better, more data-driven decisions.	http://dx.doi.org/10.1162/qss_a_00200	cs	arxiv					0.0	
ASAS-SN Sky Patrol V2.0	K. Hart	B. J. Shappee, D. Hey, C. S. Kochanek, K. Z. Stanek, L. Lim, S. Dobbs, M. Tucker, T. Jayasinghe, J. F. Beacom, T. Boright, T. Holoien, J. M. Joel Ong, J. L. Prieto, T. A. Thompson, D. Will	2023-04-07 18:00:07	The All-Sky Automated Survey for Supernovae (ASAS-SN) began observing in late-2011 and has been imaging the entire sky with nightly cadence since late 2017. A core goal of ASAS-SN is to release as much useful data as possible to the community. Working towards this goal, in 2017 the first ASAS-SN Sky Patrol was established as a tool for the community to obtain light curves from our data with no preselection of targets. Then, in 2020 we released static V-band photometry from 2013--2018 for 61 million sources. Here we describe the next generation ASAS-SN Sky Patrol, Version 2.0, which represents a major progression of this effort. Sky Patrol 2.0 provides continuously updated light curves for 111 million targets derived from numerous external catalogs of stars, galaxies, and solar system objects. We are generally able to serve photometry data within an hour of observation. Moreover, with a novel database architecture, the catalogs and light curves can be queried at unparalleled speed, returning thousands of light curves within seconds. Light curves can be accessed through a web interface (http://asas-sn.ifa.hawaii.edu/skypatrol/) or a Python client (https://asas-sn.ifa.hawaii.edu/documentation). The Python client can be used to retrieve up to 1 million light curves, generally limited only by bandwidth. This paper gives an updated overview of our survey, introduces the new Sky Patrol, and describes its system architecture. These results provide significant new capabilities to the community for pursuing multi-messenger and time-domain astronomy.	http://arxiv.org/abs/2304.03791v1	cs	arxiv					0.0	
Data management and analysis with WRF and SFIRE	Jonathan Beezley	Mavin Martin, Paul Rosen, Jan Mandel, Adam K. Kochanski	2012-08-05 23:00:59	We introduce several useful utilities in development for the creation and analysis of real wildland fire simulations using WRF and SFIRE. These utilities exist as standalone programs and scripts as well as extensions to other well known software. Python web scrapers automate the process of downloading and preprocessing atmospheric and surface data from common sources. Other scripts simplify the domain setup by creating parameter files automatically. Integration with Google Earth allows users to explore the simulation in a 3D environment along with real surface imagery. Postprocessing scripts provide the user with a number of output data formats compatible with many commonly used visualization suites allowing for the creation of high quality 3D renderings. As a whole, these improvements build toward a unified web application that brings a sophisticated wildland fire modeling environment to scientists and users alike.	http://dx.doi.org/10.1109/IGARSS.2012.6352419	cs	arxiv					0.0	
Data-flow Analysis of Programs with Associative Arrays	David Hauzar	Jan Kofroň, Pavel Baštecký	2014-05-06 00:54:14	Dynamic programming languages, such as PHP, JavaScript, and Python, provide built-in data structures including associative arrays and objects with similar semantics-object properties can be created at run-time and accessed via arbitrary expressions. While a high level of security and safety of applications written in these languages can be of a particular importance (consider a web application storing sensitive data and providing its functionality worldwide), dynamic data structures pose significant challenges for data-flow analysis making traditional static verification methods both unsound and imprecise. In this paper, we propose a sound and precise approach for value and points-to analysis of programs with associative arrays-like data structures, upon which data-flow analyses can be built. We implemented our approach in a web-application domain-in an analyzer of PHP code.	http://dx.doi.org/10.4204/EPTCS.150.6	cs	arxiv					0.0	
"Toyz: A Framework for Scientific Analysis of Large Datasets and
  Astronomical Images"	Fred Moolekamp	Eric Mamajek	2015-06-30 04:21:29	As the size of images and data products derived from astronomical data continues to increase, new tools are needed to visualize and interact with that data in a meaningful way. Motivated by our own astronomical images taken with the Dark Energy Camera (DECam) we present Toyz, an open source Python package for viewing and analyzing images and data stored on a remote server or cluster. Users connect to the Toyz web application via a web browser, making it an convenient tool for students to visualize and interact with astronomical data without having to install any software on their local machines. In addition it provides researchers with an easy-to-use tool that allows them to browse the files on a server and quickly view very large images ($>$ 2 Gb) taken with DECam and other cameras with a large FOV and create their own visualization tools that can be added on as extensions to the default Toyz framework.	http://dx.doi.org/10.1016/j.ascom.2015.10.001	cs	arxiv					0.0	
Cross-platform validation and analysis environment for particle physics	S. V. Chekanov	I. Pogrebnyak, D. Wilbern	2015-10-20 21:45:53	A multi-platform validation and analysis framework for public Monte Carlo simulation for high-energy particle collisions is discussed. The front-end of this framework uses the Python programming language, while the back-end is written in Java, which provides a multi-platform environment that can be run from a web browser and can easily be deployed at the grid sites. The analysis package includes all major software tools used in high-energy physics, such as Lorentz vectors, jet algorithms, histogram packages, graphic canvases, and tools for providing data access. This multi-platform software suite, designed to minimize OS-specific maintenance and deployment time, is used for online validation of Monte Carlo event samples through a web interface.	http://dx.doi.org/10.1016/j.cpc.2017.06.017	cs	arxiv					0.0	
Scholia and scientometrics with Wikidata	Finn Årup Nielsen	Daniel Mietchen, Egon Willighagen	2017-03-13 01:50:48	Scholia is a tool to handle scientific bibliographic information in Wikidata. The Scholia Web service creates on-the-fly scholarly profiles for researchers, organizations, journals, publishers, individual scholarly works, and for research topics. To collect the data, it queries the SPARQL-based Wikidata Query Service. Among several display formats available in Scholia are lists of publications for individual researchers and organizations, publications per year, employment timelines, as well as co-author networks and citation graphs. The Python package implementing the Web service is also able to format Wikidata bibliographic entries for use in LaTeX/BIBTeX.	http://arxiv.org/abs/1703.04222v2	cs	arxiv					0.0	
"CyberChair: A Web-Based Groupware Application to Facilitate the Paper
  Reviewing Process"	Richard van de Stadt	Aucun	2012-06-08 18:19:01	In this paper we describe CyberChair, a web-based groupware application that supports the review process for technical contributions to conferences. CyberChair deals with most administrative tasks that are involved in the review process, such as storing author information, abstracts, (camera-ready) papers and reviews. It generates several overviews based on the reviews which support the Program Committee (PC) in selecting the best papers. CyberChair points out conflicting reviews and offers the reviewers means to easily communicate to solve these conflicts. In his paper Identify the Champion, O. Nierstrasz describes this review process in terms of a pattern language. CyberChair supports PCs by using these patterns in its implementation.	http://arxiv.org/abs/1206.1833v1	cs	arxiv					0.0	
"The Recent Developmental Status of SNEGRAF: a Web-Based Gravitational
  Wave Signal Analyzer"	Satoshi Eguchi	Shota Shibagaki, Kazuhiro Hayama, Kei Kotake	2019-12-18 12:51:43	"Unveiling physical processes in a supernova is one of challenging topics of modern physics and astrophysics since that event is due to particle physics on a stellar scale and tightly related to nucleosynthesis in Universe. Multi-messenger astronomy, a combination, such as of electromagnetic-wave, gravitational-wave, and neutrino observations, will be a breakthrough to the puzzle. To boost the research, we released a web-based gravitational wave signal analyzer ""SuperNova Event Gravitational-wave-display in Fukuoka (SNEGRAF)"" last year (Eguchi et al. 2019). We are now working on an integration of the application with the RIDGE pipeline, which is for a coherent network analysis between the LIGO, VIRGO, and KAGRA observations (Hayama et al. 2007), and implemented in MATLAB. In the basic design phase, we decided to wrap RIDGE with a simple Python script and make it listen for connections from SNEGRAF. This design enables these two programs to be hosted on different servers independently, and minimizes the cyber risks of RIDGE. In this paper, we report the current developmental status of our system."	http://arxiv.org/abs/1912.08571v1	cs	arxiv					0.0	
Neural Transition-based Parsing of Library Deprecations	Petr Babkin	Nacho Navarro, Salwa Alamir, Sameena Shah	2022-12-23 20:48:33	This paper tackles the challenging problem of automating code updates to fix deprecated API usages of open source libraries by analyzing their release notes. Our system employs a three-tier architecture: first, a web crawler service retrieves deprecation documentation from the web; then a specially built parser processes those text documents into tree-structured representations; finally, a client IDE plugin locates and fixes identified deprecated usages of libraries in a given codebase. The focus of this paper in particular is the parsing component. We introduce a novel transition-based parser in two variants: based on a classical feature engineered classifier and a neural tree encoder. To confirm the effectiveness of our method, we gathered and labeled a set of 426 API deprecations from 7 well-known Python data science libraries, and demonstrated our approach decisively outperforms a non-trivial neural machine translation baseline.	http://arxiv.org/abs/2212.12584v1	cs	arxiv					0.0	
Starfyre - A Python Web Framework for creating frontend web applications	stealthanthrax	Aucun	2023-05-08 11:03:54	Hey Everyone! 👋   Over the past two months, I've been hard at work developing a new Python frontend web framework, and I'm excited to announce its first minimal release: Starfyre.   Starfyre is a Python web framework designed to simplify front-end web application development. Starfyre offers a user-friendly and powerful solution for crafting dynamic web applications by seamlessly bridging back-end and front-end development in the Python ecosystem. By unlocking untapped potential in Python front-end development, Starfyre empowers developers to create engaging and interactive applications easily.  Some of the key features are:   \- Single-file reactive components   \- Built-in state management    \- Server-side rendering   \- PyML, a custom JSX-like language   \- Support for both client-side and server-side Python   \- Integrated CSS and HTML support   \- Ability to write JavaScript if need be   \- Familiar syntax and easy learning curve  You can check out the project at [https://github.com/sansyrox/starfyre](https://github.com/sansyrox/starfyre)   I have also created a blog to explain the future visions - [https://sanskar.wtf/posts/hello-starfyre](https://sanskar.wtf/posts/hello-starfyre)   Most importantly, you can find an example app on GitHub([https://github.com/sansyrox/first-starfyre-app](https://github.com/sansyrox/first-starfyre-app)).   Feel free to share your thoughts and suggestions! I'm all ears and can't wait to hear what you all think! 😄	https://www.reddit.com/r/Python/comments/13bloxf/starfyre_a_python_web_framework_for_creating/		reddit	13bloxf	Python	438.0	438.0	104.0	Intermediate Showcase
Python Web Framework	tarsild	Aucun	2023-10-28 16:00:11	"Esmerald Web Framework  Hi,  I came to share a python web framework called Esmerald.   Esmerald was created more than an year ago and no marketing was created for it as the purpose was and always will be to be free. It was born out a need to simplify some processes and design with business in mind.  I know what you might be thinking ""another framework and we already have FastAPI"". Well, Esmerald is different from FastAPI in many ways and doesn't even try to address the same issues FastAPI first attempted and there is no ""competition"" since we are a community where we try to grow and help each other 🙂.  The reason for reaching out is to ask of you would like to go to the GitHub, have a look, play around and even if you want, contribute and help Esmerald becoming even better.   There are already institutions using it (I know this because I worked for one big institution where Esmerald was adopted) and it's great the feedback we received and people contributions for the growth and adoption of an alternative to what we currently have.  Every help counts and every feedback is important.   I truly appreciate the kindness and apologies for the long text.   Link to GitHub repo: [Github](https://github.com/dymmond/esmerald)  Link to docs: [Docs](https://esmerald.dev).  Apologies if it previously posted on the wrong subreddit but it was a confusion caused by one of the suggestions.  I hope this is not breaking any rule."	https://www.reddit.com/r/Python/comments/17igspt/python_web_framework/		reddit	17igspt	Python	82.0	82.0	44.0	Discussion
I made a Python web scraping guide for beginners	brendanmartin	Aucun	2018-11-30 11:39:30	I've been web scraping professionally for a few years and decided to make a series of web scraping tutorials that I wish I had when I started.  The series will follow a large project I'm building that analyzes political rhetoric in the news.  Part 1 is about collecting media bias data: https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/  I would really like to improve the article and give new Python learners 100% of what they need, so please feel free to let me know your thoughts.	https://www.reddit.com/r/learnprogramming/comments/a1rp7c/i_made_a_python_web_scraping_guide_for_beginners/		reddit	a1rp7c	learnprogramming	2190.0	2190.0	150.0	
Using Figma for Front-End Python Web Apps?	Alyx1337	Aucun	2023-10-06 14:36:20	Hey guys!  I work for [Taipy](https://github.com/Avaiga/taipy). We are an open-source Python library to make full web apps using Python only. We need your feedback on a potential feature: would you use [Figma](https://www.figma.com/) to design the front end of a Python app?  Our idea is to create a way to convert the Figma front-end into our framework's front-end so you can design the front-end in Figma and code the backend in Python. Before working on it, we need to know if devs would be interested in such a feature since it would be a significant workload.  Designing the front end in Taipy uses a Markdown syntax with some default styling and optional CSS. Using Figma is easier but would devs go and learn an external tool to design Front-End?  Thoughts?  &#x200B;  https://i.redd.it/g6g0i7fjflsb1.gif	https://www.reddit.com/r/Python/comments/171dyn9/using_figma_for_frontend_python_web_apps/		reddit	171dyn9	Python	104.0	104.0	49.0	Discussion
Pynecone: Web Apps in Pure Python	Boordman	Aucun	2022-12-09 15:49:58	Hello, we just launched the alpha release of [Pynecone](https://github.com/pynecone-io/pynecone) \- a way to build full-stack web apps in pure Python. The framework is easy to get started with even without previous web dev experience and is completely open source / free to use.  We made Pynecone for Python devs who want to make web apps, but don’t want the overhead of having to learn or use Javascript. We wanted more flexibility than existing Python frameworks like Streamlit/Dash that don't allow the user to make real, customizable web apps.  With Pynecone, you can make anything from a small data science/python project to a full-scale, multi page web app. (We built our [whole website](https://pynecone.io) and docs with Pynecone). We have over 60+ built-in components and are adding more.  [Here is an example of a Dalle Pynecone App created in \~50 lines of Python \(see Github link for code\).](https://i.redd.it/n3ppd9g98w4a1.gif)  We are actively trying to grow this project so no matter you skill level we welcome contributions! Open up an issue if you find missing features/bugs or contribute to existing issue. Star us on [GitHub](https://github.com/pynecone-io/pynecone) if you want to follow our progress as new updates come!	https://www.reddit.com/r/Python/comments/zh0pmy/pynecone_web_apps_in_pure_python/		reddit	zh0pmy	Python	640.0	640.0	198.0	Intermediate Showcase
Favorite Python Web Framework	AMDataLake	Aucun	2022-04-08 12:52:57	Django FastAPI Flask Masonite Bottle …other?  Also discuss why	https://www.reddit.com/r/Python/comments/tz2v7b/favorite_python_web_framework/		reddit	tz2v7b	Python	115.0	115.0	111.0	Discussion
A Beginner’s Introduction to Python Web Frameworks	jstndds	Aucun	2019-08-16 08:41:03	Hi, we recently updated an article on Python web frameworks at our company blog. I was wondering if there are any other frameworks you find useful that we missed and should add to the list. I’m copying the entire list here (each entry also has some sample code, but I’m excluding that). Please let me know if you think we should add any framework.   (and, if you’d like to check out the full article, you can find it here: [A Beginner’s Introduction to Python Web Frameworks](https://stxnext.com/blog/2018/09/27/beginners-introduction-python-frameworks/?utm_medium=social&utm_source=reddit&utm_campaign=2019-08-jd))  ## Django  **The most popular Python framework is Django, hands down.** Django’s trademark is that it offers all the tools you need to build a web application within a single package, from low- to high-end.  Django applications are based on a design pattern similar to MVC, the so-called MVT (Model-View-Template) pattern. Models are defined using the Django ORM, while SQL databases are mainly used as storage.  Django has a built-in admin panel, allowing for easy management of the database content. With minimal configuration, this panel is generated automatically based on the defined models.  Views can include both functions and classes, and the assignment of URLs to views is done in one location (the urls.py file), so that after reviewing that single file you can learn which URLs are supported. Templates are created using a fairly simple Django Templates system.  Django is praised for strong community support and detailed documentation describing the functionality of the framework. This documentation coupled with getting a comprehensive environment after the installation makes the entry threshold rather low. Once you go through [the official tutorial](https://docs.djangoproject.com/en/1.11/intro/tutorial01/), you’ll be able to do most of the things required to build an application.  **Unfortunately, Django’s monolithism also has its drawbacks.** It is difficult, though not impossible, to replace one of the built-in elements with another implementation. For example, using some other ORM (like SQLAlchemy) requires abandoning or completely rebuilding such items as the admin panel, authorization, session handling, or generating forms.  Because Django is complete but inflexible, it is suitable for standard applications (i.e. the vast majority of software projects). However, if you need to implement some unconventional design, it leads to struggling with the framework, rather than pleasant programming.  ## Flask  Flask is considered a microframework. It comes with basic functionality, while also allowing for easy expansion. Therefore, **Flask works more as the glue that allows you to join libraries with each other.**  For example, “pure Flask” does not provide support for any storage, yet there are many different implementations that you can install and use interchangeably for that purpose (such as Flask-SQLAlchemy, Flask-MongoAlchemy, and Flask-Redis). Similarly, the basic template system is Jinja2, but you can use a replacement (like Mako).  The motto of this framework is “one drop at a time,” and this is reflected in its comprehensive documentation. The knowledge of how to build an application is acquired in portions here; after reading a few paragraphs, you will be able to perform basic tasks.  You don’t have to know the more advanced stuff right away—you’ll learn it once you actually need it. Thanks to this, students of Flask can gather knowledge smoothly and avoid boredom, making Flask suitable for learning.  **A large number of Flask extensions, unfortunately, are not supported as well as the framework itself.** It happens quite often that the plug-ins are no longer being developed or their documentation is outdated. In cases like these, you need to spend some time googling a replacement that offers similar functionality and is still actively supported.  When building your application with packages from different authors, you might have to put quite a bit of sweat into integrating them with each other. You will rarely find ready-made instructions on how to do this in the plug-ins’ documentation, but in such situations the Flask community and websites such as Stack Overflow should be of help.  ## Pyramid  Pyramid, the third noteworthy Python web framework, is rooted in two other products that are no longer developed: Pylons and repoze.bfg. **The legacy left by its predecessors caused Pyramid to evolve into a very mature and stable project.**  The philosophies of Pyramid and Django differ substantially, even though both were released in the same year (2005). Unlike Django, Pyramid is trivial to customize, allowing you to create features in ways that the authors of the framework themselves hadn’t foreseen. It does not force the programmer to use framework’s idioms; it’s meant to be a solid scaffolding for complex or highly non-standard projects.  Pyramid strives to be persistence-agnostic. While there is no bundled database access module, a common practice is to combine Pyramid with the powerful, mature SQLAlchemy ORM. Of course, that’s only the most popular way to go. Programmers are free to choose whatever practices suit them best, such as using the peewee ORM, writing raw SQL queries, or integrating with a NoSQL database, just to name a few.  All options are open, though this approach requires a bit of experience to smoothly add the desired persistence mechanisms to the project. The same goes for other components, such as templating.  Openness and freedom are what Pyramid is all about. Modules bundled with it relate to the web layer only and users are encouraged to freely pick third-party packages that will support other aspects of their projects.  **However, this model causes a noticeable overhead at the beginning of any new project,**because you have to spend some time choosing and integrating the tools your team is comfortable with. Still, once you put the effort into making additional decisions during the early stages of the work, you are rewarded with a setup that makes it easy and comfortable to start a new project and develop it further.  Pyramid is a self-proclaimed “start small, finish big, stay finished framework.” This makes it an appropriate tool for experienced developers who are not afraid of playing the long game and working extra hard in the beginning, without shipping a single feature within the first few days. Less experienced programmers may feel a bit intimidated.  ## web2py  Created in 2007, web2py is a framework originally designed as a teaching tool for students, so the main concern for its authors was ease of development and deployment.  Web2py is strongly inspired by Django and Ruby on Rails, sharing the idea of **convention over configuration. In other words, web2py provides many** ***sensible defaults*** **that allow developers to get off the ground quickly.**  This approach also means there are a lot of goodies bundled with web2py. You will find everything you’d expect from a web framework in it, including a built-in server, HTML-generating helpers, forms, validators, and many more—nothing unusual thus far, one could argue. Support for multiple database engines is neat, though it’s a pretty common asset among current web frameworks.  However, some other bundled features may surprise you, since they are not present in other frameworks:  * helpers for creating [JavaScript](https://stxnext.com/services/javascript-development/)\-enabled sites with jQuery and Ajax; * scheduler and cron; * 2-factor authentication helpers; * text message sender; * an event-ticketing system, allowing for automatic assignment of problems that have occurred in the production environment to developers.  The framework proudly claims to be a full-stack solution, providing everything you could ever need.  Web2py has extensive documentation available online. It guides newcomers step by step, starting with a short introduction to the Python language. The introduction is seamlessly linked with the rest of the manual, demonstrating different aspects of web2py in a friendly manner, with lots of code snippets and screenshots.  **Despite all its competitive advantages, web2py’s community is significantly smaller than Django’s, or even Pyramid’s.** Fewer developers using it means your chances of getting help and support are lower. The official mailing list is mostly inactive.  Additionally—and unfortunately—web2py is not compatible with Python 3 at the moment. This state of things puts the framework’s prospects into question, as support for Python 2 ends in 2020. This issue is being addressed on the project’s github. [Here](https://github.com/web2py/web2py/issues/1353) is where you can track the progress.  ## Sanic  **Sanic differs considerably from the aforementioned frameworks because unlike them, it is based on asyncio**—Python’s toolbox for asynchronous programming, bundled with the standard library starting from version 3.4.  In order to develop projects based on Sanic, you have to grasp the ideas behind asyncio first. This involves a lot of theoretical knowledge about coroutines, concurrent programming caveats, and careful reasoning about the data flow in the application.  Once you get your head around Sanic/asyncio and applies the framework to an appropriate problem, the effort pays off. Sanic is especially useful when it comes to handling long-living connections, such as websockets. If your project requires support for websockets or making a lot of long-lasting external API calls, Sanic is a great choice.  Another use case of Sanic is writing a “glue-web application” that can serve as a mediator between two subsystems with incompatible APIs. Note that it requires at least Python 3.5, though.  The framework is meant to be very fast. One of its dependencies is [uvloop](https://github.com/MagicStack/uvloop)—an alternative, drop-in replacement for asyncio’s not-so-good built-in event loop. Uvloop is a wrapper around libuv, the same engine that powers Node.js. According to the uvloop documentation, this makes asyncio work 2–4 times faster.  **In terms of “what’s in the box,” Sanic doesn’t offer as much as other frameworks.** It is a microframework, just like Flask. Apart from routing and other basic web-related goodies like utilities for handling cookies and streaming responses, there’s not much inside. Sanic imitates Flask, for instance by sharing the concept of Blueprints—tiny sub-applications that allow developers to split and organize their code in bigger applications.  Sanic also won’t be a good choice for simple CRUD applications that only perform basic database operations. It would just make them more complicated with no visible benefit.  ## Japronto  Have you ever imagined handling 1,000,000 requests per second with Python?  It seems unreal, since Python isn’t the fastest programming language out there. But when a brilliant move was made to add asyncio to the standard library, it opened up countless possibilities.  Japronto is a microframework that leverages some of them. As a result, **this Python framework was able to cross the magical barrier of 1 million requests handled per second.**  You may still be at a loss as to how that is possible, exactly.  It all comes down to 2 aces up Japronto’s sleeve: uvloop and PicoHTTPParser. Uvloop is an asyncio backend based on libuv, while PicoHTTPParser is a lightweight HTTP headers parser written in C. All core components of the framework are also implemented in C. A wide variety of low-level optimizations and tricks are used to tweak performance.  Japronto is designed for special tasks that could not be accomplished with bloated mainstream frameworks. It is a perfect fit for problems where every nanosecond counts. Knowledgeable developers, obsessed with optimization, will reap all of its possible benefits.  Additionally, Japronto is meant to provide a solid foundation for microservices using REST APIs with minimal overhead. In other words, there’s not much in the box. Developers only need to set up routing and decide which routes should use synchronous or asynchronous handlers.  It might seem counterintuitive, but if a request can be handled in a synchronous way, you shouldn’t try to do it asynchronously, as the overhead of switching between coroutines will limit performance.  **What is quite unfortunate is that Japronto is not being actively developed.** On the other hand, the project is licensed under MIT, and the author claims he is willing to accept any contributions. Like Sanic, the framework is meant to work with Python 3.5+ versions.  ## aiohttp  Aiohttp is another library based on asyncio, the modern Python toolkit for writing asynchronous code. **Not meant to be a framework in a strict sense, aiohttp is more of a toolbox, supplementing the async arsenal with everything related to HTTP.**  This means aiohttp is helpful not only for writing server applications, but also to clients. Both will benefit from asyncio’s goodies, most of all the ability to handle thousands of connections at the same time, provided the majority of operations involves I/O calls.  Such powerful clients are great when you have to issue many API calls at once, for example for scraping web pages. Without asyncio, you would have to use threading or multiprocessing, which are harder to get right and require much more memory.  Apart from building standalone applications, aiohttp’s clients are a great supplement to any asyncio-based application that needs to issue non-blocking HTTP calls. The same is true for websockets. Since they are part of the HTTP specification, you can connect to websocket servers and easily exchange messages with them.  When it comes to servers, aiohttp gives you everything you can expect from a microframework. The features available out-of-the-box include routing, middleware, and signals. It may seem like it’s very little, but it will suffice for a web server.  “What about the remaining functionalities?” you may ask.  As far as those are concerned, you can build the rest of the functionalities using one or many asyncio-compatible libraries. You will find plenty of them using sources [like this one](https://github.com/timofurrer/awesome-asyncio).  Aiohttp is built with testing in mind. Developers who want to test an aiohttp-based application will find it extremely easy, especially with the aid of pytest.  Even though aiohttp offers satisfactory performance by default, there are a few low-hanging fruits you can pick. For example, you can install additional libraries: cchardet and aiodns. Aiohttp will detect them automatically. You can also utilize the same uvloop that powers Sanic.  Last but not least: **one definite advantage of aiohttp is that it is being actively maintained and developed.** Choosing aiohttp when you build your next application will certainly be a good call.  ## Twisted  With Twisted, Python developers were able to do async programming long before it was cool. Twisted is one of the oldest and most mature Python projects around.  Originally released in 2002, Twisted predates even PEP8, so the code of the project does not follow the famous code style guide recommendations. Admittedly, this may somewhat discourage people from using it these days.  Twisted’s heart is an event-driven networking engine called reactor. It is used for scheduling and calling user-defined callbacks.  In the beginning, developers had to use explicit callbacks by defining functions and passing them around separately for cases when an operation succeeded and when it failed.  Although this technique was compelling, it could also lead to what we know from early JavaScript: callback hell. In other words, the resultant code was tough to read and analyze.  **At some point, Twisted introduced inlineCallbacks—the notation for writing asynchronous code that was as simple to read as regular, synchronous code.** This solution played very well with Python’s syntax and greatly influenced modern async toolkit from the standard library, asyncio.  The greatest advantage of this framework is that although Twisted itself is just an engine with few bundled extensions, there are many additional extensions available to expand its functionality. They allow for both low-level network programming (TCP/USP) and high, application-level work (HTTP, IMAP, SHH, etc).  **This makes Twisted a perfect choice for writing specialized services; however, it is not a good candidate for regular web applications.** Developers would have to write a lot of things on their own to get the functionality they take for granted with Django.  Twisted is being actively maintained. There is an undergoing effort to migrate all of its code to be compatible with Python 3. The core functionality was rewritten some time ago, but many third-party modules are still incompatible with newer versions of the interpreter.  This may raise some concerns whether Twisted is the best choice for new projects. On the other hand, though, it is more mature than some asyncio-based solutions. Also, Twisted has been around for quite some time now, which means it will undoubtedly be maintained at least for a good while.  ## Falcon  Falcon is another microframework on our list. The goal of the Falcon project is to create a minimalist foundation for building web apps where the slightest overhead matters.  Authors of the framework claim it is a **bare-metal, bloat-free toolkit for building very fast backend code and microservices.** Plus, it is compatible with both Python 2 and 3.  A big advantage of Falcon is that it is indeed very fast. Benchmarks published on its website show an incredible advantage over mainstream solutions like Django or Flask.  The downside, though, is that **Falcon offers very little to start with.** There’s routing, middlewares, hooks—and that’s basically everything. There are no extras: no validation, no authentication, etc. It is up to the developer to extend functionality as needed.  Falcon assumes it will be used for building REST APIs that talk JSON. If that is the case, you really need literally zero configuration. You can just sit down and code.  This microframework might be an exciting proposition for implementing highly-customized services that demand the highest performance possible. Falcon is an excellent choice when you don’t want or can’t invest in asyncio-based solutions.  If you’re thinking, “Sometimes the simplest solution is the best one,” you should definitely consider Falcon.  ## API Star  API Star is the new kid on the block. It is yet another microframework, but this one is compatible with Python 3 only. Which is not surprising, because it leverages type hints introduced in Python 3.5.  **API Star uses type hints as a notation for building validation schemata in a concise, declarative way.** Such a schema (called a “Type” in the framework’s terminology) can then be bound to request a handling function.  Additionally, API Star features automatically generated API docs. They are compatible with OpenAPI 3. Such docs can facilitate communication between API authors and its consumers, i.e. frontend developers. If you use the Types we’ve mentioned, they are included in the API docs.  Another outstanding feature is the dependency injection mechanism. It appears to be an alternative to middlewares, but smarter and much more powerful.  For example, you can write a so-called Component that will provide our views with a currently authenticated User. On the view level, you have to explicitly state that it will require a User instance.  The rest happens behind the scenes. API Star resolves which Components have to be executed to finally run our view with all the required information.  The advantage that automatic dependency injection has over regular middlewares is that Components do not cause any overhead for the views where they are not used.  Last but not least, API Star can also be run atop asyncio in a more traditional, synchronous, WSGI-compliant way. **This makes it probably the only popular framework in the Python world capable of doing that.**  The rest of the goodies bundled with API Star are pretty standard: optional support for templating with jinja2, routing, and event hooks.  All in all, API Star looks extremely promising. At the time of writing, it has over 4,500 stars in its GitHub repository. The repository already has a few dozen contributors, and pull requests are merged daily. Many of us at STX Next are keeping our fingers crossed for this project!  ## Other Python web development frameworks  There are many more Python web frameworks out there you might find interesting and useful. Each of them focuses on a different issue, was built for distinct tasks, or has a particular history.  The first that comes to mind is **Zope2,** one of the oldest frameworks, still used mainly as part of the Plone CMS. **Zope3** (later renamed BlueBream) was created as Zope2’s successor. The framework was supposed to allow for easier creation of large applications, but hasn’t won too much popularity, mainly because of the need to master fairly complex concepts (e.g. Zope Component Architecture) very early in the learning process.  Also noteworthy is the **Google App Engine,** which allows you to run applications written in Python, among others. This platform lets you create applications in any framework compatible with WSGI. The SDK for the App Engine includes a simple framework called webapp2, and this exact approach is often used in web applications adapted to this environment.  Another interesting example is **Tornado,** developed by FriendFeed and made available by Facebook. This framework includes libraries supporting asynchronicity, so you can build applications that support multiple simultaneous connections (like long polling or WebSocket).  Other libraries similar to Tornado include **Pulsar** (async) and **Gevent** (greenlet). These libraries allow you to build any network applications (multiplayer games and chat rooms, for example). They also perform well at handling HTTP requests.  Developing applications using these frameworks and libraries is more difficult and requires you to explore some harder-to-grasp concepts. We recommend getting to them later on, as you venture deeper into the wonderful world of Python.  \----------------  This is the full list we came up with. Thanks for reading; let me know what you think!	https://www.reddit.com/r/Python/comments/cr3l7z/a_beginners_introduction_to_python_web_frameworks/		reddit	cr3l7z	Python	773.0	773.0	76.0	
I made a way to build Web Apps in pure Python: Pynecone	Pleasant-Cow-3898	Aucun	2022-12-09 15:56:11		https://github.com/pynecone-io/pynecone		reddit	zh0uov	programming	885.0	885.0	160.0	
Python web scraping bot detection evasion techniques	Lower-Imagination655	Aucun	2022-07-27 09:49:41	Nice guide posted on level-up-coding, this will spare you headaches going forward -   [https://levelup.gitconnected.com/web-scraping-and-the-art-of-war-5-tools-that-will-help-your-bot-win-c2a3840d8b71](https://levelup.gitconnected.com/web-scraping-and-the-art-of-war-5-tools-that-will-help-your-bot-win-c2a3840d8b71)	https://www.reddit.com/r/learnpython/comments/w9agwg/python_web_scraping_bot_detection_evasion/		reddit	w9agwg	learnpython	242.0	242.0	52.0	
Python web scraping video?!	3dPrintMyThingi	Aucun	2023-10-22 20:15:57	Am looking for a youtube video and i understand there are loads but thats the problem. I want to scrap a website which has products title and link. You click on the link and it takes you to the products main page where i want to scrap product info and description and part number...so really need a video explaining how to build a scraper that will go to each links and scrap the necessary information..is there a specific youtube video which explains this?!	https://www.reddit.com/r/webscraping/comments/17e26oq/python_web_scraping_video/		reddit	17e26oq	webscraping	2.0	2.0	3.0	
Studying: CS50 Web Programming with Python	zelfmoordjongens	Aucun	2023-08-29 19:37:13	I already know like 80% but I'm refreshing it since I have mostly done some front end work lately.	https://i.redd.it/gcp1xw9rq3lb1.jpg		reddit	164s1za	cs50	85.0	85.0	81.0	web track
Six months into Python and Data science, my first Dashboard Web App with covid19 data using python only	mrgadgety	Aucun	2020-04-22 10:21:30		https://v.redd.it/mlqov8dbicu41		reddit	g5ymoy	Python	1730.0	1730.0	139.0	I Made This
Web Scraping 1010 with Python	sbskell	Aucun	2020-09-01 14:43:33		https://www.scrapingbee.com/blog/web-scraping-101-with-python/		reddit	ikliwj	Python	951.0	951.0	102.0	Resource
Web Scraping 101 in Python	pijora	Aucun	2019-08-23 15:06:33		https://www.freecodecamp.org/news/web-scraping-101-in-python/		reddit	cuf4q5	programming	1121.0	1121.0	113.0	
Reflex VS Taipy ? (100% Python Web Frameworks)	hootsh_1337	Aucun	2023-10-22 16:47:56	Hello! :)  I was reading about entirely Python-based web frameworks, and came across a new one called Taipy, I know it's supposed to be better than Streamlit in terms of it's ability to provide more options for the developer, while sacrificing some of Streamlit's ease-of-use. I've tried Streamlit before, so it seemed like Taipy devs actually have a point there, and they do mention pros/cons vs Streamlit in their YT presentations.  But I was wondering how it compares to Reflex (previously Pynecone) ..  Have anyone tried both Reflex and Taipy to make web apps? Did anything stand out?  I'm really curious about the difference between the two, any help is appreciated. Thank you <3	https://www.reddit.com/r/Python/comments/17dxl5b/reflex_vs_taipy_100_python_web_frameworks/		reddit	17dxl5b	Python	4.0	4.0	12.0	Discussion
Python Web course recommendation in Udemy?	Nice-Comfortable-975	Aucun	2023-10-22 02:37:25	Any reco course for python web development sa Udemy or other sites? Thank you on advance.	https://www.reddit.com/r/PinoyProgrammer/comments/17dj79a/python_web_course_recommendation_in_udemy/		reddit	17dj79a	PinoyProgrammer	2.0	2.0	3.0	advice
Python Web scraping issue	Fun_Ambassador_6228	Aucun	2023-08-29 14:49:32	"I need to click ""CSV"" in li tag. Here I paste element of the page. Please help me to slove this issue.  <button \_ngcontent-cse-c383="""" type=""button"" id=""dropdownMenu2"" data-toggle=""dropdown"" aria-haspopup=""true"" aria-expanded=""true"" class=""dropdown-button dropdown-toggle""><i \_ngcontent-cse-c383="""" aria-hidden=""true "" class=""fa fa-download""></i> Download </button>      <ul \_ngcontent-cse-c383="""" aria-labelledby=""dropdownMenu2"" class=""dropdown-menu dropdown-right download""><li \_ngcontent-cse-c383=""""><a \_ngcontent-cse-c383="""">XLS</a></li>**<li \_ngcontent-cse-c383=""""><a \_ngcontent-cse-c383="""">CSV</a></li>**<li \_ngcontent-cse-c383=""""><a \_ngcontent-cse-c383="""">XML</a></li></ul>  &#x200B;"	https://www.reddit.com/r/learnpython/comments/164kix0/python_web_scraping_issue/		reddit	164kix0	learnpython	1.0	1.0	3.0	
Is learning Flask before Django or FastAPI a good way to introduce myself in Python Web Development?	eddyxide	Aucun	2023-02-10 11:28:52	I'm currently working as PHP Full Stack Intern, but I plan to work with Python someday. I already started a project to do a ToDo app in Flask to get introduced to the framework, am I doing a good choice to start learning Python Web Development for real?	https://www.reddit.com/r/Python/comments/10ypnnn/is_learning_flask_before_django_or_fastapi_a_good/		reddit	10ypnnn	Python	236.0	236.0	87.0	Discussion
I've created one of the Fastest Python web Frameworks!!	Conclusion-Striking	Aucun	2023-03-19 22:24:36	**Panther**   **Github**: [https://github.com/AliRn76/panther](https://github.com/AliRn76/panther)   **Documentation**: [https://pantherpy.github.io/](https://pantherpy.github.io/)     https://preview.redd.it/gtec70b1uroa1.png?width=831&format=png&auto=webp&s=0b6487e99b7b627016d3481ec43de0f9037e4ebd	https://www.reddit.com/r/Python/comments/11vzvde/ive_created_one_of_the_fastest_python_web/		reddit	11vzvde	Python	34.0	34.0	40.0	Discussion
Intro To Django Python Web Apps	webhelperapp	Aucun	2023-10-28 13:16:44		https://webhelperapp.com/intro-to-django-python-web-apps/		reddit	17idl32	Udemy	1.0	1.0	0.0	
Intro To Django Python Web Apps	Ordinary_Craft	Aucun	2023-10-28 13:16:01		https://webhelperapp.com/intro-to-django-python-web-apps/		reddit	17idkmh	udemyfreebies	1.0	1.0	0.0	
Intro To Django Python Web Apps	Ordinary_Craft	Aucun	2023-10-28 13:15:52		https://webhelperapp.com/intro-to-django-python-web-apps/		reddit	17idkik	FreeCourses_coupons	1.0	1.0	0.0	
Data Structures in Python Web Development	TheLostWanderer47	Aucun	2023-10-25 16:54:41		https://plainenglish.io/community/data-structures-in-python-web-development		reddit	17g9ebo	Python	2.0	2.0	0.0	Tutorial
Anyone interested in python/web app programming?	Nexus01_	Aucun	2023-09-10 14:16:00	Just want to chat	https://www.reddit.com/r/teenagers/comments/16f1d9k/anyone_interested_in_pythonweb_app_programming/		reddit	16f1d9k	teenagers	1.0	1.0	10.0	Discussion
Build and run your Python web scrapers in the cloud with Apify SDK for Python	fnesveda	Aucun	2023-03-14 15:23:14		https://github.com/apify/apify-sdk-python		reddit	11r9298	Python	127.0	127.0	20.0	Resource
Python web scrape	EdvinHolding	Aucun	2023-04-17 18:36:27	"Hi Guys. I am new in Discord, and have no idea how Python works. What i would want to develop is : Scrape Live every 10-15mins  Posts from Linkedin , Upwork, Reddit, and put them in Google Sheets.    For example i would like to scrape latest posts from Linkedin search ""Development"" , whatever post comes under that search to be scrapped and inserted in Google Sheets. Also for other platforms , customised search, and whatever comes on that search to be scrapped. I would need to scrape 2-3 things Heading, Description , and maybe one more thing. My questions is : can someone guide me or give me advice what and where would be the best way to make this, also is there any platform thats doing this? I am looking for the cheapest alternative."	https://www.reddit.com/r/learnpython/comments/12ps3z1/python_web_scrape/		reddit	12ps3z1	learnpython	1.0	1.0	9.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-18 05:54:50		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=40855&_unique_id=652f732a29711		reddit	17ajhfh	Udemy	1.0	1.0	0.0	
Graphs in Python web app	VidarOdinsson	Aucun	2023-03-28 12:56:01	"I'm developping my own AI model using Spacy and NLP to process, filter and link a lot of data then I'm using Matplotlib to make a graph of these links.  I also project to develop my own web application which I want to be public, maybe using Flask or Django (don't know yet which one would fit the better) but I especially find Matplotlib a bit ""rough and rustic"" graphically and it seems we can't implement interactive graphs made with this library in a web app (maybe I'm saying craps).  So I'm planning to use another library but I don't know any that could fit in my project. I just need to make co-occurrence graphs for now but I need ""scalibility"" in data processing (if it needs to be considered) and I'll probably need to make different kinds of graphs when I'll be more comfortable with data science. Obviously, I need the graphs to be graphically attractive for the users and interactive.  In your opinion, what library would be the most suitable for my project ?"	https://www.reddit.com/r/Python/comments/124nwhh/graphs_in_python_web_app/		reddit	124nwhh	Python	19.0	19.0	17.0	Discussion
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-18 05:54:53		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=40858&_unique_id=652f732d2dd01		reddit	17ajhgc	udemyfreebies	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-18 05:54:49		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=40854&_unique_id=652f732964194		reddit	17ajhf6	FreeUdemyCoupons	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-18 05:54:52		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=40857&_unique_id=652f732c65cba		reddit	17ajhg4	udemycoursedaily	1.0	1.0	0.0	
Python Web Scraping Delay	nrzOG	Aucun	2023-03-25 00:56:47	Web Scraping Headlines delay  I’m using python, beautiful soup (bs4) and requests to scrape headlines from an website within seconds when they appear in website.. here’s how i do it.  I modified script to check theblock.co/latest h2 div where (headlines) are and if a new headline appears i receive data (headline) via cmd immediately but someone else is scraping the same headline 20 seconds earlier than me..  Here is an screenshot that i compared seconds when i get data to cmd and someone’s terminal that scrapes same website/headline before me.  Link Screenshot “imgbb” https://ibb.co/19NpV1q  What could be the case and what it’s preventing me to scrape quicker.. Is Selenium/Scrapy faster than Beautiful Soup?  Or could it be that im using VPN to avoid getting blocked by site?  Looking forward to hear your opinions.	https://www.reddit.com/r/Python/comments/12159xu/python_web_scraping_delay/		reddit	12159xu	Python	11.0	11.0	12.0	Discussion
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-10-08 11:12:48		https://idownloadcoupon.com/udemy/1950/		reddit	172wm8f	udemyfreebies	1.0	1.0	0.0	Limited Time
Introducing JustPy: An object-oriented, component based, high-level Python Web Framework that requires no front-end programming. With a few lines of only Python code, you can create interactive websites without any JavaScript programming. Comes with a comprehensive tutorial	eli_mintz	Aucun	2020-02-10 13:56:34	"# JustPy  [JustPy Docs and Tutorials](https://justpy.io)  ## Introduction  JustPy is an object-oriented, component based, high-level Python Web Framework that requires no front-end programming. With a few lines of only Python code, you can create interactive websites without any JavaScript programming.  Unlike other web frameworks, JustPy has no front-end/back-end distinction. All programming is done on the back-end allowing a simpler, more productive, and more Pythonic web development experience. JustPy removes the front-end/back-end distinction by intercepting the relevant events on the front-end and sending them to the back-end to be processed.  In JustPy, elements on the web page are instances of component classes. A component in JustPy is a Python class that allows you to instantiate reusable custom elements whose functionality and design is encapsulated away from the rest of your code.  Custom components can be created using other components as building blocks. Out of the box, JustPy comes with support for [HTML](https://justpy.io/#/tutorial/html_components) and [SVG](https://justpy.io/#/tutorial/svg_components) components as well as more complex components such as [charts](https://justpy.io/#/charts_tutorial/introduction) and [grids](https://justpy.io/#/grids_tutorial/introduction).  It also supports most of the components and the functionality of the [Quasar](https://quasar.dev/) library of [Material Design 2.0](https://material.io/) components.  JustPy encourages creating your own components and reusing them in different projects (and, if applicable, sharing these components with others).  JustPy supports visualization using [matplotlib](https://justpy.io/#/tutorial/matplotlib) and [Highcharts](https://justpy.io/#/charts_tutorial/introduction).  JustPy integrates nicely with [pandas](https://pandas.pydata.org/) and simplifies building web sites based on pandas analysis. JustPy comes with a [pandas extension](https://justpy.io/#/charts_tutorial/pandas?id=using-the-pandas-extension) that makes it simple to create interactive charts and grids from pandas data structures.  For updates and news please follow the [JustPy Twitter account](https://twitter.com/justpyframework)  ## Hello World!      import justpy as jp          def hello_world():         wp = jp.WebPage()         d = jp.Div(text='Hello world!')         wp.add(d)         return wp              jp.justpy(hello_world)  The program above activates a web server that returns a web page with 'Hello world!' for any request. Locally, you would direct your browser to [http://127.0.0.1:8000](http://127.0.0.1:8000) or http://localhost:8000/ or  to see the result.  Here is a slightly modified version in which 'Hello world!' changes to 'I was clicked!' when it is clicked.      import justpy as jp          def my_click(self, msg):         self.text = 'I was clicked!'          def hello_world():         wp = jp.WebPage()         d = jp.Div(text='Hello world!')         d.on('click', my_click)         wp.add(d)         return wp          jp.justpy(hello_world)  Many other examples can be found in the [tutorial](https://justpy.io/#/tutorial/getting_started)  ## Under the Hood  JustPy's backend is built using:  * [starlette](https://www.starlette.io/) \- ""a lightweight [ASGI](https://asgi.readthedocs.io/en/latest/) framework/toolkit, which is ideal for building high performance asyncio services"". * [uvicorn](https://www.uvicorn.org/) \- ""a lightning-fast [ASGI](https://asgi.readthedocs.io/en/latest/) server, built on [uvloop](https://github.com/MagicStack/uvloop) and [httptools](https://github.com/MagicStack/httptools)"".  JustPy's frontend (which is transparent to JustPy developers) is built using:  * [Vue.js](https://vuejs.org/) \- ""The Progressive JavaScript Framework""  The way JustPy removes the frontend/backend distinction is by intercepting the relevant events on the frontend and sending them to the backend to be processed.  ## License  [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0.txt)"	https://www.reddit.com/r/Python/comments/f1qmsj/introducing_justpy_an_objectoriented_component/		reddit	f1qmsj	Python	1347.0	1347.0	263.0	Resource
La librairie Python WebSockets décide de fermer sans les traiter les tickets lié à un usage en Cryptocurrency.	Poglosaurus	Aucun	2022-07-20 10:33:24		https://websockets.readthedocs.io/en/stable/project/contributing.html		reddit	w3j1xz	france	162.0	162.0	140.0	Écologie
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-01 13:39:14		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=33669&_unique_id=65197681cada6		reddit	16x1h1t	udemyfreebies	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-10-01 12:01:47		https://idownloadcoupon.com/udemy/1483/		reddit	16wzbyu	udemyfreebies	1.0	1.0	0.0	Limited Time
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-01 13:39:09		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=33665&_unique_id=6519767d7a9e8		reddit	16x1gzm	FreeUdemyCoupons	1.0	1.0	0.0	
IAA: Python web dev interview questions	saitamaxmadara	Aucun	2023-07-08 07:32:27	Based on my previous post I considered it would be helpful for people who are about to give interview to prepare themselves with questions that I usually ask when I'm interviewing.     Here's the list of questions for **Python Web Development role** (from **1-2** yoe), please note I don't strictly follow these questions it can vary on which libraries the candidate has done projects on.     **Basics:**  * Difference between list and set * When one should use a set (or list) * Can we use dict as set * Is it possible to store function as dictionary key * Difference between tuples and list     **Advance basics (if candidate clears the above round)**:  * What is list (or dict) comprehension in python * What are scopes in python, explain with example * Python uses pass by reference or pass by value approach * Explain namespaces in python * In what scenario you'd use a decorator * Does using a generator function results in less memory consumption   *(There are many more questions in the basics category like inhertence, args, kwargs, pickling but I go with the above mention questions cause those are enough for web dev unless I feel need to ask more)*       **Programming approach questions (topics include threading, async-await etc):**  * What is concurrency in programming? * In which situations, one should go for approach which results in higher concurrency * Can you tell me the difference between threading and multiprocessing (if candidate has mentioned in the resume) * Why threading in python isn't actual threading like other system languages (if candidate knows about GIL then he's already selected) * How once should make sure to sync variables when using a multiprocessing program * How async-await is different from multiprocessing * For IO based concurrency one should pick threading, multiprocessing or async-await * *Bonus question: Why creating large number of threads don't solve the problem, does it introduce new problems?*  **Web development questions (with above questions I usually get idea how deep candidate has been into python and web dev stuff, so I try to make it short to get things done quickly):**  * Are you fimilar with REST? What are common HTTP verbs that we use in REST apis? * Is it a good idea to use PUT instead of POST when updating an entity? Does one should strictly follow the REST rules? * Is it possible to send data from client in GET request? Can you suggest some use case where we need to use it? (usually an api with lots for filters) * Which frameworks you've worked with in your previous projects? * Have you used any database with them? * Why did you pick x database for your project, is it not possible to do it with y database? Was there any particular reason? * Let's assume we are making a small e-commerce platform, can you suggest stack that we should be using?     There are more questions based on django, flask or fastapi. But we don't specifically hire for a single framework as we are service based company, we try to find people who are comfortable working in any framework or can learn the new one.     Let me know if it helps you and I will create the same for other roles as well.	https://www.reddit.com/r/developersIndia/comments/14tx93b/iaa_python_web_dev_interview_questions/		reddit	14tx93b	developersIndia	18.0	18.0	7.0	Resources
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-01 13:39:13		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=33668&_unique_id=65197680d3a47		reddit	16x1h1f	udemycoursedaily	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-10-01 13:39:10		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=33666&_unique_id=6519767e39686		reddit	16x1gzy	Udemy	1.0	1.0	0.0	
Python web apps with AI	Adam-Schroeder	Aucun	2023-08-21 14:42:10	Hi Everyone,   I'm Adam, the Community Manager at Plotly Dash - data visualizations and data apps in Python.  To stay on top of this changing AI landscape, we recently challenged the Plotly Python Community to build Dash apps that utilize the ChatGPT API. After receiving many impressive Python apps, we are thrilled to announce that several authors will be showcasing their top submissions on August 30.  If you're interested in seeing what Python community members were able to build with open source, feel free to register for the live community showcase!  https://go.plotly.com/dash-chatgpt	https://www.reddit.com/r/Python/comments/15x9n3j/python_web_apps_with_ai/		reddit	15x9n3j	Python	0.0	0.0	0.0	Tutorial
Robyn - A Python web framework with a Rust runtime - crossed 200k installs on PyPi	stealthanthrax	Aucun	2022-04-26 12:04:22	Hi Everyone! 👋  I wrote this blog to celebrate 200k install of Robyn. This blog documents the journey of Robyn so far and sheds some light on the future plans of Robyn.  I hope you all enjoy the read and share any feedback with me.  Blog Link: [https://www.sanskar.me/hello\_robyn.html](https://www.sanskar.me/hello_robyn.html)	https://www.reddit.com/r/Python/comments/ucazjl/robyn_a_python_web_framework_with_a_rust_runtime/		reddit	ucazjl	Python	480.0	480.0	60.0	News
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-18 03:46:31		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=28049&_unique_id=6507c81749d8d		reddit	16lkwn8	udemycoursedaily	1.0	1.0	0.0	
On a sub about the Python Web Framework	mrswats	Aucun	2023-10-17 21:23:05		https://i.redd.it/cnplw7fbytub1.jpg		reddit	17a94ev	lostredditors	6.0	6.0	1.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-18 03:46:32		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=28050&_unique_id=6507c81851689		reddit	16lkwnk	udemyfreebies	1.0	1.0	0.0	
Looking for a python web development remote job.	alilast	Aucun	2023-10-01 09:07:43	Hello everyone, i have 1 year experience in python web development in django, fastapi and flask, i dont no, how to find job remotly, kindly give some guidance, where to start, finding jobs remotely, other problem is that i am currently located in Pakistan, sometimes it creates problem while applying on LinkedIn, is there any solution for this?	https://www.reddit.com/r/remotework/comments/16wwase/looking_for_a_python_web_development_remote_job/		reddit	16wwase	remotework	1.0	1.0	3.0	
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-09-18 09:04:58		https://idownloadcoupon.com/udemy/3530		reddit	16lqdek	udemyfreebies	1.0	1.0	0.0	Limited Time
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-18 03:46:29		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=28047&_unique_id=6507c81503865		reddit	16lkwm4	FreeUdemyCoupons	1.0	1.0	0.0	
Python web or desktop app?	frick111	Aucun	2023-07-11 19:33:27	Hello! Im a third year comp sci student but my experience is mostly in java.  Im looking to make an app for me and a few friends to use that will scrape a few websites and compare some market trends. It will probably use selenium to scrape these websites. I still havent decided if I should make a desktop or web app, any recomendations on which one and what frameworks to use?	https://www.reddit.com/r/learnprogramming/comments/14x1175/python_web_or_desktop_app/		reddit	14x1175	learnprogramming	2.0	2.0	3.0	
Introducing Panther - A Fast and Friendly Python Web Framework	Conclusion-Striking	Aucun	2023-07-22 03:07:05	Hey everyone!  I'm excited to introduce Panther, a Python web framework that's designed to be fast and easy to use. With Panther, you can build async APIs quickly and efficiently, without sacrificing performance or readability.  Panther comes with a host of features that make it easy to build robust APIs, including:  - Document-oriented database support (including PantherDB and MongoDB) - Visual API monitoring in the terminal - Caching for APIs (both in-memory and in Redis) - Built-in authentication and permission classes (customizable) - Custom middleware support - Custom throttling support  Getting started with Panther is easy - just create a virtual environment, activate it, and install the framework using pip. Then, you can create a new project using the `panther create` command, and start building your API right away.  Here's a quick example of what a Panther API might look like:  ``` from datetime import datetime, timedelta  from panther.app import API from panther.configs import config from panther import version, status from panther.request import Request from panther.response import Response from panther.throttling import Throttling   @API() async def hello_world():     return {'detail': 'Hello World'}   @API(cache=True, throttling=Throttling(rate=5, duration=timedelta(minutes=1))) async def info(request: Request):     data = {         'version': version(),         'datetime_now': datetime.now().isoformat(),         'user_agent': request.headers.user_agent,         'db_engine': config['db_engine'],     }     return Response(data=data, status_code=status.HTTP_202_ACCEPTED) ```  If you're interested in learning more about Panther, check out the documentation at https://pantherpy.github.io, or head over to the GitHub repository at [https://github.com/alirn76/panther. ↗](https://github.com/alirn76/panther.)  Thanks for reading, and happy coding!	https://www.reddit.com/r/Python/comments/1568gde/introducing_panther_a_fast_and_friendly_python/		reddit	1568gde	Python	9.0	9.0	17.0	Discussion
If you could choose any Python web framework to build APIs for a startup, which one would you choose and why?	Perdox	Aucun	2022-09-30 17:52:23		https://www.reddit.com/r/Python/comments/xs7s6a/if_you_could_choose_any_python_web_framework_to/		reddit	xs7s6a	Python	194.0	194.0	130.0	Discussion
Which Python web framework uses web sockets most nicely?	drBonkers	Aucun	2023-07-20 16:42:21	I want to build a website with a collaborative code editor. I'm looking for the right tool to do it.	https://www.reddit.com/r/learnpython/comments/154w4y6/which_python_web_framework_uses_web_sockets_most/		reddit	154w4y6	learnpython	2.0	2.0	0.0	
Python Web Development: Building Dynamic and Powerful Web Applications	appy-pie-inc	Aucun	2023-07-21 15:09:10	"Python has quickly become one of the most popular programming languages for web development, owing to its simplicity, versatility, and a vast array of libraries and frameworks. Whether you are a seasoned developer or a beginner, Python offers a robust ecosystem to create dynamic and powerful web applications. In this article, we will explore the fundamentals of Python web development and delve into some of the popular frameworks widely used in the industry.  **The Role of Python in Web Development**  Python's rise in web development can be attributed to its readable and concise syntax, which enables developers to write clean and maintainable code. Its simplicity allows developers to focus on building the core functionality of their web applications without getting bogged down in complex syntax and boilerplate code. Moreover, Python boasts an extensive collection of modules specifically designed for web development, such as 'requests' for handling HTTP requests, 'Beautiful Soup' for web scraping, and 'Flask' and 'Django' frameworks for building web applications.  **Understanding Web Frameworks**  Web frameworks provide a structured and efficient way to develop web applications. Two of the most popular Python web frameworks are Django and Flask.  **a. Django:** Renowned for its ""batteries-included"" philosophy, Django is a full-fledged web framework that comes equipped with a rich set of tools and functionalities. This makes it an ideal choice for building complex, feature-rich web applications. Django follows the ""Don't Repeat Yourself"" (DRY) principle, promoting reusability and maintainability of code. Additionally, Django includes an Object-Relational Mapping (ORM) system, allowing developers to interact with the database using Python objects, thereby simplifying database management.  **b. Flask:** In contrast, Flask is a micro-framework, which means it provides only the essentials, allowing developers to add additional components based on their specific needs. Flask is known for its simplicity and flexibility, making it an excellent option for small to medium-sized projects or when developers prefer more control over the application's structure. Its lightweight nature and modular design have contributed to its popularity among developers.  **Creating a Simple Web Application with Flask**  To illustrate the power and simplicity of Python web development, let's consider building a simple web application using Flask. Flask allows you to create routes (URL mappings) and associated functions to handle web requests. By running a Flask development server, you can test your web application locally and view the output in a web browser.  **Database Integration**  One of the critical aspects of web development is database integration. Python web development makes it seamless to work with various databases. Django, for example, supports multiple database engines, such as PostgreSQL, MySQL, SQLite, and Oracle. Its ORM system abstracts away the underlying SQL queries, allowing developers to interact with databases using Python objects.  **Frontend Development**  While Python excels on the backend, it is often combined with frontend technologies like HTML, CSS, and JavaScript to create complete web applications. Web frameworks like Django provide support for rendering dynamic HTML templates, enabling developers to create responsive and user-friendly interfaces.  **Deployment**  Python web applications can be deployed on a wide range of platforms and hosting services. Common options include cloud platforms like AWS, Google Cloud, or Heroku, as well as web servers like Apache or Nginx. Additionally, containerization with tools like Docker has become increasingly popular for simplifying the deployment process.  In conclusion, Python web development has gained immense popularity due to its simplicity, robust frameworks, and extensive libraries. Whether you choose Django for large-scale projects or Flask for smaller applications, Python empowers developers to create sophisticated web applications efficiently. With its versatility, readable syntax, and strong community support, Python continues to be a top choice for web development, helping developers bring their ideas to life on the web."	https://www.reddit.com/r/appypiellp/comments/155qp90/python_web_development_building_dynamic_and/		reddit	155qp90	appypiellp	1.0	1.0	0.0	
Extensive Web Scraping Tutorial in Python, Ruby, Node, R and Java	pijora	Aucun	2020-07-05 21:44:42	Hi everyone, having worked in the web scraping industry for a few years I know how easily troublesome it can be to write, maintain and even begin web scraping.  One year ago, I wrote a web-scraping guide that was really loved by the community. [reddit post](https://old.reddit.com/r/learnprogramming/comments/cqa5ed/a_webscraping_guide_for_beginners/), [article](https://www.daolf.com/posts/avoiding-being-blocked-while-scraping-ultimate-guide/). It was actually my first and only gilded post here 😊.  One year forward, I left my job and co-bootstrapped a web scraping API 🤞. During the year we have made some good tutorials for beginners on our blog and I wanted to share it with you.   We tried our best to make those tutorials complete (20 minutes read time each) and simple. They cover many topics related to web scraping from bottom to top.  * how to make HTTP requests * how to parse HTML * how to use Chrome headless  and much more.  So far we have written extensive guides for 5 languages:  * [🐍 Python](https://www.scrapingbee.com/blog/web-scraping-101-with-python/) * [💎 Ruby](https://www.scrapingbee.com/blog/web-scraping-ruby/) * [😎 NodeJS](https://www.scrapingbee.com/blog/web-scraping-javascript/) * [🤓 R](https://www.scrapingbee.com/blog/web-scraping-r/) * [☕️ Java (130 pages free-ebook)](https://www.scrapingbee.com/java-webscraping-book/)  Hoping that it can help you with your work or your project.  Happy to answer web scraping questions if you have any.	https://www.reddit.com/r/learnprogramming/comments/hluvkr/extensive_web_scraping_tutorial_in_python_ruby/		reddit	hluvkr	learnprogramming	1914.0	1914.0	77.0	Tutorial
Python web frameworks to learn	Wolfagen	Aucun	2023-07-05 19:54:22	What Python web technologies someone can recommend to learn primarily, so to not scatter attention and build a working job-ready stack. Django or Flask? Some else recommendations / thoughts?	https://www.reddit.com/r/AskProgramming/comments/14rlf02/python_web_frameworks_to_learn/		reddit	14rlf02	AskProgramming	2.0	2.0	3.0	
Python Web Scraper	riverrockrun	Aucun	2022-12-31 23:32:22	I'm looking to scrape some baseball data from a website that sits behind a login page and requires a monthly subscription. I pay the subscription but would like to web scrape individual player data instead of putting it into my spreadsheet manually (using pandas and matplotlib to work with data later). Which python web scrapper would be best for this? BeautifulSoup, Selenium, Scrapy, etc. Thanks in advance!	https://www.reddit.com/r/learnpython/comments/1006lbj/python_web_scraper/		reddit	1006lbj	learnpython	9.0	9.0	13.0	
r/PythonWeb Lounge	Cygen_Space	Aucun	2023-07-01 02:44:08	A place for members of r/PythonWeb to chat with each other	https://www.reddit.com/r/PythonWeb/comments/14njk2v/rpythonweb_lounge/		reddit	14njk2v	PythonWeb	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-08 14:34:35		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=23517&_unique_id=64fb30faa867f		reddit	16dc8i2	FreeUdemyCoupons	1.0	1.0	0.0	
Issue with Django Channels and Python WebSocket client, but not JS WebSocket client	whiteBlasian	Aucun	2023-09-27 15:23:42	"Hey Guys,  Been stumped on a weird issue for the last couple of days. I am using Django Channels to implement WebSockets. When I connect to the backend channel with a JS client in the browser, the client can send and receive messages no problem. The line below shows the browser console when the JS client receives messages from the backend.  `MessageEvent {isTrusted: true, data: '3.2', origin: 'ws://127.0.0.1:8000', lastEventId: '', source: null, …}`  However, when I run a WebSocket client in Python **it does not receive messages**. It can connect to the server and send messages, but it cannot receive them. Below is the test script I've been using:      def onMsg(ws, msg):         print(""got "" + msg)          def onOpen(ws):         print(""got "" + str(ws))         print(""sent "" + ws.send(""1, 3.2, 3.2""))            def onClose(ws):         print(""closed"")          def testWebSocketPyClient():         websocket.enableTrace(True)         wsapp = websocket.WebSocketApp(""ws://127.0.0.1:8000/upload-channel/"", on_message=onMsg, on_open=onOpen, on_data=onMsg)         wsapp.run_forever()           if __name__ == ""__main__"":         testWebSocketPyClient()  Here are the logs when I connect the Python client to the channel:      WebSocket HANDSHAKING /upload-channel/ [127.0.0.1:65376]     connected  {'type': 'websocket.connect'} WebSocket CONNECT /upload-channel/ [127.0.0.1:65376]      sent data      received  {'type': 'websocket.receive', 'text': '1, 3.2, 3.2'}      ['1', ' 3.2', ' 3.2']     didnt send the data 'WebSocketProtocol' object has no attribute 'handshake_deferred'  I can see it connects, but then get the ""no attribute handshake\_deferred"" error and can not send messages.  Any thoughts??  Cheers"	https://www.reddit.com/r/django/comments/16tngx4/issue_with_django_channels_and_python_websocket/		reddit	16tngx4	django	5.0	5.0	5.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-08 14:34:39		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=23520&_unique_id=64fb30feb705a		reddit	16dc8kb	udemyfreebies	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-09-08 14:34:37		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=23519&_unique_id=64fb30fd53ff9		reddit	16dc8je	udemycoursedaily	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-09-03 06:00:46		https://idownloadcoupon.com/udemy/736/python-django-rest-api-bootcamp-build-a-python-web-api/		reddit	168p20n	udemyfreebies	2.0	2.0	0.0	Limited Time
Junior who wants a job in Python Web Development	SilentPurpleSpark	Aucun	2023-08-27 01:18:37	Hello !   I have used Python for a few months, but I've been learning Python seriously for a month and I want to accelerate my efforts of getting into the industry of programming. I analyzed the available posts and I've decided that Web Development would be the area where I'd have the most fun.    I got stuck at choosing the right library for me : Django or Flask ?   I've read hours of comparisons between the two, and watching a few samples of code, I find Flask to be easier to understand. Also what I found would resume into :   \-Flask is easier to start with but harder to develop into complex projects or to manage ;   \-Django is harder to start with, requires much more preparations but it's more manageable when the project rises in complexity ;   But I want to make sure, so I'm asking :   1.What is possible to do in Django is also possible to do in Flask?   2.Is it really that hard to code in Flask the things Django does automatically for you?   3.Does Flask have career opportunity?   4.Because Flask doesn't have too many prebuilt features, it gives you more freedom in a beneficial way?	https://www.reddit.com/r/flask/comments/162corf/junior_who_wants_a_job_in_python_web_development/		reddit	162corf	flask	12.0	12.0	8.0	Discussion
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-09-02 21:34:12		https://idownloadcoupon.com/udemy/736/		reddit	168ejsu	udemyfreebies	1.0	1.0	0.0	Limited Time
My first React and Python web app	DrJrea	Aucun	2022-01-01 13:27:03	I recently made and deployed my first web app using React and Python!  Site to search movies and tv shows to see which streaming providers they’re available on (Currently only checks UK providers).  https://findwheretowatch.co.uk	https://www.reddit.com/r/webdev/comments/rtjeer/my_first_react_and_python_web_app/		reddit	rtjeer	webdev	111.0	111.0	45.0	Showoff Saturday
A First Look at PyScript: Python in the Web Browser – Real Python	ajpinedam	Aucun	2022-06-07 14:09:51		https://realpython.com/pyscript-python-in-browser/		reddit	v6wn9m	Python	419.0	419.0	65.0	Tutorial
A Python Web Crawler	10ysf	Aucun	2023-04-30 10:54:37	Hello everyone. I need help: I would like to create a python script that searches for a query string within the sites given below and after each search operation it returns the results from the given websites in the form of an HTML search result page. I want it to search within these websites:  [cio.com](https://cio.com)  [techrepublic.com](https://techrepublic.com)  [theverge.com](https://theverge.com)  I tried searching for an already-made script, but I couldn't find one.  Thanks in advance.   Edit: Just got the the answer by asking chatGPT. Thanks.	https://www.reddit.com/r/learnpython/comments/133m3wp/a_python_web_crawler/		reddit	133m3wp	learnpython	0.0	0.0	4.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-20 16:32:45		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=9857&_unique_id=64e2402d914af		reddit	15wfyey	udemycoursedaily	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-20 16:32:46		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=9858&_unique_id=64e2402e496a2		reddit	15wfyfb	udemyfreebies	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-20 16:32:43		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=9855&_unique_id=64e2402b1779e		reddit	15wfydr	FreeUdemyCoupons	1.0	1.0	0.0	
Where can I deploy websites that using python as a backend (web applications)	YukkiiCode	Aucun	2023-04-22 09:16:50	hello, I need a host that I can buy and use to deploy my web apps, the cheapest ever.   and if it possible that I deploy several webapps it would be amazing, as I need something to deploy all my projects on, and is this even possible?	https://www.reddit.com/r/Python/comments/12v0d0e/where_can_i_deploy_websites_that_using_python_as/		reddit	12v0d0e	Python	189.0	189.0	123.0	Discussion
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-17 16:44:45		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=8131&_unique_id=64de4e7cef5e8		reddit	15tss4l	udemycoursedaily	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-17 16:44:42		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=8129&_unique_id=64de4e7aa5753		reddit	15tss3h	FreeUdemyCoupons	1.0	1.0	0.0	
Python & Django REST API Bootcamp - Build A Python Web API	abjinternational	Aucun	2023-08-17 16:44:46		https://www.freewebcart.com/courses/python-django-rest-api-bootcamp-build-a-python-web-api/?feed_id=8132&_unique_id=64de4e7de1307		reddit	15tss55	udemyfreebies	1.0	1.0	0.0	
Show HN: I built a Python web framework	qznc_bot2	Aucun	2023-09-09 22:00:09		https://github.com/ZeroIntensity/view.py		reddit	16ei5f6	hackernews	1.0	1.0	1.0	
Masonite 2.0 Released - The Modern Python Web Framework!	Jmancuso9	Aucun	2018-06-16 14:12:57	I posted about the Masonite Python web framework a few months ago on this r/python here and it received interesting feedback. During this time we received a few contributors who are just super awesome and contributed some awesome features.  We also were able to boost the speed of the framework to serve about twice as many requests in 30 seconds as Masonite 1.6 using some \`wrk\` benchmark testing.  Our contributors are extremely excited for this release and we can't wait to show it to the Python community. We think many of you will love the framework.  Here are a few useful links to checkout the framework:  Slack Open Invitation: [http://slack.masoniteproject.com](http://slack.masoniteproject.com)  The Github Repo: [https://github.com/MasoniteFramework/masonite](https://github.com/MasoniteFramework/masonite)  The Documentation: [https://docs.masoniteproject.com/prologue/introduction-and-installaton](https://docs.masoniteproject.com/prologue/introduction-and-installaton)  Whats New in Masonite 2.0: [https://docs.masoniteproject.com/whats-new/masonite-2.0](https://docs.masoniteproject.com/whats-new/masonite-2.0)  The Core Repository: [https://github.com/MasoniteFramework/core](https://github.com/MasoniteFramework/core)  Creating Your First Blog: [https://docs.masoniteproject.com/creating-your-first-blog/introduction](https://docs.masoniteproject.com/creating-your-first-blog/introduction)  Feedback for the Masonite community is appreciated and  we'll be watching this thread for your thoughts on the framework! We hope to see you guys create some awesome web applications!  &#x200B;  Here is the new 2.1 release: [https://www.reddit.com/r/Python/comments/a22z8t/next\_version\_of\_masonite\_v21\_released\_the\_modern/](https://www.reddit.com/r/Python/comments/a22z8t/next_version_of_masonite_v21_released_the_modern/)	https://www.reddit.com/r/Python/comments/8rjla6/masonite_20_released_the_modern_python_web/		reddit	8rjla6	Python	284.0	284.0	104.0	
Easy to follow Python web scraping tutorial with the help of MITMProxy	makedatauseful	Aucun	2021-01-01 03:50:37	Hey r/python I posted this tutorial on how to access a private API with the help of Man in the Middle Proxy a couple of months back and thought I might reshare for those who may have missed it.  [https://www.youtube.com/watch?v=LbPKgknr8m8](https://www.youtube.com/watch?v=LbPKgknr8m8)  **Topics covered**   * MITMProxy to observe the web traffic and get the API calls * Requests to perform the API call in Python * BeautifulSoup to convert the XML data * Pandas to take the converted XML data and create a CSV file  If your 2021 new years resolution is to learn Python definitely consider subscribing to my YouTube channel because my goal is to share more tutorials!	https://www.reddit.com/r/Python/comments/ko4gh7/easy_to_follow_python_web_scraping_tutorial_with/		reddit	ko4gh7	Python	725.0	725.0	29.0	Tutorial
Show HN: I built a Python web framework	PatientModBot	Aucun	2023-09-09 22:46:36		https://github.com/ZeroIntensity/view.py		reddit	16ejbj1	patient_hackernews	1.0	1.0	1.0	
Async Python Web Frameworks comparison 2021-04-29	horneds	Aucun	2021-04-29 09:21:54		https://github.com/klen/py-frameworks-bench		reddit	n10m8w	Python	259.0	259.0	41.0	Resource
Problem with python web scraping	legendarypegasus	Aucun	2023-05-23 04:32:54	"Hello everyone, I am doing web scraping to a page but it is not updating the data of the navigation bar when I download the html, I currently explain myself with selenium I look for the next page and I click on it to download the html of the different pages but The html of the page labels is not updating so I can only go up to 10, any advice you can give me?  &#x200B;  import selenium   from selenium import webdriver   from selenium.webdriver.support.ui import WebDriverWait   from bs4 import BeautifulSoup as bs4   from selenium.webdriver.common.by import By   from selenium.webdriver.support import expected\_conditions as EC           def get\_html(url, driver, page):   print(""pag"", page)   driver.get(url)   WebDriverWait(driver, 10).until(lambda d: d.execute\_script('return document.readyState') == 'complete')   element\_padre = driver.find\_element(By.ID, f""pagina{page}"")   element\_hijo = element\_padre.find\_element(By.TAG\_NAME, ""a"")   element\_hijo.click()       if driver.find\_element(By.ID, f""pagina{page + 1}"") is not None:   html\_content = driver.page\_source   soup = bs4(html\_content, ""html.parser"")   pretty\_html = soup.prettify()   with open(f""ciencuadras{page}.html"", ""w"", encoding=""utf-8"") as file:   file.write(pretty\_html)   else:   print(""No hay más páginas"")       driver = selenium.webdriver.Firefox()   url = ""https://www.ciencuadras.com/inmobiliarias""   page = 1   while True:   page += 1   try:   get\_html(url,driver,page)   except selenium.common.exceptions.NoSuchElementException as e:   print(e)   \#driver.quit()"	https://www.reddit.com/r/learnpython/comments/13pdzyp/problem_with_python_web_scraping/		reddit	13pdzyp	learnpython	1.0	1.0	2.0	
Python Web Dev Pro: Flask, Django, HTML, CSS & Bootstrap	smartybrome	Aucun	2023-10-27 14:04:16		https://idownloadcoupon.com/udemy/2990/		reddit	17hoa82	udemyfreebies	1.0	1.0	0.0	Limited Time
Python and Django REST API Bootcamp - Build A Python Web API ($54.99 to FREE)	Noledgebase	Aucun	2023-10-18 08:51:54		https://www.jucktion.com/f/udemy-coupon/python-and-django-rest-api-bootcamp-build-a-python-web-api-$54-99-to-f-275750/		reddit	17am0pz	Udemies	1.0	1.0	0.0	
Python Web Dev Pro: Flask, Django, HTML, CSS & Bootstrap	smartybrome	Aucun	2023-10-27 09:31:07		https://idownloadcoupon.com/udemy/2990/		reddit	17hjp6j	udemyfreebies	1.0	1.0	0.0	Limited Time
Getting Started With Python Web Scraping For LLMs	Daninmde	Aucun	2023-09-08 17:49:36		https://www.aitimejournal.com/getting-started-with-python-web-scraping-for-llms/46041/		reddit	16dh6mu	VisionaryZone	1.0	1.0	0.0	
Getting Started With Python Web Scraping For LLMs	Daninmde	Aucun	2023-09-08 18:11:35		https://www.aitimejournal.com/getting-started-with-python-web-scraping-for-llms/46041/		reddit	16dhqy7	chiefaiofficer	1.0	1.0	0.0	
Issue with Django Channels and Python WebSocket client, but not JS WebSocket client	whiteBlasian	Aucun	2023-09-27 19:54:53		/r/django/comments/16tngx4/issue_with_django_channels_and_python_websocket/		reddit	16tu80s	learndjango	1.0	1.0	0.0	
Master Python Web Scraping & Automation using BS4 & Selenium	abjinternational	Aucun	2023-10-18 05:53:06		https://www.freewebcart.com/courses/master-python-web-scraping-automation-using-bs4-selenium/?feed_id=40848&_unique_id=652f72c1b6b25		reddit	17ajgjr	Udemy	1.0	1.0	0.0	
Master Python Web Scraping & Automation using BS4 & Selenium	abjinternational	Aucun	2023-10-18 05:53:05		https://www.freewebcart.com/courses/master-python-web-scraping-automation-using-bs4-selenium/?feed_id=40847&_unique_id=652f72c0de35c		reddit	17ajgjd	FreeUdemyCoupons	1.0	1.0	0.0	
Python and Django REST API Bootcamp - Build A Python Web API ($54.99 to FREE)	Noledgebase	Aucun	2023-10-08 11:50:16		https://www.jucktion.com/f/udemy-coupon/python-and-django-rest-api-bootcamp-build-a-python-web-api-$54-99-to-f-273620/		reddit	172x955	Udemies	1.0	1.0	0.0	
Master Python Web Scraping & Automation using BS4 & Selenium	abjinternational	Aucun	2023-10-18 05:53:09		https://www.freewebcart.com/courses/master-python-web-scraping-automation-using-bs4-selenium/?feed_id=40851&_unique_id=652f72c4ed6ea		reddit	17ajgks	udemyfreebies	1.0	1.0	0.0	
Master Python Web Scraping & Automation using BS4 & Selenium	abjinternational	Aucun	2023-10-18 05:53:08		https://www.freewebcart.com/courses/master-python-web-scraping-automation-using-bs4-selenium/?feed_id=40850&_unique_id=652f72c44a043		reddit	17ajgkl	udemycoursedaily	1.0	1.0	0.0	
Master Python Web Scraping & Automation using BS4 & Selenium	smartybrome	Aucun	2023-10-18 14:04:01		https://idownloadcoupon.com/udemy/1653/		reddit	17arluy	udemyfreebies	1.0	1.0	0.0	Limited Time
Practice Tests for Python web scrapping.	abjinternational	Aucun	2023-06-28 05:52:19		https://www.freewebcart.com/practice-tests-for-python-web-scrapping/		reddit	14l138p	udemycoursedaily	1.0	1.0	0.0	
Practice Tests for Python web scrapping.	abjinternational	Aucun	2023-06-28 05:52:19		https://www.freewebcart.com/practice-tests-for-python-web-scrapping/		reddit	14l138l	FreeUdemyCoupons	1.0	1.0	0.0	
Python Web Scraping Help	kimasdawn	Aucun	2023-03-21 01:32:31	"**REPOSTED BECAUSE I PUT IT IN THE WRONG REDDIT \^\^'**  I've been practicing web scraping in Python for a while now, but I'm coming across a problem I'm not sure I understand.  I'm scraping crypto market prices, and my test is returning the data I want - great - but it's not updating in real time. How do I go about fixing this? In my search on the wonderful world wide web, I've only become more confused.  &#x200B;      URL = ""https://coinmarketcap.com/""     page = requests.request(""GET"", URL)     soup = BeautifulSoup(page.content, ""html.parser"")     results = soup.find(id=""__next"")          crypto_names = results.find_all(""div"", class_=""sc-beb003d5-2 bkNrIb"")          dataList = []          def multiple_appends(listname, *element):             listname.extend(element)          for crypto_name in crypto_names:             while crypto_name:                 name_element = crypto_name.find(""p"", class_=""sc-e225a64a-0 ePTNty"")                 price_element = crypto_name.find(""div"", class_=""sc-8bda0120-0 dskdZn"") or crypto_name.find(""div"", class_=""sc-8bda0120-0 dskdZn fall"") or crypto_name.find(""div"", class_=""sc-8bda0120-0 dskdZn rise"")                 percent_element = crypto_name.find(""span"", class_=""sc-97d6d2ca-0 bQjSqS"")                                  multiple_appends(dataList,                                  name_element.text,                                  price_element.text,                                  percent_element.text)                      print(str(dataList))                 f = open(""response.html"", ""a"")                 f.write(str(""Coin name: ""+ name_element.text.strip())+"" | "")                 f.write(str(""Price: "" + price_element.text.strip()) + "" | "")                 f.write(str(""Percentage (1hr): "" + percent_element.text.strip()) + ""\n"")                 f.close()                 dataList.clear()                 time. Sleep(5)"	https://www.reddit.com/r/learnpython/comments/11x2x4z/python_web_scraping_help/		reddit	11x2x4z	learnpython	1.0	1.0	3.0	
Welcome to Pyramid, a Python Web Framework	pmz	Aucun	2021-01-22 13:50:45		https://trypyramid.com/		reddit	l2o43w	Python	126.0	126.0	52.0	Resource
Practice Tests for Python web scrapping.	abjinternational	Aucun	2023-06-28 05:52:18		https://www.freewebcart.com/practice-tests-for-python-web-scrapping/		reddit	14l138e	udemyfreebies	0.0	0.0	0.0	Limited Time
Intro To Django Python Web Apps | 100% Off Udemy Coupons	webhelperapp	Aucun	2023-10-28 13:17:49		https://webhelperapp.com/intro-to-django-python-web-apps/		reddit	17idlur	djangolearning	0.0	0.0	0.0	Tutorial
Python & Django REST API Bootcamp - Build A Python Web API	smartybrome	Aucun	2023-07-09 06:01:02		https://idownloadcoupon.com/udemy/2606/python-django-rest-api-bootcamp-build-a-python-web-api/		reddit	14uql3c	udemyfreebies	2.0	2.0	0.0	Limited Time
