{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e1f876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************** Explorer REDDIT *****************************************************************\n",
      "*********************** Explorer les subreddits  *************************************************************\n",
      "TITLE : \n",
      " Effectiveness of Nirmatrelvir–Ritonavir Against the Development of Post–COVID-19 Conditions Among U.S. Veterans\n",
      "ID : \n",
      " 17k5381\n",
      "AUTHOR : \n",
      " hexagonincircuit1594\n",
      "URL : \n",
      " https://www.acpjournals.org/doi/10.7326/M23-1394\n",
      "SCORE : \n",
      " 16\n",
      "COMMENTS COUNT : \n",
      " 2\n",
      "CREATED : \n",
      " 2023-10-30 22:05:28\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Long-term Prognosis at 1.5 years after Infection with Wild-type strain of SARS-CoV-2 and Alpha, Delta, as well as Omicron Variants\n",
      "ID : \n",
      " 17k2lcg\n",
      "AUTHOR : \n",
      " PrincessGambit\n",
      "URL : \n",
      " https://www.ijidonline.com/article/S1201-9712(23)00760-9/fulltext\n",
      "SCORE : \n",
      " 43\n",
      "COMMENTS COUNT : \n",
      " 7\n",
      "CREATED : \n",
      " 2023-10-30 20:18:23\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Risk of hospital admission and death from first-ever SARS-CoV-2 infection by age group during the Delta and Omicron periods in British Columbia, Canada\n",
      "ID : \n",
      " 17jxs7t\n",
      "AUTHOR : \n",
      " hexagonincircuit1594\n",
      "URL : \n",
      " https://www.cmaj.ca/content/195/42/E1427\n",
      "SCORE : \n",
      " 18\n",
      "COMMENTS COUNT : \n",
      " 1\n",
      "CREATED : \n",
      " 2023-10-30 16:47:11\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Respiratory mucosal immune memory to SARS-CoV-2 after infection and vaccination\n",
      "ID : \n",
      " 17jgyvq\n",
      "AUTHOR : \n",
      " enterpriseF-love\n",
      "URL : \n",
      " https://www.nature.com/articles/s41467-023-42433-w\n",
      "SCORE : \n",
      " 29\n",
      "COMMENTS COUNT : \n",
      " 3\n",
      "CREATED : \n",
      " 2023-10-30 00:29:43\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Resurgence of SARS-CoV-2 Delta after Omicron variant superinfection in an immunocompromised pediatric patient\n",
      "ID : \n",
      " 17iheiq\n",
      "AUTHOR : \n",
      " enterpriseF-love\n",
      "URL : \n",
      " https://virologyj.biomedcentral.com/articles/10.1186/s12985-023-02186-w\n",
      "SCORE : \n",
      " 54\n",
      "COMMENTS COUNT : \n",
      " 8\n",
      "CREATED : \n",
      " 2023-10-28 16:29:18\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Chronic Fatigue and Dysautonomia following COVID-19 Vaccination Is Distinguished from Normal Vaccination Response by Altered Blood Markers\n",
      "ID : \n",
      " 17hyb1z\n",
      "AUTHOR : \n",
      " PrincessGambit\n",
      "URL : \n",
      " https://www.mdpi.com/2076-393X/11/11/1642?fbclid=IwAR0rKE94m8sZWfpkmwRAkPcMqUXjfo7C4XnbazJys32wOBqD2vFjcvE1LMo\n",
      "SCORE : \n",
      " 46\n",
      "COMMENTS COUNT : \n",
      " 5\n",
      "CREATED : \n",
      " 2023-10-27 21:41:47\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Effectiveness of the second COVID-19 booster against Omicron: a large-scale cohort study in Chile\n",
      "ID : \n",
      " 17hsn1a\n",
      "AUTHOR : \n",
      " hexagonincircuit1594\n",
      "URL : \n",
      " https://www.nature.com/articles/s41467-023-41942-y\n",
      "SCORE : \n",
      " 14\n",
      "COMMENTS COUNT : \n",
      " 3\n",
      "CREATED : \n",
      " 2023-10-27 17:22:48\n",
      "\n",
      "\n",
      "TITLE : \n",
      " COVID-19 illness severity and 2-year prevalence of physical symptoms: an observational study in Iceland, Sweden, Norway and Denmark\n",
      "ID : \n",
      " 17hljh4\n",
      "AUTHOR : \n",
      " hexagonincircuit1594\n",
      "URL : \n",
      " https://www.thelancet.com/journals/lanepe/article/PIIS2666-7762(23)00175-8/fulltext\n",
      "SCORE : \n",
      " 22\n",
      "COMMENTS COUNT : \n",
      " 2\n",
      "CREATED : \n",
      " 2023-10-27 11:35:40\n",
      "\n",
      "\n",
      "TITLE : \n",
      " Ischemic Stroke after Bivalent COVID-19 Vaccination: A Self-Controlled Case Series Study\n",
      "ID : \n",
      " 17h2w3g\n",
      "AUTHOR : \n",
      " rainbow658\n",
      "URL : \n",
      " https://www.medrxiv.org/content/10.1101/2023.10.12.23296968v1\n",
      "SCORE : \n",
      " 13\n",
      "COMMENTS COUNT : \n",
      " 4\n",
      "CREATED : \n",
      " 2023-10-26 18:20:38\n",
      "\n",
      "\n",
      "TITLE : \n",
      " An atlas of continuous adaptive evolution in endemic human viruses\n",
      "ID : \n",
      " 17h1ton\n",
      "AUTHOR : \n",
      " hexagonincircuit1594\n",
      "URL : \n",
      " https://www.cell.com/cell-host-microbe/fulltext/S1931-3128(23)00380-3\n",
      "SCORE : \n",
      " 12\n",
      "COMMENTS COUNT : \n",
      " 2\n",
      "CREATED : \n",
      " 2023-10-26 17:32:22\n",
      "\n",
      "\n",
      "*********************** Explorer un poste à identifiant unique ************************************************\n",
      "Commentaire : \n",
      "\n",
      "texte : \n",
      " **Please read before commenting.**\n",
      "\n",
      "Keep in mind this is a *science* sub. Cite your sources appropriately (No news sources, no Twitter, no Youtube). No politics/economics/low effort comments (jokes, ELI5, etc.)/anecdotal discussion (personal stories/info). Please read our [full ruleset](https://www.reddit.com/r/COVID19/about/rules/) carefully before commenting/posting.\n",
      "\n",
      "**If you talk about you, your mom, your friends, etc. experience with COVID/COVID symptoms or vaccine experiences, or** ***any*** **info that pertains to you or their situation, you will be banned.** These discussions are better suited for the Weekly Discussion on /r/Coronavirus.\n",
      "\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/COVID19) if you have any questions or concerns.*\n",
      "auteur : \n",
      " AutoModerator\n",
      "\n",
      "\n",
      "Commentaire : \n",
      "\n",
      "texte : \n",
      " >This study demonstrated an effective and fast (in 1 sec) inactivation capacity of the DUV light on SARS-CoV-2 and other microorganisms, meanwhile, the DUV LED module had the advantage to realise a narrow-band DUV emission and uniform radiation (the unevenness was less than 5% on the inactivation surface) reliably. The research gaps regarding the influences of viral variants (Delta and Omicron) and low temperatures on the DUV virucidal efficacy were filled. The lethal effect of DUV was reduced by the cryogenic environment, for instance, the DUV dose needed to be doubled at −50 °C to achieve the same inactivation performance compared to the room temperature for the variant of Omicron. This was mainly elicited by the different thermal energy and chance of capture in the negative-U large-relaxation model. Besides, the inactivation of Omicron required a significantly higher DUV dose compared to other viral strains, which was theoretically due to its genetic and proteinic characteristics. The crucial discoveries in this study can offer human society guidance of DUV disinfection to fight against the COVID-19, especially in the cryogenic conditions (such as the food cold chain logistics and the open air in winter).\n",
      "auteur : \n",
      " Vasastan1\n",
      "\n",
      "\n",
      "***************************** Explorer arxiv ******************************************************************\n",
      "Title: Egg-smol Python: A Pythonic Library for E-graphs\n",
      "Summary: E-graphs have emerged as a versatile data structure with applications in\n",
      "synthesis, optimization, and verification through techniques such as equality\n",
      "saturation. This paper introduces Python bindings for the experimental egg-smol\n",
      "library, which aims to bring the benefits of e-graphs to the Python ecosystem.\n",
      "The bindings offer a high-level, Pythonic API providing an accessible and\n",
      "familiar interface for Python users. By integrating e-graph techniques with\n",
      "Python, we hope to enable collaboration and innovation across various domains\n",
      "in the scientific computing and machine learning communities. We discuss the\n",
      "advantages of using Python bindings for both Python and existing egg-smol\n",
      "users, as well as possible future directions for development.\n",
      "--------\n",
      "Title: Making Python Code Idiomatic by Automatic Refactoring Non-Idiomatic\n",
      "  Python Code with Pythonic Idioms\n",
      "Summary: Compared to other programming languages (e.g., Java), Python has more idioms\n",
      "to make Python code concise and efficient. Although pythonic idioms are well\n",
      "accepted in the Python community, Python programmers are often faced with many\n",
      "challenges in using them, for example, being unaware of certain pythonic idioms\n",
      "or do not know how to use them properly. Based on an analysis of 7,638 Python\n",
      "repositories on GitHub, we find that non-idiomatic Python code that can be\n",
      "implemented with pythonic idioms occurs frequently and widely. Unfortunately,\n",
      "there is no tool for automatically refactoring such non-idiomatic code into\n",
      "idiomatic code. In this paper, we design and implement an automatic refactoring\n",
      "tool to make Python code idiomatic. We identify nine pythonic idioms by\n",
      "systematically contrasting the abstract syntax grammar of Python and Java. Then\n",
      "we define the syntactic patterns for detecting non-idiomatic code for each\n",
      "pythonic idiom. Finally, we devise atomic AST-rewriting operations and\n",
      "refactoring steps to refactor non-idiomatic code into idiomatic code. We test\n",
      "and review over 4,115 refactorings applied to 1,065 Python projects from\n",
      "GitHub, and submit 90 pull requests for the 90 randomly sampled refactorings to\n",
      "84 projects. These evaluations confirm the high-accuracy, practicality and\n",
      "usefulness of our refactoring tool on real-world Python code. Our refactoring\n",
      "tool can be accessed at 47.242.131.128:5000.\n",
      "--------\n",
      "Title: Modern Python at the Large Synoptic Survey Telescope\n",
      "Summary: The LSST software systems make extensive use of Python, with almost all of it\n",
      "initially being developed solely in Python 2. Since LSST will be commissioned\n",
      "when Python 2 is end-of-lifed it is critical that we have all our code support\n",
      "Python 3 before commissioning begins. Over the past year we have made\n",
      "significant progress in migrating the bulk of the code from the Data Management\n",
      "system onto Python 3. This paper presents our migration methodology, and the\n",
      "current status of the port, with our eventual aim to be running completely on\n",
      "Python 3 by early 2018. We also discuss recent modernizations to our Python\n",
      "codebase.\n",
      "--------\n",
      "Title: Python GUI Scripting Interface for Running Atomic Physics Applications\n",
      "Summary: We create a Python GUI scripting interface working under Windows in addition\n",
      "to (UNIX/Linux). The GUI has been built around the Python open-source\n",
      "programming language. We use the Python's GUI library that so called Python\n",
      "Mega Widgets (PMW) and based on Tkinter Python module\n",
      "(http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI was\n",
      "motivated primarily by the desire of more updated operations, more flexibility\n",
      "incorporating future and current improvements in producing atomic data.\n",
      "Furthermore it will be useful for a variety of applications of atomic physics,\n",
      "plasma physics and astrophysics and will help in calculating various atomic\n",
      "properties.\n",
      "--------\n",
      "Title: Towards Memory Safe Python Enclave for Security Sensitive Computation\n",
      "Summary: Intel SGX Guard eXtensions (SGX), a hardware-supported trusted execution\n",
      "environment (TEE), is designed to protect security-sensitive applications.\n",
      "However, since enclave applications are developed with memory unsafe languages\n",
      "such as C/C++, traditional memory corruption is not eliminated in SGX. Rust-SGX\n",
      "is the first toolkit providing enclave developers with a memory-language.\n",
      "However, Rust is considered a Systems language and has become the right choice\n",
      "for concurrent applications and web browsers. Many application domains such as\n",
      "Big Data, Machine Learning, Robotics, Computer Vision are more commonly\n",
      "developed in the python programming language. Therefore, Python application\n",
      "developers cannot benefit from secure enclaves like Intel SGX and rust-SGX. To\n",
      "fill this gap, we propose Python-SGX, which is a memory-safe SGX SDK providing\n",
      "enclave developers a memory-safe Python development environment. The key idea\n",
      "is to enable memory-safe Python language in SGX by solving the following key\n",
      "challenges: (1) defining a memory-safe Python interpreter (2)replacing unsafe\n",
      "elements of Python interpreter with safe ones,(3) achieving comparable\n",
      "performance to non-enclave Python applications, and (4) not introducing any\n",
      "unsafe new code or libraries into SGX. We propose to build Python-SGX with\n",
      "PyPy, a Python interpreter written by RPython, which is a subset of Python, and\n",
      "tame unsafe parts in PyPy by formal verification, security hardening, and\n",
      "memory safe language. We have implemented python-SGX and tested it with a\n",
      "series of benchmarks programs. Our evaluation results show that Python-SGX does\n",
      "not cause significant overhead.\n",
      "--------\n",
      "Title: Porting the LSST Data Management Pipeline Software to Python 3\n",
      "Summary: The LSST data management science pipelines software consists of more than\n",
      "100,000 lines of Python 2 code. LSST operations will begin after support for\n",
      "Python 2 has been dropped by the Python community in 2020, and we must\n",
      "therefore plan to migrate the codebase to Python 3. During the transition\n",
      "period we must also support our community of active Python 2 users and this\n",
      "complicates the porting significantly. We have decided to use the Python future\n",
      "package as the basis for our port to enable support for Python 2 and Python 3\n",
      "simultaneously, whilst developing with a mindset more suited to Python 3. In\n",
      "this paper we report on the current status of the port and the difficulties\n",
      "that have been encountered.\n",
      "--------\n",
      "Title: A general approach for running Python codes in OpenFOAM using an\n",
      "  embedded pybind11 Python interpreter\n",
      "Summary: As the overlap between traditional computational mechanics and machine\n",
      "learning grows, there is an increasing demand for straight-forward approaches\n",
      "to interface Python-based procedures with C++-based OpenFOAM. This article\n",
      "introduces one such general methodology, allowing the execution of Python code\n",
      "directly within an OpenFOAM solver without the need for Python code\n",
      "translation. The proposed approach is based on the lightweight library\n",
      "pybind11, where OpenFOAM data is transferred to an embedded Python interpreter\n",
      "for manipulation, and results are returned as needed. Following a review of\n",
      "related approaches, the article describes the approach, with a particular focus\n",
      "on data transfer between Python and OpenFOAM, executing Python scripts and\n",
      "functions, and practical details about the implementation in OpenFOAM. Three\n",
      "complementary test cases are presented to highlight the functionality and\n",
      "demonstrate the effect of different data transfer approaches: a Python-based\n",
      "velocity profile boundary condition; a Python-based solver for prototyping; and\n",
      "a machine learning mechanical constitutive law class for solids4foam which\n",
      "performs field calculations.\n",
      "--------\n",
      "Title: Python for education: the exact cover problem\n",
      "Summary: Python implementation of Algorithm X by Knuth is presented. Algorithm X finds\n",
      "all solutions to the exact cover problem. The exemplary results for\n",
      "pentominoes, Latin squares and Sudoku are given.\n",
      "--------\n",
      "Title: Teddy: Automatic Recommendation of Pythonic Idiom Usage For Pull-Based\n",
      "  Software Projects\n",
      "Summary: Pythonic code is idiomatic code that follows guiding principles and practices\n",
      "within the Python community. Offering performance and readability benefits,\n",
      "Pythonic code is claimed to be widely adopted by experienced Python developers,\n",
      "but can be a learning curve to novice programmers. To aid with Pythonic\n",
      "learning, we create an automated tool, called Teddy, that can help checking the\n",
      "Pythonic idiom usage. The tool offers a prevention mode with Just-In-Time\n",
      "analysis to recommend the use of Pythonic idiom during code review and a\n",
      "detection mode with historical analysis to run a thorough scan of idiomatic and\n",
      "non-idiomatic code. In this paper, we first describe our tool and an evaluation\n",
      "of its performance. Furthermore, we present a case study that demonstrates how\n",
      "to use Teddy in a real-life scenario on an Open Source project. An evaluation\n",
      "shows that Teddy has high precision for detecting Pythonic idiom and\n",
      "non-Pythonic code. Using interactive visualizations, we demonstrate how novice\n",
      "programmers can navigate and identify Pythonic idiom and non-Pythonic code in\n",
      "their projects. Our video demo with the full interactive visualizations is\n",
      "available at https://youtu.be/vOCQReSvBxA.\n",
      "--------\n",
      "Title: Using Python for Model Inference in Deep Learning\n",
      "Summary: Python has become the de-facto language for training deep neural networks,\n",
      "coupling a large suite of scientific computing libraries with efficient\n",
      "libraries for tensor computation such as PyTorch or TensorFlow. However, when\n",
      "models are used for inference they are typically extracted from Python as\n",
      "TensorFlow graphs or TorchScript programs in order to meet performance and\n",
      "packaging constraints. The extraction process can be time consuming, impeding\n",
      "fast prototyping. We show how it is possible to meet these performance and\n",
      "packaging constraints while performing inference in Python. In particular, we\n",
      "present a way of using multiple Python interpreters within a single process to\n",
      "achieve scalable inference and describe a new container format for models that\n",
      "contains both native Python code and data. This approach simplifies the model\n",
      "deployment story by eliminating the model extraction step, and makes it easier\n",
      "to integrate existing performance-enhancing Python libraries. We evaluate our\n",
      "design on a suite of popular PyTorch models on Github, showing how they can be\n",
      "packaged in our inference format, and comparing their performance to\n",
      "TorchScript. For larger models, our packaged Python models perform the same as\n",
      "TorchScript, and for smaller models where there is some Python overhead, our\n",
      "multi-interpreter approach ensures inference is still scalable.\n",
      "--------\n",
      "Title: Machine Learning using Stata/Python\n",
      "Summary: We present two related Stata modules, r_ml_stata and c_ml_stata, for fitting\n",
      "popular Machine Learning (ML) methods both in regression and classification\n",
      "settings. Using the recent Stata/Python integration platform (sfi) of Stata 16,\n",
      "these commands provide hyper-parameters' optimal tuning via K-fold\n",
      "cross-validation using greed search. More specifically, they make use of the\n",
      "Python Scikit-learn API to carry out both cross-validation and outcome/label\n",
      "prediction.\n",
      "--------\n",
      "Title: Python Type Hints are Turing Complete\n",
      "Summary: Grigore showed that Java generics are Turing complete by describing a\n",
      "reduction from Turing machines to Java subtyping. We apply Grigore's algorithm\n",
      "to Python type hints and deduce that they are Turing complete. In addition, we\n",
      "present an alternative reduction in which the Turing machines are simulated in\n",
      "real time, resulting in significantly lower compilation times. Our work is\n",
      "accompanied by a Python implementation of both reductions that compiles Turing\n",
      "machines into Python subtyping machines.\n",
      "--------\n",
      "Title: OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI\n",
      "  Libraries on HPC Systems\n",
      "Summary: Python has become a dominant programming language for emerging areas like\n",
      "Machine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractive\n",
      "feature of Python is that it provides easy-to-use programming interface while\n",
      "allowing library developers to enhance performance of their applications by\n",
      "harnessing the computing power offered by High Performance Computing (HPC)\n",
      "platforms. Efficient communication is key to scaling applications on parallel\n",
      "systems, which is typically enabled by the Message Passing Interface (MPI)\n",
      "standard and compliant libraries on HPC hardware. mpi4py is a Python-based\n",
      "communication library that provides an MPI-like interface for Python\n",
      "applications allowing application developers to utilize parallel processing\n",
      "elements including GPUs. However, there is currently no benchmark suite to\n",
      "evaluate communication performance of mpi4py -- and Python MPI codes in general\n",
      "-- on modern HPC systems. In order to bridge this gap, we propose OMB-Py --\n",
      "Python extensions to the open-source OSU Micro-Benchmark (OMB) suite -- aimed\n",
      "to evaluate communication performance of MPI-based parallel applications in\n",
      "Python. To the best of our knowledge, OMB-Py is the first communication\n",
      "benchmark suite for parallel Python applications. OMB-Py consists of a variety\n",
      "of point-to-point and collective communication benchmark tests that are\n",
      "implemented for a range of popular Python libraries including NumPy, CuPy,\n",
      "Numba, and PyCUDA. Our evaluation reveals that mpi4py introduces a small\n",
      "overhead when compared to native MPI libraries. We plan to publicly release\n",
      "OMB-Py to benefit the Python HPC community.\n",
      "--------\n",
      "Title: Does Coding in Pythonic Zen Peak Performance? Preliminary Experiments of\n",
      "  Nine Pythonic Idioms at Scale\n",
      "Summary: In the field of data science, and for academics in general, the Python\n",
      "programming language is a popular choice, mainly because of its libraries for\n",
      "storing, manipulating, and gaining insight from data. Evidence includes the\n",
      "versatile set of machine learning, data visualization, and manipulation\n",
      "packages used for the ever-growing size of available data. The Zen of Python is\n",
      "a set of guiding design principles that developers use to write acceptable and\n",
      "elegant Python code. Most principles revolve around simplicity. However, as the\n",
      "need to compute large amounts of data, performance has become a necessity for\n",
      "the Python programmer. The new idea in this paper is to confirm whether writing\n",
      "the Pythonic way peaks performance at scale. As a starting point, we conduct a\n",
      "set of preliminary experiments to evaluate nine Pythonic code examples by\n",
      "comparing the performance of both Pythonic and Non-Pythonic code snippets. Our\n",
      "results reveal that writing in Pythonic idioms may save memory and time. We\n",
      "show that incorporating list comprehension, generator expression, zip, and\n",
      "itertools.zip_longest idioms can save up to 7,000 MB and up to 32.25 seconds.\n",
      "The results open more questions on how they could be utilized in a real-world\n",
      "setting. The replication package includes all scripts, and the results are\n",
      "available at https://doi.org/10.5281/zenodo.5712349\n",
      "--------\n",
      "Title: Pydelay - a python tool for solving delay differential equations\n",
      "Summary: pydelay is a python library which translates a system of delay differential\n",
      "equations into C-code and simulates the code using scipy weave.\n",
      "--------\n",
      "Title: How fast can we make interpreted Python?\n",
      "Summary: Python is a popular dynamic language with a large part of its appeal coming\n",
      "from powerful libraries and extension modules. These augment the language and\n",
      "make it a productive environment for a wide variety of tasks, ranging from web\n",
      "development (Django) to numerical analysis (NumPy). Unfortunately, Python's\n",
      "performance is quite poor when compared to modern implementations of languages\n",
      "such as Lua and JavaScript.\n",
      "  Why does Python lag so far behind these other languages? As we show, the very\n",
      "same API and extension libraries that make Python a powerful language also make\n",
      "it very difficult to efficiently execute. Given that we want to retain access\n",
      "to the great extension libraries that already exist for Python, how fast can we\n",
      "make it?\n",
      "  To evaluate this, we designed and implemented Falcon, a high-performance\n",
      "bytecode interpreter fully compatible with the standard CPython interpreter.\n",
      "Falcon applies a number of well known optimizations and introduces several new\n",
      "techniques to speed up execution of Python bytecode. In our evaluation, we\n",
      "found Falcon an average of 25% faster than the standard Python interpreter on\n",
      "most benchmarks and in some cases about 2.5X faster.\n",
      "--------\n",
      "Title: Performance of Python runtimes on a non-numeric scientific code\n",
      "Summary: The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational\n",
      "homology of the moduli space of Riemann surfaces is an example of a non-numeric\n",
      "scientific code: most of the processing it does is generating graphs\n",
      "(represented by complex Python objects) and computing their isomorphisms (a\n",
      "triple of Python lists; again a nested data structure). These operations are\n",
      "repeated many times over: for example, the spaces and are triangulated by\n",
      "4'583'322 and 747'664 graphs, respectively. This is an opportunity for every\n",
      "Python runtime to prove its strength in optimization. The purpose of this\n",
      "experiment was to assess the maturity of alternative Python runtimes, in terms\n",
      "of: compatibility with the language as implemented in CPython 2.7, and\n",
      "performance speedup. This paper compares the results and experiences from\n",
      "running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython\n",
      "0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.\n",
      "--------\n",
      "Title: A Python Extension for the Massively Parallel Multiphysics Simulation\n",
      "  Framework waLBerla\n",
      "Summary: We present a Python extension to the massively parallel HPC simulation\n",
      "toolkit waLBerla. waLBerla is a framework for stencil based algorithms\n",
      "operating on block-structured grids, with the main application field being\n",
      "fluid simulations in complex geometries using the lattice Boltzmann method.\n",
      "Careful performance engineering results in excellent node performance and good\n",
      "scalability to over 400,000 cores. To increase the usability and flexibility of\n",
      "the framework, a Python interface was developed. Python extensions are used at\n",
      "all stages of the simulation pipeline: They simplify and automate scenario\n",
      "setup, evaluation, and plotting. We show how our Python interface outperforms\n",
      "the existing text-file-based configuration mechanism, providing features like\n",
      "automatic nondimensionalization of physical quantities and handling of complex\n",
      "parameter dependencies. Furthermore, Python is used to process and evaluate\n",
      "results while the simulation is running, leading to smaller output files and\n",
      "the possibility to adjust parameters dependent on the current simulation state.\n",
      "C++ data structures are exported such that a seamless interfacing to other\n",
      "numerical Python libraries is possible. The expressive power of Python and the\n",
      "performance of C++ make development of efficient code with low time effort\n",
      "possible.\n",
      "--------\n",
      "Title: Generating Python Code From Object-Z Specifications\n",
      "Summary: Object-Z is an object-oriented specification language which extends the Z\n",
      "language with classes, objects, inheritance and polymorphism that can be used\n",
      "to represent the specification of a complex system as collections of objects.\n",
      "There are a number of existing works that mapped Object-Z to C++ and Java\n",
      "programming languages. Since Python and Object-Z share many similarities, both\n",
      "are object-oriented paradigm, support set theory and predicate calculus\n",
      "moreover, Python is a functional programming language which is naturally closer\n",
      "to formal specifications, we propose a mapping from Object-Z specifications to\n",
      "Python code that covers some Object-Z constructs and express its specifications\n",
      "in Python to validate these specifications. The validations are used in the\n",
      "mapping covered preconditions, post-conditions, and invariants that are built\n",
      "using lambda function and Python's decorator. This work has found Python is an\n",
      "excellent language for developing libraries to map Object-Z specifications to\n",
      "Python.\n",
      "--------\n",
      "Title: Building a scalable python distribution for HEP data analysis\n",
      "Summary: There are numerous approaches to building analysis applications across the\n",
      "high-energy physics community. Among them are Python-based, or at least\n",
      "Python-driven, analysis workflows. We aim to ease the adoption of a\n",
      "Python-based analysis toolkit by making it easier for non-expert users to gain\n",
      "access to Python tools for scientific analysis. Experimental software\n",
      "distributions and individual user analysis have quite different requirements.\n",
      "Distributions tend to worry most about stability, usability and\n",
      "reproducibility, while the users usually strive to be fast and nimble. We\n",
      "discuss how we built and now maintain a python distribution for analysis while\n",
      "satisfying requirements both a large software distribution (in our case, that\n",
      "of CMSSW) and user, or laptop, level analysis. We pursued the integration of\n",
      "tools used by the broader data science community as well as HEP developed\n",
      "(e.g., histogrammar, root_numpy) Python packages. We discuss concepts we\n",
      "investigated for package integration and testing, as well as issues we\n",
      "encountered through this process. Distribution and platform support are\n",
      "important topics. We discuss our approach and progress towards a sustainable\n",
      "infrastructure for supporting this Python stack for the CMS user community and\n",
      "for the broader HEP user community.\n",
      "--------\n",
      "Title: The Dune Python Module\n",
      "Summary: In this paper we present the new Dune-Python module which provides Python\n",
      "bindings for the Dune core, which is a C++ environment for solving partial\n",
      "differential equations. The aim of this new module is to firstly provide the\n",
      "general infrastructure for exporting realizations of statically polymorphic\n",
      "interfaces based on just-in-time compilation and secondly to provide bindings\n",
      "for the central interfaces of the dune core modules. In the first release we\n",
      "focus on the grid interface. Our aim is to only introduce a thin layer when\n",
      "passing objects into Python which can be removed when the object is passed back\n",
      "into a C++ algorithm. Thus no efficiency is lost and little additional code\n",
      "maintenance cost is incurred. To make the transition for Dune users to the\n",
      "Python environment straightforward the Python classes provide a very similar\n",
      "interface to their C++ counterparts. In addition, vectorized versions of many\n",
      "interfaces allow for more efficient code on the Python side. The infrastructure\n",
      "for exporting these interfaces and the resulting bindings for a Dune grid are\n",
      "explained in detail in this paper for both experienced Dune users and others\n",
      "interested in a flexible Python environment for implementing grid based schemes\n",
      "for solving partial differential equations.\n",
      "--------\n",
      "Title: Image Processing in Python With Montage\n",
      "Summary: The Montage image mosaic engine has found wide applicability in astronomy\n",
      "research, integration into processing environments, and is an examplar\n",
      "application for the development of advanced cyber-infrastructure. It is written\n",
      "in C to provide performance and portability. Linking C/C++ libraries to the\n",
      "Python kernel at run time as binary extensions allows them to run under Python\n",
      "at compiled speeds and enables users to take advantage of all the functionality\n",
      "in Python. We have built Python binary extensions of the 59 ANSI-C modules that\n",
      "make up version 5 of the Montage toolkit. This has involved a turning the code\n",
      "into a C library, with driver code fully separated to reproduce the calling\n",
      "sequence of the command-line tools; and then adding Python and C linkage code\n",
      "with the Cython library, which acts as a bridge between general C libraries and\n",
      "the Python interface. We will demonstrate how to use these Python binary\n",
      "extensions to perform image processing, including reprojecting and resampling\n",
      "images, rectifying background emission to a common level, creation of image\n",
      "mosaics that preserve the calibration and astrometric fidelity of the input\n",
      "images, creating visualizations with an adaptive stretch algorithm, processing\n",
      "HEALPix images, and analyzing and managing image metadata.\n",
      "--------\n",
      "Title: An Analysis of Python's Topics, Trends, and Technologies Through Mining\n",
      "  Stack Overflow Discussions\n",
      "Summary: Python is a popular, widely used, and general-purpose programming language.\n",
      "In spite of its ever-growing community, researchers have not performed much\n",
      "analysis on Python's topics, trends, and technologies which provides insights\n",
      "for developers about Python community trends and main issues. In this article,\n",
      "we examine the main topics related to this language being discussed by\n",
      "developers on one of the most popular Q\\&A websites, Stack Overflow, as well as\n",
      "temporal trends through mining 2461876 posts. To be more useful for the\n",
      "software engineers, we study what Python provides as the alternative to popular\n",
      "technologies offered by common programming languages like Java. Our results\n",
      "indicate that discussions about Python standard features, web programming, and\n",
      "scientific programming. Programming in areas such as mathematics, data science,\n",
      "statistics, machine learning, natural language processing (NLP), and so forth.\n",
      "are the most popular areas in the Python community. At the same time, areas\n",
      "related to scientific programming are steadily receiving more attention from\n",
      "the Python developers.\n",
      "--------\n",
      "Title: Python Workflows on HPC Systems\n",
      "Summary: The recent successes and wide spread application of compute intensive machine\n",
      "learning and data analytics methods have been boosting the usage of the Python\n",
      "programming language on HPC systems. While Python provides many advantages for\n",
      "the users, it has not been designed with a focus on multi-user environments or\n",
      "parallel programming - making it quite challenging to maintain stable and\n",
      "secure Python workflows on a HPC system. In this paper, we analyze the key\n",
      "problems induced by the usage of Python on HPC clusters and sketch appropriate\n",
      "workarounds for efficiently maintaining multi-user Python software\n",
      "environments, securing and restricting resources of Python jobs and containing\n",
      "Python processes, while focusing on Deep Learning applications running on GPU\n",
      "clusters.\n",
      "--------\n",
      "Title: Conflict-aware Inference of Python Compatible Runtime Environments with\n",
      "  Domain Knowledge Graph\n",
      "Summary: Code sharing and reuse is a widespread use practice in software engineering.\n",
      "Although a vast amount of open-source Python code is accessible on many online\n",
      "platforms, programmers often find it difficult to restore a successful runtime\n",
      "environment. Previous studies validated automatic inference of Python\n",
      "dependencies using pre-built knowledge bases. However, these studies do not\n",
      "cover sufficient knowledge to accurately match the Python code and also ignore\n",
      "the potential conflicts between their inferred dependencies, thus resulting in\n",
      "a low success rate of inference. In this paper, we propose PyCRE, a new\n",
      "approach to automatically inferring Python compatible runtime environments with\n",
      "domain knowledge graph (KG). Specifically, we design a domain-specific ontology\n",
      "for Python third-party packages and construct KGs for over 10,000 popular\n",
      "packages in Python 2 and Python 3. PyCRE discovers candidate libraries by\n",
      "measuring the matching degree between the known libraries and the third-party\n",
      "resources used in target code. For the NP-complete problem of dependency\n",
      "solving, we propose a heuristic graph traversal algorithm to efficiently\n",
      "guarantee the compatibility between packages. PyCRE achieves superior\n",
      "performance on a real-world dataset and efficiently resolves nearly half more\n",
      "import errors than previous methods.\n",
      "--------\n",
      "Title: Triangulating Python Performance Issues with Scalene\n",
      "Summary: This paper proposes Scalene, a profiler specialized for Python. Scalene\n",
      "combines a suite of innovations to precisely and simultaneously profile CPU,\n",
      "memory, and GPU usage, all with low overhead. Scalene's CPU and memory\n",
      "profilers help Python programmers direct their optimization efforts by\n",
      "distinguishing between inefficient Python and efficient native execution time\n",
      "and memory usage. Scalene's memory profiler employs a novel sampling algorithm\n",
      "that lets it operate with low overhead yet high precision. It also incorporates\n",
      "a novel algorithm that automatically pinpoints memory leaks, whether within\n",
      "Python or across the Python-native boundary. Scalene tracks a new metric called\n",
      "copy volume, which highlights costly copying operations that can occur when\n",
      "Python silently converts between C and Python data representations, or between\n",
      "CPU and GPU. Since its introduction, Scalene has been widely adopted, with over\n",
      "500,000 downloads to date. We present experience reports from developers who\n",
      "used Scalene to achieve significant performance improvements and memory\n",
      "savings.\n",
      "--------\n",
      "Title: Python for education: permutations\n",
      "Summary: Python implementation of permutations is presented. Three classes are\n",
      "introduced: Perm for permutations, Group for permutation groups, and PermError\n",
      "to report any errors for both classes. The class Perm is based on Python\n",
      "dictionaries and utilize cycle notation. The methods of calculation for the\n",
      "perm order, parity, ranking and unranking are given. A random permutation\n",
      "generation is also shown. The class Group is very simple and it is also based\n",
      "on dictionaries. It is mainly the presentation of the permutation groups\n",
      "interface with methods for the group order, subgroups (normalizer, centralizer,\n",
      "center, stabilizer), orbits, and several tests. The corresponding Python code\n",
      "is contained in the modules perms and groups.\n",
      "--------\n",
      "Title: Python bindings for libcloudph++\n",
      "Summary: This technical note introduces the Python bindings for libcloudph++. The\n",
      "libcloudph++ is a C++ library of algorithms for representing atmospheric cloud\n",
      "microphysics in numerical models. The bindings expose the complete\n",
      "functionality of the library to the Python users. The bindings are implemented\n",
      "using the Boost.Python C++ library and use NumPy arrays. This note includes\n",
      "listings with Python scripts exemplifying the use of selected library\n",
      "components. An example solution for using the Python bindings to access\n",
      "libcloudph++ from Fortran is presented.\n",
      "--------\n",
      "Title: Pytrec_eval: An Extremely Fast Python Interface to trec_eval\n",
      "Summary: We introduce pytrec_eval, a Python interface to the tree_eval information\n",
      "retrieval evaluation toolkit. pytrec_eval exposes the reference implementations\n",
      "of trec_eval within Python as a native extension. We show that pytrec_eval is\n",
      "around one order of magnitude faster than invoking trec_eval as a sub process\n",
      "from within Python. Compared to a native Python implementation of NDCG,\n",
      "pytrec_eval is twice as fast for practically-sized rankings. Finally, we\n",
      "demonstrate its effectiveness in an application where pytrec_eval is combined\n",
      "with Pyndri and the OpenAI Gym where query expansion is learned using\n",
      "Q-learning.\n",
      "--------\n",
      "Title: Yaps: Python Frontend to Stan\n",
      "Summary: Stan is a popular probabilistic programming language with a self-contained\n",
      "syntax and semantics that is close to graphical models. Unfortunately, existing\n",
      "embeddings of Stan in Python use multi-line strings. That approach forces users\n",
      "to switch between two different language styles, with no support for syntax\n",
      "highlighting or simple error reporting within the Stan code. This paper tackles\n",
      "the question of whether Stan could use Python syntax while retaining its\n",
      "self-contained semantics. The answer is yes, that can be accomplished by\n",
      "reinterpreting the Python syntax. This paper introduces Yaps, a new frontend to\n",
      "Stan based on reinterpreted Python. We tested Yaps on over a thousand Stan\n",
      "models and made it available open-source.\n",
      "--------\n",
      "Title: Nonparametric Estimation of the Random Coefficients Model in Python\n",
      "Summary: We present $\\textbf{PyRMLE}$, a Python module that implements Regularized\n",
      "Maximum Likelihood Estimation for the analysis of Random Coefficient models.\n",
      "$\\textbf{PyRMLE}$ is simple to use and readily works with data formats that are\n",
      "typical to Random Coefficient problems. The module makes use of Python's\n",
      "scientific libraries $\\textbf{NumPy}$ and $\\textbf{SciPy}$ for computational\n",
      "efficiency. The main implementation of the algorithm is executed purely in\n",
      "Python code which takes advantage of Python's high-level features.\n",
      "--------\n",
      "Title: Running HMC Simulation with Python via QUDA\n",
      "Summary: Lyncs-API is a Python API for Lattice QCD applications. It is designed as a\n",
      "Python toolkit that allows the user to use and run various lattice QCD\n",
      "libraries while programming in Python. The goal is to provide the user an easy\n",
      "programming experience without scarifying performance across multiple\n",
      "platforms, by preparing a common framework for various softwares for lattice\n",
      "QCD calculations. As such, it contains interfaces to, e.g., c-lime, DDalphaAMG,\n",
      "tmLQCD, and QUDA. In this proceeding, we focus on a Lyncs interface to QUDA,\n",
      "named Lyncs-QUDA, and present a small tutorial on how to use this Python\n",
      "interface to perform a HMC simulation using QUDA.\n",
      "--------\n",
      "Title: Python client for Isabelle server\n",
      "Summary: We contribute a Python client for the Isabelle server, which gives\n",
      "researchers and students using Python as their primary programming language an\n",
      "opportunity to communicate with the Isabelle server through TCP directly from a\n",
      "Python script. Such an approach helps avoid the complexities of integrating the\n",
      "existing Python script with languages used for Isabelle development (ML and\n",
      "Scala). We also describe new features that appeared since the announcement of\n",
      "the first version of the client a year ago. Finally, we give examples of the\n",
      "client's applications in research and education and discuss known limitations\n",
      "and possible directions for future development.\n",
      "--------\n",
      "Title: ePython: An implementation of Python for the many-core Epiphany\n",
      "  coprocessor\n",
      "Summary: The Epiphany is a many-core, low power, low on-chip memory architecture and\n",
      "one can very cheaply gain access to a number of parallel cores which is\n",
      "beneficial for HPC education and prototyping. The very low power nature of\n",
      "these architectures also means that there is potential for their use in future\n",
      "HPC machines, however there is a high barrier to entry in programming them due\n",
      "to the associated complexities and immaturity of supporting tools.\n",
      "  In this paper we present our work on ePython, a subset of Python for the\n",
      "Epiphany and similar many-core co-processors. Due to the limited on-chip memory\n",
      "per core we have developed a new Python interpreter and this, combined with\n",
      "additional support for parallelism, has meant that novices can take advantage\n",
      "of Python to very quickly write parallel codes on the Epiphany and explore\n",
      "concepts of HPC using a smaller scale parallel machine. The high level nature\n",
      "of Python opens up new possibilities on the Epiphany, we examine a\n",
      "computationally intensive Gauss-Seidel code from the programmability and\n",
      "performance perspective, discuss running Python hybrid on both the host CPU and\n",
      "Epiphany, and interoperability between a full Python interpreter on the CPU and\n",
      "ePython on the Epiphany. The result of this work is support for developing\n",
      "Python on the Epiphany, which can be applied to other similar architectures,\n",
      "that the community have already started to adopt and use to explore concepts of\n",
      "parallelism and HPC.\n",
      "--------\n",
      "Title: Characterizing Bugs in Python and R Data Analytics Programs\n",
      "Summary: R and Python are among the most popular languages used in many critical data\n",
      "analytics tasks. However, we still do not fully understand the capabilities of\n",
      "these two languages w.r.t. bugs encountered in data analytics tasks. What type\n",
      "of bugs are common? What are the main root causes? What is the relation between\n",
      "bugs and root causes? How to mitigate these bugs? We present a comprehensive\n",
      "study of 5,068 Stack Overflow posts, 1,800 bug fix commits from GitHub\n",
      "repositories, and several GitHub issues of the most used libraries to\n",
      "understand bugs in R and Python. Our key findings include: while both R and\n",
      "Python have bugs due to inexperience with data analysis, Python see\n",
      "significantly larger data preprocessing bugs compared to R. Developers\n",
      "experience significantly more data flow bugs in R because intermediate results\n",
      "are often implicit. We also found changes and bugs in packages and libraries\n",
      "cause more bugs in R compared to Python while package or library misselection\n",
      "and conflicts cause more bugs in Python than R. While R has a slightly higher\n",
      "readability barrier for data analysts, the statistical power of R leads to a\n",
      "less number of bad performance bugs. In terms of data visualization, R packages\n",
      "have significantly more bugs than Python libraries. We also identified a strong\n",
      "correlation between comparable packages in R and Python despite their\n",
      "linguistic and methodological differences. Lastly, we contribute a large\n",
      "dataset of manually verified R and Python bugs.\n",
      "--------\n",
      "Title: Simplifying Parallelization of Scientific Codes by a Function-Centric\n",
      "  Approach in Python\n",
      "Summary: The purpose of this paper is to show how existing scientific software can be\n",
      "parallelized using a separate thin layer of Python code where all parallel\n",
      "communication is implemented. We provide specific examples on such layers of\n",
      "code, and these examples may act as templates for parallelizing a wide set of\n",
      "serial scientific codes. The use of Python for parallelization is motivated by\n",
      "the fact that the language is well suited for reusing existing serial codes\n",
      "programmed in other languages. The extreme flexibility of Python with regard to\n",
      "handling functions makes it very easy to wrap up decomposed computational tasks\n",
      "of a serial scientific application as Python functions. Many\n",
      "parallelization-specific components can be implemented as generic Python\n",
      "functions, which may take as input those functions that perform concrete\n",
      "computational tasks. The overall programming effort needed by this\n",
      "parallelization approach is rather limited, and the resulting parallel Python\n",
      "scripts have a compact and clean structure. The usefulness of the\n",
      "parallelization approach is exemplified by three different classes of\n",
      "applications in natural and social sciences.\n",
      "--------\n",
      "Title: DockerizeMe: Automatic Inference of Environment Dependencies for Python\n",
      "  Code Snippets\n",
      "Summary: Platforms like Stack Overflow and GitHub's gist system promote the sharing of\n",
      "ideas and programming techniques via the distribution of code snippets designed\n",
      "to illustrate particular tasks. Python, a popular and fast-growing programming\n",
      "language, sees heavy use on both sites, with nearly one million questions asked\n",
      "on Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,\n",
      "around 75% of the Python example code shared through these sites cannot be\n",
      "directly executed. When run in a clean environment, over 50% of public Python\n",
      "gists fail due to an import error for a missing library.\n",
      "  We present DockerizeMe, a technique for inferring the dependencies needed to\n",
      "execute a Python code snippet without import error. DockerizeMe starts with\n",
      "offline knowledge acquisition of the resources and dependencies for popular\n",
      "Python packages from the Python Package Index (PyPI). It then builds Docker\n",
      "specifications using a graph-based inference procedure. Our inference procedure\n",
      "resolves import errors in 892 out of nearly 3,000 gists from the Gistable\n",
      "dataset for which Gistable's baseline approach could not find and install all\n",
      "dependencies.\n",
      "--------\n",
      "Title: OpenML-Python: an extensible Python API for OpenML\n",
      "Summary: OpenML is an online platform for open science collaboration in machine\n",
      "learning, used to share datasets and results of machine learning experiments.\n",
      "In this paper we introduce OpenML-Python, a client API for Python, opening up\n",
      "the OpenML platform for a wide range of Python-based tools. It provides easy\n",
      "access to all datasets, tasks and experiments on OpenML from within Python. It\n",
      "also provides functionality to conduct machine learning experiments, upload the\n",
      "results to OpenML, and reproduce results which are stored on OpenML.\n",
      "Furthermore, it comes with a scikit-learn plugin and a plugin mechanism to\n",
      "easily integrate other machine learning libraries written in Python into the\n",
      "OpenML ecosystem. Source code and documentation is available at\n",
      "https://github.com/openml/openml-python/.\n",
      "--------\n",
      "Title: Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations\n",
      "  and visualizations via ParaMonte::Python library\n",
      "Summary: ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial\n",
      "and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for\n",
      "sampling mathematical objective functions, in particular, the posterior\n",
      "distributions of parameters in Bayesian modeling and analysis in data science,\n",
      "Machine Learning, and scientific inference in general. In addition to providing\n",
      "access to fast high-performance serial/parallel Monte Carlo and MCMC sampling\n",
      "routines, the ParaMonte::Python library provides extensive post-processing and\n",
      "visualization tools that aim to automate and streamline the process of model\n",
      "calibration and uncertainty quantification in Bayesian data analysis.\n",
      "Furthermore, the automatically-enabled restart functionality of\n",
      "ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future\n",
      "restart of Monte Carlo simulations, should any interruptions happen. The\n",
      "ParaMonte::Python library is MIT-licensed and is permanently maintained on\n",
      "GitHub at\n",
      "https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.\n",
      "--------\n",
      "Title: Productivity, Portability, Performance: Data-Centric Python\n",
      "Summary: Python has become the de facto language for scientific computing. Programming\n",
      "in Python is highly productive, mainly due to its rich science-oriented\n",
      "software ecosystem built around the NumPy module. As a result, the demand for\n",
      "Python support in High Performance Computing (HPC) has skyrocketed. However,\n",
      "the Python language itself does not necessarily offer high performance. In this\n",
      "work, we present a workflow that retains Python's high productivity while\n",
      "achieving portable performance across different architectures. The workflow's\n",
      "key features are HPC-oriented language extensions and a set of automatic\n",
      "optimizations powered by a data-centric intermediate representation. We show\n",
      "performance results and scaling across CPU, GPU, FPGA, and the Piz Daint\n",
      "supercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups over\n",
      "previous-best solutions, first-ever Xilinx and Intel FPGA results of annotated\n",
      "Python, and up to 93.16% scaling efficiency on 512 nodes.\n",
      "--------\n",
      "Title: PyTracer: Automatically profiling numerical instabilities in Python\n",
      "Summary: Numerical stability is a crucial requirement of reliable scientific\n",
      "computing. However, despite the pervasiveness of Python in data science,\n",
      "analyzing large Python programs remains challenging due to the lack of scalable\n",
      "numerical analysis tools available for this language. To fill this gap, we\n",
      "developed PyTracer, a profiler to quantify numerical instability in Python\n",
      "applications. PyTracer transparently instruments Python code to produce\n",
      "numerical traces and visualize them interactively in a Plotly dashboard. We\n",
      "designed PyTracer to be agnostic to numerical noise model, allowing for tool\n",
      "evaluation through Monte-Carlo Arithmetic, random rounding, random data\n",
      "perturbation, or structured noise for a particular application. We illustrate\n",
      "PyTracer's capabilities by testing the numerical stability of key functions in\n",
      "both SciPy and Scikit-learn, two dominant Python libraries for mathematical\n",
      "modeling. Through these evaluations, we demonstrate PyTracer as a scalable,\n",
      "automatic, and generic framework for numerical profiling in Python.\n",
      "--------\n",
      "Title: GAP-Gen: Guided Automatic Python Code Generation\n",
      "Summary: Automatic code generation from natural language descriptions can be highly\n",
      "beneficial during the process of software development. In this work, we propose\n",
      "GAP-Gen, a Guided Automatic Python Code Generation method based on Python\n",
      "syntactic constraints and semantic constraints. We first introduce Python\n",
      "syntactic constraints in the form of Syntax-Flow, which is a simplified version\n",
      "of Abstract Syntax Tree (AST) reducing the size and high complexity of Abstract\n",
      "Syntax Tree but maintaining crucial syntactic information of Python code. In\n",
      "addition to Syntax-Flow, we introduce Variable-Flow which abstracts variable\n",
      "and function names consistently through out the code. In our work, rather than\n",
      "pretraining, we focus on modifying the finetuning process which reduces\n",
      "computational requirements but retains high generation performance on automatic\n",
      "Python code generation task. GAP-Gen fine-tunes the transformer based language\n",
      "models T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet,\n",
      "CodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Our\n",
      "experiments show that GAP-Gen achieves better results on automatic Python code\n",
      "generation task than previous works.\n",
      "--------\n",
      "Title: Approaches to the Parallelization of Merge Sort in Python\n",
      "Summary: The theory of divide-and-conquer parallelization has been well-studied in the\n",
      "past, providing a solid basis upon which to explore different approaches to the\n",
      "parallelization of merge sort in Python. Python's simplicity and extensive\n",
      "selection of libraries make it the most popular scientific programming\n",
      "language, so it is a fitting language in which to implement and analyze these\n",
      "algorithms.\n",
      "  In this paper, we use Python packages multiprocessing and mpi4py to implement\n",
      "several different parallel merge sort algorithms. Experiments are conducted on\n",
      "an academic supercomputer, upon which benchmarks are performed using Cloudmesh.\n",
      "We find that hybrid multiprocessing merge sort outperforms several other\n",
      "algorithms, achieving a 1.5x speedup compared to the built-in Python sorted()\n",
      "and a 34x speedup compared to sequential merge sort. Our results provide\n",
      "insight into different approaches to implementing parallel merge sort in Python\n",
      "and contribute to the understanding of general divide-and-conquer\n",
      "parallelization in Python on both shared and distributed memory systems.\n",
      "--------\n",
      "Title: Faster or Slower? Performance Mystery of Python Idioms Unveiled with\n",
      "  Empirical Evidence\n",
      "Summary: The usage of Python idioms is popular among Python developers in a formative\n",
      "study of 101 performance-related questions of Python idioms on Stack Overflow,\n",
      "we find that developers often get confused about the performance impact of\n",
      "Python idioms and use anecdotal toy code or rely on personal project experience\n",
      "which is often contradictory in performance outcomes. There has been no\n",
      "large-scale, systematic empirical evidence to reconcile these performance\n",
      "debates. In the paper, we create a large synthetic dataset with 24,126 pairs of\n",
      "non-idiomatic and functionally-equivalent idiomatic code for the nine unique\n",
      "Python idioms identified in Zhang et al., and reuse a large real-project\n",
      "dataset of 54,879 such code pairs provided by Zhang et al. We develop a\n",
      "reliable performance measurement method to compare the speedup or slowdown by\n",
      "idiomatic code against non-idiomatic counterpart, and analyze the performance\n",
      "discrepancies between the synthetic and real-project code, the relationships\n",
      "between code features and performance changes, and the root causes of\n",
      "performance changes at the bytecode level. We summarize our findings as some\n",
      "actionable suggestions for using Python idioms.\n",
      "--------\n",
      "Title: Rapid Development of Interferometric Software Using MIRIAD and Python\n",
      "Summary: New and upgraded radio interferometers produce data at massive rates and will\n",
      "require significant improvements in analysis techniques to reach their promised\n",
      "levels of performance in a routine manner. Until these techniques are fully\n",
      "developed, productivity and accessibility in scientific programming\n",
      "environments will be key bottlenecks in the pipeline leading from data-taking\n",
      "to research results. We present an open-source software package, miriad-python,\n",
      "that allows access to the MIRIAD interferometric reduction system in the Python\n",
      "programming language. The modular design of MIRIAD and the high productivity\n",
      "and accessibility of Python provide an excellent foundation for rapid\n",
      "development of interferometric software. Several other projects with similar\n",
      "goals exist and we describe them and compare miriad-python to them in detail.\n",
      "Along with an overview of the package design, we present sample code and\n",
      "applications, including the detection of millisecond astrophysical transients,\n",
      "determination and application of nonstandard calibration parameters,\n",
      "interactive data visualization, and a reduction pipeline using a directed\n",
      "acyclic graph dependency model analogous to that of the traditional Unix tool\n",
      "\"make\". The key aspects of the miriad-python software project are documented.\n",
      "We find that miriad-python provides an extremely effective environment for\n",
      "prototyping new interferometric software, though certain existing packages\n",
      "provide far more infrastructure for some applications. While equivalent\n",
      "software written in compiled languages can be much faster than Python, there\n",
      "are many situations in which execution time is profitably exchanged for speed\n",
      "of development, code readability, accessibility to nonexpert programmers, quick\n",
      "interlinking with foreign software packages, and other virtues of the Python\n",
      "language.\n",
      "--------\n",
      "Title: Toward Efficient Interactions between Python and Native Libraries\n",
      "Summary: Python has become a popular programming language because of its excellent\n",
      "programmability. Many modern software packages utilize Python for high-level\n",
      "algorithm design and depend on native libraries written in C/C++/Fortran for\n",
      "efficient computation kernels. Interaction between Python code and native\n",
      "libraries introduces performance losses because of the abstraction lying on the\n",
      "boundary of Python and native libraries. On the one side, Python code,\n",
      "typically run with interpretation, is disjoint from its execution behavior. On\n",
      "the other side, native libraries do not include program semantics to understand\n",
      "algorithm defects.\n",
      "  To understand the interaction inefficiencies, we extensively study a large\n",
      "collection of Python software packages and categorize them according to the\n",
      "root causes of inefficiencies. We extract two inefficiency patterns that are\n",
      "common in interaction inefficiencies. Based on these patterns, we develop\n",
      "PieProf, a lightweight profiler, to pinpoint interaction inefficiencies in\n",
      "Python applications. The principle of PieProf is to measure the inefficiencies\n",
      "in the native execution and associate inefficiencies with high-level Python\n",
      "code to provide a holistic view. Guided by PieProf, we optimize 17 real-world\n",
      "applications, yielding speedups up to 6.3$\\times$ on application level.\n",
      "--------\n",
      "Title: Improving Tese Case Generation for Python Native Libraries Through\n",
      "  Constraints on Input Data Structures\n",
      "Summary: Modern Python projects execute computational functions using native libraries\n",
      "and give Python interfaces to boost execution speed; hence, testing these\n",
      "libraries becomes critical to the project's robustness. One challenge is that\n",
      "existing approaches use coverage to guide generation, but native libraries run\n",
      "as black boxes to Python code with no execution information. Another is that\n",
      "dynamic binary instrumentation reduces testing performance as it needs to\n",
      "monitor both native libraries and the Python virtual machine.\n",
      "  To address these challenges, in this paper, we propose an automated test case\n",
      "generation approach that works at the Python code layer. Our insight is that\n",
      "many path conditions in native libraries are for processing input data\n",
      "structures through interacting with the VM. In our approach, we instrument the\n",
      "Python Interpreter to monitor the interactions between native libraries and VM,\n",
      "derive constraints on the structures, and then use the constraints to guide\n",
      "test case generation. We implement our approach in a tool named PyCing and\n",
      "apply it to six widely-used Python projects. The experimental results reveal\n",
      "that with the structure constraint guidance, PyCing can cover more execution\n",
      "paths than existing test cases and state-of-the-art tools. Also, with the\n",
      "checkers in the testing framework Pytest, PyCing can identify segmentation\n",
      "faults in 10 Python interfaces and memory leaks in 9. Our instrumentation\n",
      "strategy also has an acceptable influence on testing efficiency.\n",
      "--------\n",
      "Title: binary_c-python: A Python-based stellar population synthesis tool and\n",
      "  interface to binary_c\n",
      "Summary: We present the software package binary_c-python which provides a convenient\n",
      "and easy-to-use interface to the binary_c framework, allowing the user to\n",
      "rapidly evolve individual systems and populations of stars. binary_c-python is\n",
      "available on Pip and on GitLab. binary_c-python contains many useful features\n",
      "to control and process the output of binary_c, like by providing\n",
      "binary_c-python with logging statements that are dynamically compiled and\n",
      "loaded into binary_c. Moreover, we have recently added standardised output of\n",
      "events like Roche-lobe overflow or double compact-object formation to binary_c,\n",
      "and automatic parsing and managing of that output in binary_c-python.\n",
      "binary_c-python uses multiprocessing to utilise all the cores on a particular\n",
      "machine, and can run populations with HPC cluster workload managers like\n",
      "HTCondor and Slurm, allowing the user to run simulations on large computing\n",
      "clusters. We provide documentation that is automatically generated based on\n",
      "docstrings and a suite of Jupyter notebooks. These notebooks consist of\n",
      "technical tutorials on how to use binary_c-python and use-case scenarios aimed\n",
      "at doing science. Much of binary_c-python is covered by unit tests to ensure\n",
      "reliability and correctness, and the test coverage is continually increased as\n",
      "the package is improved.\n",
      "--------\n",
      "Title: PyMsOfa: A Python Package for the Standards of Fundamental Astronomy\n",
      "  (SOFA) Service\n",
      "Summary: The Standards of Fundamental Astronomy (SOFA) is a service provided by the\n",
      "International Astronomical Union (IAU) that offers algorithms and software for\n",
      "astronomical calculations, which was released in two versions by FORTRAN 77 and\n",
      "ANSI C, respectively. In this work, we implement the python package PyMsOfa for\n",
      "SOFA service by three ways: (1) a python wrapper package based on a foreign\n",
      "function library for Python (ctypes), (2) a python wrapper package with the\n",
      "foreign function interface for Python calling C code (cffi), and (3) a python\n",
      "package directly written in pure python codes from SOFA subroutines. The\n",
      "package PyMsOfa has fully implemented 247 functions of the original SOFA\n",
      "routines. In addition, PyMsOfa is also extensively examined, which is exactly\n",
      "consistent with those test examples given by the original SOFA. This python\n",
      "package can be suitable to not only the astrometric detection of habitable\n",
      "planets of the Closeby Habitable Exoplanet Survey (CHES) mission (Ji et al.\n",
      "2022), but also for the frontiers themes of black holes and dark matter related\n",
      "to astrometric calculations and other fields. The source codes are available\n",
      "via https://github.com/CHES2023/PyMsOfa.\n",
      "--------\n",
      "Title: Python for Education: Computational Methods for Nonlinear Systems\n",
      "Summary: We describe a novel, interdisciplinary, computational methods course that\n",
      "uses Python and associated numerical and visualization libraries to enable\n",
      "students to implement simulations for a number of different course modules.\n",
      "Problems in complex networks, biomechanics, pattern formation, and gene\n",
      "regulation are highlighted to illustrate the breadth and flexibility of\n",
      "Python-powered computational environments.\n",
      "--------\n",
      "Title: Implementation of Kalman Filter with Python Language\n",
      "Summary: In this paper, we investigate the implementation of a Python code for a\n",
      "Kalman Filter using the Numpy package. A Kalman Filtering is carried out in two\n",
      "steps: Prediction and Update. Each step is investigated and coded as a function\n",
      "with matrix input and output. These different functions are explained and an\n",
      "example of a Kalman Filter application for the localization of mobile in\n",
      "wireless networks is given.\n",
      "--------\n",
      "Title: A Framework for Distributed Deep Learning Layer Design in Python\n",
      "Summary: In this paper, a framework for testing Deep Neural Network (DNN) design in\n",
      "Python is presented. First, big data, machine learning (ML), and Artificial\n",
      "Neural Networks (ANNs) are discussed to familiarize the reader with the\n",
      "importance of such a system. Next, the benefits and detriments of implementing\n",
      "such a system in Python are presented. Lastly, the specifics of the system are\n",
      "explained, and some experimental results are presented to prove the\n",
      "effectiveness of the system.\n",
      "--------\n",
      "Title: Want Drugs? Use Python\n",
      "Summary: We describe how Python can be leveraged to streamline the curation, modelling\n",
      "and dissemination of drug discovery data as well as the development of\n",
      "innovative, freely available tools for the related scientific community. We\n",
      "look at various examples, such as chemistry toolkits, machine-learning\n",
      "applications and web frameworks and show how Python can glue it all together to\n",
      "create efficient data science pipelines.\n",
      "--------\n",
      "Title: Geoplotlib: a Python Toolbox for Visualizing Geographical Data\n",
      "Summary: We introduce geoplotlib, an open-source python toolbox for visualizing\n",
      "geographical data. geoplotlib supports the development of hardware-accelerated\n",
      "interactive visualizations in pure python, and provides implementations of dot\n",
      "maps, kernel density estimation, spatial graphs, Voronoi tesselation,\n",
      "shapefiles and many more common spatial visualizations. We describe geoplotlib\n",
      "design, functionalities and use cases.\n",
      "--------\n",
      "Title: Powerbox: A Python package for creating structured fields with isotropic\n",
      "  power spectra\n",
      "Summary: Powerbox is a pure-Python package for creating and measuring structured\n",
      "fields with homogeneous and isotropic power spectra.\n",
      "--------\n",
      "Title: TimeGym: Debugging for Time Series Modeling in Python\n",
      "Summary: We introduce the TimeGym Forecasting Debugging Toolkit, a Python library for\n",
      "testing and debugging time series forecasting pipelines. TimeGym simplifies the\n",
      "testing forecasting pipeline by providing generic tests for forecasting\n",
      "pipelines fresh out of the box. These tests are based on common modeling\n",
      "challenges of time series. Our library enables forecasters to apply a\n",
      "Test-Driven Development approach to forecast modeling, using specified oracles\n",
      "to generate artificial data with noise.\n",
      "--------\n",
      "Title: MontePython: Implementing Quantum Monte Carlo using Python\n",
      "Summary: We present a cross-language C++/Python program for simulations of quantum\n",
      "mechanical systems with the use of Quantum Monte Carlo (QMC) methods. We\n",
      "describe a system for which to apply QMC, the algorithms of variational Monte\n",
      "Carlo and diffusion Monte Carlo and we describe how to implement theses methods\n",
      "in pure C++ and C++/Python. Furthermore we check the efficiency of the\n",
      "implementations in serial and parallel cases to show that the overhead using\n",
      "Python can be negligible.\n",
      "--------\n",
      "Title: HOOMD-blue: A Python package for high-performance molecular dynamics and\n",
      "  hard particle Monte Carlo simulations\n",
      "Summary: HOOMD-blue is a particle simulation engine designed for nano- and\n",
      "colloidal-scale molecular dynamics and hard particle Monte Carlo simulations.\n",
      "It has been actively developed since March 2007 and available open source since\n",
      "August 2008. HOOMD-blue is a Python package with a high performance C++/CUDA\n",
      "backend that we built from the ground up for GPU acceleration. The Python\n",
      "interface allows users to combine HOOMD-blue with with other packages in the\n",
      "Python ecosystem to create simulation and analysis workflows. We employ\n",
      "software engineering practices to develop, test, maintain, and expand the code.\n",
      "--------\n",
      "Title: Plyades: A Python Library for Space Mission Design\n",
      "Summary: Plyades: A Python Library for Space Mission Design Designing a space mission\n",
      "is a computation-heavy task. Software tools that conduct the necessary\n",
      "numerical simulations and optimizations are therefore indispensable. The\n",
      "usability of existing software, written in Fortran and MATLAB, suffers because\n",
      "of high complexity, low levels of abstraction and out-dated programming\n",
      "practices. We propose Python as a viable alternative for astrodynamics tools\n",
      "and demonstrate the proof-of-concept library Plyades which combines powerful\n",
      "features with Pythonic ease of use.\n",
      "--------\n",
      "Title: A Practical Python API for Querying AFLOWLIB\n",
      "Summary: Large databases such as aflowlib.org provide valuable data sources for\n",
      "discovering material trends through machine learning. Although a REST API and\n",
      "query language are available, there is a learning curve associated with the\n",
      "AFLUX language that acts as a barrier for new users. Additionally, the data is\n",
      "stored using non-standard serialization formats. Here we present a high-level\n",
      "API that allows immediate access to the aflowlib data using standard python\n",
      "operators and language features. It provides an easy way to integrate aflowlib\n",
      "data with other python materials packages such as ase and quippy, and provides\n",
      "automatic deserialization into numpy arrays and python objects. This package is\n",
      "available via \"pip install aflow\".\n",
      "--------\n",
      "Title: salmon: A Symbolic Linear Regression Package for Python\n",
      "Summary: One of the most attractive features of R is its linear modeling capabilities.\n",
      "We describe a Python package, salmon, that brings the best of R's linear\n",
      "modeling functionality to Python in a Pythonic way -- by providing composable\n",
      "objects for specifying and fitting linear models. This object-oriented design\n",
      "also enables other features that enhance ease-of-use, such as automatic\n",
      "visualizations and intelligent model building.\n",
      "--------\n",
      "Title: pySiDR: Python Event Reconstruction for SiD\n",
      "Summary: Event reconstruction in the ILC community has typically relied on algorithms\n",
      "implemented in C++, a fast compiled language. However, the Python package\n",
      "pyLCIO provides a full interface to tracker and calorimeter hits stored in LCIO\n",
      "files, opening up the possibility to implement reconstruction algorithms in a\n",
      "language uniquely well suited to working with large lists of hits built with\n",
      "list comprehensions. Python, an interpreted language which can perform complex\n",
      "tasks with minimal code, also allows seamless integration with powerful machine\n",
      "learning tools developed recently. We discuss pySiDR, a Python package for SiD\n",
      "event reconstruction.\n",
      "--------\n",
      "Title: FitsGeo -- Python package for PHITS geometry development and\n",
      "  visualization\n",
      "Summary: An easy way to define and visualize geometry for PHITS input files\n",
      "introduced. Suggested FitsGeo Python package helps to define surfaces as Python\n",
      "objects and manipulate them conveniently. VPython assists to view defined\n",
      "geometry interactively which boosts geometry development and helps with\n",
      "complicated cases. Every class that sets the surface object has methods with\n",
      "some extra properties. As well as geometry generation for PHITS input,\n",
      "additional modules developed for material and cell definition. Any user with a\n",
      "very basic knowledge of Python can define the geometry in a convenient way and\n",
      "use it in further research related to particle transport.\n",
      "--------\n",
      "Title: HDPython: A High Level Python Based Object-Oriented HDL Framework\n",
      "Summary: We present a High-Level Python-based Hardware Description Language\n",
      "(HDPython), It uses Python as its source language and converts it to standard\n",
      "VHDL. Compared to other approaches of building converters from a high-level\n",
      "programming language into a hardware description language, this new approach\n",
      "aims to maintain an object-oriented paradigm throughout the entire process.\n",
      "Instead of removing all the high-level features from Python to make it into an\n",
      "HDL, this approach goes the opposite way. It tries to show how certain features\n",
      "from a high-level language can be implemented in an HDL, providing the\n",
      "corresponding benefits of high-level programming for the user.\n",
      "--------\n",
      "Title: cellanneal: A User-Friendly Deconvolution Software for Omics Data\n",
      "Summary: We introduce cellanneal, a python-based software for deconvolving bulk RNA\n",
      "sequencing data. cellanneal relies on the optimization of Spearman's rank\n",
      "correlation coefficient between experimental and computational mixture gene\n",
      "expression vectors using simulated annealing. cellanneal can be used as a\n",
      "python package or via a command line interface, but importantly also provides a\n",
      "simple graphical user interface which is distributed as a single executable\n",
      "file for user convenience. The python package is available at\n",
      "https://github.com/LiBuchauer/cellanneal , the graphical software can be\n",
      "downloaded at http://shalevlab.weizmann.ac.il/resources .\n",
      "--------\n",
      "Title: Asgl: A Python Package for Penalized Linear and Quantile Regression\n",
      "Summary: Asg is a Python package that solves penalized linear regression and quantile\n",
      "regression models for simultaneous variable selection and prediction, for both\n",
      "high and low dimensional frameworks. It makes very easy to set up and solve\n",
      "different types of lasso-based penalizations among which the asgl (adaptive\n",
      "sparse group lasso, that gives name to the package) is remarked. This package\n",
      "is built on top of cvxpy, a Python-embedded modeling language for convex\n",
      "optimization problems and makes extensive use of multiprocessing, a Python\n",
      "module for parallel computing that significantly reduces computation times of\n",
      "asgl.\n",
      "--------\n",
      "Title: Scalpel: The Python Static Analysis Framework\n",
      "Summary: Despite being the most popular programming language, Python has not yet\n",
      "received enough attention from the community. To the best of our knowledge,\n",
      "there is no general static analysis framework proposed to facilitate the\n",
      "implementation of dedicated Python static analyzers. To fill this gap, we\n",
      "design and implement such a framework (named Scalpel) and make it publicly\n",
      "available as an open-source project. The Scalpel framework has already\n",
      "integrated a number of fundamental static analysis functions (e.g., call graph\n",
      "constructions, control-flow graph constructions, alias analysis, etc.) that are\n",
      "ready to be reused by developers to implement client applications focusing on\n",
      "statically resolving dedicated Python problems such as detecting bugs or fixing\n",
      "vulnerabilities.\n",
      "--------\n",
      "Title: Modernizing the ESRF beamline application software architecture with\n",
      "  generic Python modules\n",
      "Summary: We report on the modernization of the ESRF beamline application software with\n",
      "Python modules. The current building blocks used around the SPEC data\n",
      "acquisition software together with the new elements are presented.\n",
      "--------\n",
      "Title: Multi-Agent Programming Contest 2011 - The Python-DTU Team\n",
      "Summary: We provide a brief description of the Python-DTU system, including the\n",
      "overall design, the tools and the algorithms that we plan to use in the agent\n",
      "contest.\n",
      "--------\n",
      "Title: Proceedings of the 6th European Conference on Python in Science\n",
      "  (EuroSciPy 2013)\n",
      "Summary: These are the proceedings of the 6th European Conference on Python in\n",
      "Science, EuroSciPy 2013, that was held in Brussels (21-25 August 2013).\n",
      "--------\n",
      "Title: Py-oopsi: the python implementation of the fast-oopsi algorithm\n",
      "Summary: Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widely\n",
      "used to extract neuron spike activities from calcium fluorescence signals.\n",
      "Here, we propose detailed implementation of the fast-oopsi algorithm in python\n",
      "programming language. Some corrections are also made to the original fast-oopsi\n",
      "paper.\n",
      "--------\n",
      "Title: Proceedings of the 7th European Conference on Python in Science\n",
      "  (EuroSciPy 2014)\n",
      "Summary: These are the proceedings of the 7th European Conference on Python in\n",
      "Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).\n",
      "--------\n",
      "Title: PythonFOAM: In-situ data analyses with OpenFOAM and Python\n",
      "Summary: We outline the development of a general-purpose Python-based data analysis\n",
      "tool for OpenFOAM. Our implementation relies on the construction of OpenFOAM\n",
      "applications that have bindings to data analysis libraries in Python. Double\n",
      "precision data in OpenFOAM is cast to a NumPy array using the NumPy C-API and\n",
      "Python modules may then be used for arbitrary data analysis and manipulation on\n",
      "flow-field information. We highlight how the proposed wrapper may be used for\n",
      "an in-situ online singular value decomposition (SVD) implemented in Python and\n",
      "accessed from the OpenFOAM solver PimpleFOAM. Here, `in-situ' refers to a\n",
      "programming paradigm that allows for a concurrent computation of the data\n",
      "analysis on the same computational resources utilized for the partial\n",
      "differential equation solver. In addition, to demonstrate data-parallel\n",
      "analyses, we deploy a distributed SVD, which collects snapshot data across the\n",
      "ranks of a distributed simulation to compute the global left singular vectors.\n",
      "Crucially, both OpenFOAM and Python share the same message passing interface\n",
      "(MPI) communicator for this deployment which allows Python objects and\n",
      "functions to exchange NumPy arrays across ranks. Subsequently, we provide\n",
      "scaling assessments of this distributed SVD on multiple nodes of Intel\n",
      "Broadwell and KNL architectures for canonical test cases such as the large eddy\n",
      "simulations of a backward facing step and a channel flow at friction Reynolds\n",
      "number of 395. Finally, we demonstrate the deployment of a deep neural network\n",
      "for compressing the flow-field information using an autoencoder to demonstrate\n",
      "an ability to use state-of-the-art machine learning tools in the Python\n",
      "ecosystem.\n",
      "--------\n",
      "Title: Python Crypto Misuses in the Wild\n",
      "Summary: Background: Previous studies have shown that up to 99.59 % of the Java apps\n",
      "using crypto APIs misuse the API at least once. However, these studies have\n",
      "been conducted on Java and C, while empirical studies for other languages are\n",
      "missing. For example, a controlled user study with crypto tasks in Python has\n",
      "shown that 68.5 % of the professional developers write a secure solution for a\n",
      "crypto task. Aims: To understand if this observation holds for real-world code,\n",
      "we conducted a study of crypto misuses in Python. Method: We developed a static\n",
      "analysis tool that covers common misuses of 5 different Python crypto APIs.\n",
      "With this analysis, we analyzed 895 popular Python projects from GitHub and 51\n",
      "MicroPython projects for embedded devices. Further, we compared our results\n",
      "with the findings of previous studies. Results: Our analysis reveals that 52.26\n",
      "% of the Python projects have at least one misuse. Further, some Python crypto\n",
      "libraries API design helps developers from misusing crypto functions, which\n",
      "were much more common in studies conducted with Java and C code. Conclusion: We\n",
      "conclude that we can see a positive impact of the good API design on crypto\n",
      "misuses for Python applications. Further, our analysis of MicroPython projects\n",
      "reveals the importance of hybrid analyses.\n",
      "--------\n",
      "Title: An array-oriented Python interface for FastJet\n",
      "Summary: Analysis on HEP data is an iterative process in which the results of one step\n",
      "often inform the next. In an exploratory analysis, it is common to perform one\n",
      "computation on a collection of events, then view the results (often with\n",
      "histograms) to decide what to try next. Awkward Array is a Scikit-HEP Python\n",
      "package that enables data analysis with array-at-a-time operations to implement\n",
      "cuts as slices, combinatorics as composable functions, etc. However, most C++\n",
      "HEP libraries, such as FastJet, have an imperative, one-particle-at-a-time\n",
      "interface, which would be inefficient in Python and goes against the grain of\n",
      "the array-at-a-time logic of scientific Python. Therefore, we developed\n",
      "fastjet, a pip-installable Python package that provides FastJet C++ binaries,\n",
      "the classic (particle-at-a-time) Python interface, and the new array-oriented\n",
      "interface for use with Awkward Array.\n",
      "  The new interface streamlines interoperability with scientific Python\n",
      "software beyond HEP, such as machine learning. In one case, adopting this\n",
      "library along with other array-oriented tools accelerated HEP analysis code by\n",
      "a factor of 20. It was designed to be easily integrated with libraries in the\n",
      "Scikit-HEP ecosystem, including Uproot (file I/O), hist (histogramming), Vector\n",
      "(Lorentz vectors), and Coffea (high-level glue). We discuss the design of the\n",
      "fastjet Python library, integrating the classic interface with the array\n",
      "oriented interface and with the Vector library for Lorentz vector operations.\n",
      "The new interface was developed as open source.\n",
      "--------\n",
      "Title: Deep Learning: From Basics to Building Deep Neural Networks with Python\n",
      "Summary: This book is intended for beginners who have no familiarity with deep\n",
      "learning. Our only expectation from readers is that they already have the basic\n",
      "programming skills in Python.\n",
      "--------\n",
      "Title: The Awkward World of Python and C++\n",
      "Summary: There are undeniable benefits of binding Python and C++ to take advantage of\n",
      "the best features of both languages. This is especially relevant to the HEP and\n",
      "other scientific communities that have invested heavily in the C++ frameworks\n",
      "and are rapidly moving their data analyses to Python. Version 2 of Awkward\n",
      "Array, a Scikit-HEP Python library, introduces a set of header-only C++\n",
      "libraries that do not depend on any application binary interface. Users can\n",
      "directly include these libraries in their compilation rather than linking\n",
      "against platform-specific libraries. This new development makes the integration\n",
      "of Awkward Arrays into other projects easier and more portable as the\n",
      "implementation is easily separable from the rest of the Awkward Array codebase.\n",
      "The code is minimal, it does not include all of the code needed to use Awkward\n",
      "Arrays in Python, nor does it include references to Python or pybind11. The C++\n",
      "users can use it to make arrays and then copy them to Python without any\n",
      "specialized data types - only raw buffers, strings, and integers. This C++ code\n",
      "also simplifies the process of just-in-time (JIT) compilation in ROOT. This\n",
      "implementation approach solves some of the drawbacks, like packaging projects\n",
      "where native dependencies can be challenging. In this paper, we demonstrate the\n",
      "technique to integrate C++ and Python by using a header-only approach. We also\n",
      "describe the implementation of a new LayoutBuilder and a GrowableBuffer.\n",
      "Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposing\n",
      "Awkward Arrays to C++ without copying them are discussed.\n",
      "--------\n",
      "Title: SlipCover: Near Zero-Overhead Code Coverage for Python\n",
      "Summary: Coverage analysis is widely used but can suffer from high overhead. This\n",
      "overhead is especially acute in the context of Python, which is already\n",
      "notoriously slow (a recent study observes a roughly 30x slowdown vs. native\n",
      "code). We find that the state-of-the-art coverage tool for Python,\n",
      "coverage$.$py, introduces a median overhead of 180% with the standard Python\n",
      "interpreter. Slowdowns are even more extreme when using PyPy, a JIT-compiled\n",
      "Python implementation, with coverage$.$py imposing a median overhead of 1,300%.\n",
      "This performance degradation reduces the utility of coverage analysis in most\n",
      "use cases, including testing and fuzzing, and precludes its use in deployment.\n",
      "This paper presents SlipCover, a novel, near-zero overhead coverage analyzer\n",
      "for Python. SlipCover works without modifications to either the Python\n",
      "interpreter or PyPy. It first processes a program's AST to accurately identify\n",
      "all branches and lines. SlipCover then dynamically rewrites Python bytecodes to\n",
      "add lightweight instrumentation to each identified branch and line. At run\n",
      "time, SlipCover periodically de-instruments already-covered lines and branches.\n",
      "The result is extremely low overheads -- a median of just 5% -- making\n",
      "SlipCover suitable for use in deployment. We show its efficiency can translate\n",
      "to significant increases in the speed of coverage-based clients. As a proof of\n",
      "concept, we integrate SlipCover into TPBT, a targeted property-based testing\n",
      "system, and observe a 22x speedup.\n",
      "--------\n",
      "Title: Cosmic Microwave Background Anisotropy Measurement From Python V\n",
      "Summary: We analyze observations of the microwave sky made with the Python experiment\n",
      "in its fifth year of operation at the Amundsen-Scott South Pole Station in\n",
      "Antarctica. After modeling the noise and constructing a map, we extract the\n",
      "cosmic signal from the data. We simultaneously estimate the angular power\n",
      "spectrum in eight bands ranging from large (l ~ 40) to small (l ~ 260) angular\n",
      "scales, with power detected in the first six bands. There is a significant rise\n",
      "in the power spectrum from large to smaller (l ~ 200) scales, consistent with\n",
      "that expected from acoustic oscillations in the early Universe. We compare this\n",
      "Python V map to a map made from data taken in the third year of Python. Python\n",
      "III observations were made at a frequency of 90 GHz and covered a subset of the\n",
      "region of the sky covered by Python V observations, which were made at 40 GHz.\n",
      "Good agreement is obtained both visually (with a filtered version of the map)\n",
      "and via a likelihood ratio test.\n",
      "--------\n",
      "Title: Solve the Master Equation by Python-An Introduction to the Python\n",
      "  Computing Environment\n",
      "Summary: A brief introduction to the Python computing environment is given. By solving\n",
      "the master equation encountered in quantum transport, we give an example of how\n",
      "to solve the ODE problems in Python. The ODE solvers used are the ZVODE routine\n",
      "in Scipy and the bsimp solver in GSL. For the former, the equation can be in\n",
      "its complex-valued form, while for the latter, it has to be rewritten to a\n",
      "real-valued form. The focus is on the detailed workflow of the implementation\n",
      "process, rather than on the syntax of the python language, with the hope to\n",
      "help readers simulate their own models in Python.\n",
      "--------\n",
      "Title: FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC\n",
      "  libraries\n",
      "Summary: The Python package fluidfft provides a common Python API for performing Fast\n",
      "Fourier Transforms (FFT) in sequential, in parallel and on GPU with different\n",
      "FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT\n",
      "framework which allows Python users to easily and efficiently perform FFT and\n",
      "the associated tasks, such as as computing linear operators and energy spectra.\n",
      "We describe the architecture of the package composed of C++ and Cython FFT\n",
      "classes, Python \"operator\" classes and Pythran functions. The package supplies\n",
      "utilities to easily test itself and benchmark the different FFT solutions for a\n",
      "particular case and on a particular machine. We present a performance scaling\n",
      "analysis on three different computing clusters and a microbenchmark showing\n",
      "that fluidfft is an interesting solution to write efficient Python applications\n",
      "using FFT.\n",
      "--------\n",
      "Title: Speeding simulation analysis up with yt and Intel Distribution for\n",
      "  Python\n",
      "Summary: As modern scientific simulations grow ever more in size and complexity, even\n",
      "their analysis and post-processing becomes increasingly demanding, calling for\n",
      "the use of HPC resources and methods. yt is a parallel, open source\n",
      "post-processing python package for numerical simulations in astrophysics, made\n",
      "popular by its cross-format compatibility, its active community of developers\n",
      "and its integration with several other professional Python instruments. The\n",
      "Intel Distribution for Python enhances yt's performance and parallel\n",
      "scalability, through the optimization of lower-level libraries Numpy and Scipy,\n",
      "which make use of the optimized Intel Math Kernel Library (Intel-MKL) and the\n",
      "Intel MPI library for distributed computing. The library package yt is used for\n",
      "several analysis tasks, including integration of derived quantities, volumetric\n",
      "rendering, 2D phase plots, cosmological halo analysis and production of\n",
      "synthetic X-ray observation. In this paper, we provide a brief tutorial for the\n",
      "installation of yt and the Intel Distribution for Python, and the execution of\n",
      "each analysis task. Compared to the Anaconda python distribution, using the\n",
      "provided solution one can achieve net speedups up to 4.6x on Intel Xeon\n",
      "Scalable processors (codename Skylake).\n",
      "--------\n",
      "Title: Scalene: Scripting-Language Aware Profiling for Python\n",
      "Summary: Existing profilers for scripting languages (a.k.a. \"glue\" languages) like\n",
      "Python suffer from numerous problems that drastically limit their usefulness.\n",
      "They impose order-of-magnitude overheads, report information at too coarse a\n",
      "granularity, or fail in the face of threads. Worse, past\n",
      "profilers---essentially variants of their counterparts for C---are oblivious to\n",
      "the fact that optimizing code in scripting languages requires information about\n",
      "code spanning the divide between the scripting language and libraries written\n",
      "in compiled languages.\n",
      "  This paper introduces scripting-language aware profiling, and presents\n",
      "Scalene, an implementation of scripting-language aware profiling for Python.\n",
      "Scalene employs a combination of sampling, inference, and disassembly of\n",
      "byte-codes to efficiently and precisely attribute execution time and memory\n",
      "usage to either Python, which developers can optimize, or library code, which\n",
      "they cannot. It includes a novel sampling memory allocator that reports\n",
      "line-level memory consumption and trends with low overhead, helping developers\n",
      "reduce footprints and identify leaks. Finally, it introduces a new metric, copy\n",
      "volume, to help developers root out insidious copying costs across the\n",
      "Python/library boundary, which can drastically degrade performance. Scalene\n",
      "works for single or multi-threaded Python code, is precise, reporting detailed\n",
      "information at the line granularity, while imposing modest overheads\n",
      "(26%--53%).\n",
      "--------\n",
      "Title: Extending Python for Quantum-Classical Computing via Quantum\n",
      "  Just-in-Time Compilation\n",
      "Summary: Python is a popular programming language known for its flexibility,\n",
      "usability, readability, and focus on developer productivity. The quantum\n",
      "software community has adopted Python on a number of large-scale efforts due to\n",
      "these characteristics, as well as the remote nature of near-term quantum\n",
      "processors. The use of Python has enabled quick prototyping for quantum code\n",
      "that directly benefits pertinent research and development efforts in quantum\n",
      "scientific computing. However, this rapid prototyping ability comes at the cost\n",
      "of future performant integration for tightly-coupled CPU-QPU architectures with\n",
      "fast-feedback. Here we present a language extension to Python that enables\n",
      "heterogeneous quantum-classical computing via a robust C++ infrastructure for\n",
      "quantum just-in-time (QJIT) compilation. Our work builds off the QCOR C++\n",
      "language extension and compiler infrastructure to enable a single-source,\n",
      "quantum hardware-agnostic approach to quantum-classical computing that retains\n",
      "the performance required for tightly coupled CPU-QPU compute models. We detail\n",
      "this Pythonic extension, its programming model and underlying software\n",
      "architecture, and provide a robust set of examples to demonstrate the utility\n",
      "of our approach.\n",
      "--------\n",
      "Title: An Empirical Study of Automated Unit Test Generation for Python\n",
      "Summary: Various mature automated test generation tools exist for statically typed\n",
      "programming languages such as Java. Automatically generating unit tests for\n",
      "dynamically typed programming languages such as Python, however, is\n",
      "substantially more difficult due to the dynamic nature of these languages as\n",
      "well as the lack of type information. Our Pynguin framework provides automated\n",
      "unit test generation for Python. In this paper, we extend our previous work on\n",
      "Pynguin to support more aspects of the Python language, and by studying a\n",
      "larger variety of well-established state of the art test-generation algorithms,\n",
      "namely DynaMOSA, MIO, and MOSA. Furthermore, we improved our Pynguin tool to\n",
      "generate regression assertions, whose quality we also evaluate. Our experiments\n",
      "confirm that evolutionary algorithms can outperform random test generation also\n",
      "in the context of Python, and similar to the Java world, DynaMOSA yields the\n",
      "highest coverage results. However, our results also demonstrate that there are\n",
      "still fundamental remaining issues, such as inferring type information for code\n",
      "without this information, currently limiting the effectiveness of test\n",
      "generation for Python.\n",
      "--------\n",
      "Title: An Exploratory Study on the Predominant Programming Paradigms in Python\n",
      "  Code\n",
      "Summary: Python is a multi-paradigm programming language that fully supports\n",
      "object-oriented (OO) programming. The language allows writing code in a\n",
      "non-procedural imperative manner, using procedures, using classes, or in a\n",
      "functional style. To date, no one has studied what paradigm(s), if any, are\n",
      "predominant in Python code and projects. In this work, we first define a\n",
      "technique to classify Python files into predominant paradigm(s). We then\n",
      "automate our approach and evaluate it against human judgements, showing over\n",
      "80% agreement. We then analyze over 100k open-source Python projects,\n",
      "automatically classifying each source file and investigating the paradigm\n",
      "distributions. The results indicate Python developers tend to heavily favor OO\n",
      "features. We also observed a positive correlation between OO and procedural\n",
      "paradigms and the size of the project. And despite few files or projects being\n",
      "predominantly functional, we still found many functional feature uses.\n",
      "--------\n",
      "Title: A Data Set of Generalizable Python Code Change Patterns\n",
      "Summary: Mining repetitive code changes from version control history is a common way\n",
      "of discovering unknown change patterns. Such change patterns can be used in\n",
      "code recommender systems or automated program repair techniques. While there\n",
      "are such tools and datasets exist for Java, there is little work on finding and\n",
      "recommending such changes in Python. In this paper, we present a data set of\n",
      "manually vetted generalizable Python repetitive code change patterns. We create\n",
      "a coding guideline to identify generalizable change patterns that can be used\n",
      "in automated tooling. We leverage the mined change patterns from recent work\n",
      "that mines repetitive changes in Python projects and use our coding guideline\n",
      "to manually review the patterns. For each change, we also record a description\n",
      "of the change and why it is applied along with other characteristics such as\n",
      "the number of projects it occurs in. This review process allows us to identify\n",
      "and share 72 Python change patterns that can be used to build and advance\n",
      "Python developer support tools.\n",
      "--------\n",
      "Title: Scalable Demand-Driven Call Graph Generation for Python\n",
      "Summary: Call graph generation is the foundation of inter-procedural static analysis.\n",
      "PyCG is the state-of-the-art approach for generating call graphs for Python\n",
      "programs. Unfortunately, PyCG does not scale to large programs when adapted to\n",
      "whole-program analysis where dependent libraries are also analyzed. Further,\n",
      "PyCG does not support demand-driven analysis where only the reachable functions\n",
      "from given entry functions are analyzed. Moreover, PyCG is flow-insensitive and\n",
      "does not fully support Python's features, hindering its accuracy. To overcome\n",
      "these drawbacks, we propose a scalable demand-driven approach for generating\n",
      "call graphs for Python programs, and implement it as a prototype tool Jarvis.\n",
      "Jarvis maintains an assignment graph (i.e., points-to relations between program\n",
      "identifiers) for each function in a program to allow reuse and improve\n",
      "scalability. Given a set of entry functions as the demands, Jarvis generates\n",
      "the call graph on-the-fly, where flow-sensitive intra-procedural analysis and\n",
      "inter-procedural analysis are conducted in turn. Our evaluation on a\n",
      "micro-benchmark of 135 small Python programs and a macro-benchmark of 6\n",
      "real-world Python applications has demonstrated that Jarvis can significantly\n",
      "improve PyCG by at least 67% faster in time, 84% higher in precision, and at\n",
      "least 10% higher in recall.\n",
      "--------\n",
      "Title: Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for\n",
      "  Tetrad Causal Search\n",
      "Summary: We give novel Python and R interfaces for the (Java) Tetrad project for\n",
      "causal modeling, search, and estimation. The Tetrad project is a mainstay in\n",
      "the literature, having been under consistent development for over 30 years.\n",
      "Some of its algorithms are now classics, like PC and FCI; others are recent\n",
      "developments. It is increasingly the case, however, that researchers need to\n",
      "access the underlying Java code from Python or R. Existing methods for doing\n",
      "this are inadequate. We provide new, up-to-date methods using the JPype\n",
      "Python-Java interface and the Reticulate Python-R interface, directly solving\n",
      "these issues. With the addition of some simple tools and the provision of\n",
      "working examples for both Python and R, using JPype and Reticulate to interface\n",
      "Python and R with Tetrad is straightforward and intuitive.\n",
      "--------\n",
      "Title: High performance Python for direct numerical simulations of turbulent\n",
      "  flows\n",
      "Summary: Direct Numerical Simulations (DNS) of the Navier Stokes equations is an\n",
      "invaluable research tool in fluid dynamics. Still, there are few publicly\n",
      "available research codes and, due to the heavy number crunching implied,\n",
      "available codes are usually written in low-level languages such as C/C++ or\n",
      "Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS\n",
      "code that nearly matches the performance of C++ for thousands of processors and\n",
      "billions of unknowns. We also describe a version optimized through Cython, that\n",
      "is found to match the speed of C++. The solvers are written from scratch in\n",
      "Python, both the mesh, the MPI domain decomposition, and the temporal\n",
      "integrators. The solvers have been verified and benchmarked on the Shaheen\n",
      "supercomputer at the KAUST supercomputing laboratory, and we are able to show\n",
      "very good scaling up to several thousand cores.\n",
      "  A very important part of the implementation is the mesh decomposition (we\n",
      "implement both slab and pencil decompositions) and 3D parallel Fast Fourier\n",
      "Transforms (FFT). The mesh decomposition and FFT routines have been implemented\n",
      "in Python using serial FFT routines (either NumPy, pyFFTW or any other serial\n",
      "FFT module), NumPy array manipulations and with MPI communications handled by\n",
      "MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT\n",
      "in Python for a slab mesh decomposition using 4 lines of compact Python code,\n",
      "for which the parallel performance on Shaheen is found to be slightly better\n",
      "than similar routines provided through the FFTW library. For a pencil mesh\n",
      "decomposition 7 lines of code is required to execute a transform.\n",
      "--------\n",
      "Title: PyArmadillo: a streamlined linear algebra library for Python\n",
      "Summary: PyArmadillo is a linear algebra library for the Python language, with the aim\n",
      "of closely mirroring the programming interface of the widely used Armadillo C++\n",
      "library, which in turn is deliberately similar to Matlab. PyArmadillo hence\n",
      "facilitates algorithm prototyping with Matlab-like syntax directly in Python,\n",
      "and relatively straightforward conversion of PyArmadillo-based Python code into\n",
      "performant Armadillo-based C++ code. The converted code can be used for\n",
      "purposes such as speeding up Python-based programs in conjunction with\n",
      "pybind11, or the integration of algorithms originally prototyped in Python into\n",
      "larger C++ codebases. PyArmadillo provides objects for matrices and cubes, as\n",
      "well as over 200 associated functions for manipulating data stored in the\n",
      "objects. Integer, floating point and complex numbers are supported. Various\n",
      "matrix factorisations are provided through integration with LAPACK, or one of\n",
      "its high performance drop-in replacements such as Intel MKL or OpenBLAS.\n",
      "PyArmadillo is open-source software, distributed under the Apache 2.0 license;\n",
      "it can be obtained at https://pyarma.sourceforge.io or via the Python Package\n",
      "Index in precompiled form.\n",
      "--------\n",
      "Title: PyCG: Practical Call Graph Generation in Python\n",
      "Summary: Call graphs play an important role in different contexts, such as profiling\n",
      "and vulnerability propagation analysis. Generating call graphs in an efficient\n",
      "manner can be a challenging task when it comes to high-level languages that are\n",
      "modular and incorporate dynamic features and higher-order functions.\n",
      "  Despite the language's popularity, there have been very few tools aiming to\n",
      "generate call graphs for Python programs. Worse, these tools suffer from\n",
      "several effectiveness issues that limit their practicality in realistic\n",
      "programs. We propose a pragmatic, static approach for call graph generation in\n",
      "Python. We compute all assignment relations between program identifiers of\n",
      "functions, variables, classes, and modules through an inter-procedural\n",
      "analysis. Based on these assignment relations, we produce the resulting call\n",
      "graph by resolving all calls to potentially invoked functions. Notably, the\n",
      "underlying analysis is designed to be efficient and scalable, handling several\n",
      "Python features, such as modules, generators, function closures, and multiple\n",
      "inheritance.\n",
      "  We have evaluated our prototype implementation, which we call PyCG, using two\n",
      "benchmarks: a micro-benchmark suite containing small Python programs and a set\n",
      "of macro-benchmarks with several popular real-world Python packages. Our\n",
      "results indicate that PyCG can efficiently handle thousands of lines of code in\n",
      "less than a second (0.38 seconds for 1k LoC on average). Further, it\n",
      "outperforms the state-of-the-art for Python in both precision and recall: PyCG\n",
      "achieves high rates of precision ~99.2%, and adequate recall ~69.9%. Finally,\n",
      "we demonstrate how PyCG can aid dependency impact analysis by showcasing a\n",
      "potential enhancement to GitHub's \"security advisory\" notification service\n",
      "using a real-world example.\n",
      "--------\n",
      "Title: Python for Smarter Cities: Comparison of Python libraries for static and\n",
      "  interactive visualisations of large vector data\n",
      "Summary: Local governments, as part of 'smart city' initiatives and to promote\n",
      "interoperability, are increasingly incorporating open-source software into\n",
      "their data management, analysis, and visualisation workflows. Python, with its\n",
      "concise and natural syntax, presents a low barrier to entry for municipal staff\n",
      "without computer science backgrounds. However, with regard to geospatial\n",
      "visualisations in particular, the range of available Python libraries has\n",
      "diversified to such an extent that identifying candidate libraries for specific\n",
      "use cases is a challenging undertaking. This study therefore assesses\n",
      "prominent, actively-developed visualisation libraries in the Python ecosystem\n",
      "with respect to their suitability for producing visualisations of large vector\n",
      "datasets. A simple visualisation task common in urban development is used to\n",
      "produce near-identical thematic maps across static and an interactive 'tracks'\n",
      "of comparison. All short-listed libraries were able to generate the sample map\n",
      "products for both a small and larger dataset. Code complexity differed more\n",
      "strongly for interactive visualisations. Formal and informal documentation\n",
      "channels are highlighted to outline available resources for flattening learning\n",
      "curves. CPU runtimes for the Python-based portion of the process chain differed\n",
      "starkly for both tracks, pointing to avenues for further research. These\n",
      "results demonstrate that the Python ecosystem offers local governments powerful\n",
      "tools, free of vendor lock-in and licensing fees, to produce performant and\n",
      "consistently formatted visualisations for both internal and public\n",
      "distribution.\n",
      "--------\n",
      "Title: An Empirical Study of Fault Localization in Python Programs\n",
      "Summary: Despite its massive popularity as a programming language, especially in novel\n",
      "domains like data science programs, there is comparatively little research\n",
      "about fault localization that targets Python. Even though it is plausible that\n",
      "several findings about programming languages like C/C++ and Java -- the most\n",
      "common choices for fault localization research -- carry over to other\n",
      "languages, whether the dynamic nature of Python and how the language is used in\n",
      "practice affect the capabilities of classic fault localization approaches\n",
      "remain open questions to investigate.\n",
      "  This paper is the first large-scale empirical study of fault localization on\n",
      "real-world Python programs and faults. Using Zou et al.'s recent large-scale\n",
      "empirical study of fault localization in Java as the basis of our study, we\n",
      "investigated the effectiveness (i.e., localization accuracy), efficiency (i.e.,\n",
      "runtime performance), and other features (e.g., different entity granularities)\n",
      "of seven well-known fault-localization techniques in four families\n",
      "(spectrum-based, mutation-based, predicate switching, and stack-trace based) on\n",
      "135 faults from 13 open-source Python projects from the BugsInPy curated\n",
      "collection.\n",
      "  The results replicate for Python several results known about Java, and shed\n",
      "light on whether Python's peculiarities affect the capabilities of fault\n",
      "localization. The replication package that accompanies this paper includes\n",
      "detailed data about our experiments, as well as the tool FauxPy that we\n",
      "implemented to conduct the study.\n",
      "--------\n",
      "Title: Does Python Smell Like Java? Tool Support for Design Defect Discovery in\n",
      "  Python\n",
      "Summary: The context of this work is specification, detection and ultimately removal\n",
      "of detectable harmful patterns in source code that are associated with defects\n",
      "in design and implementation of software. In particular, we investigate five\n",
      "code smells and four antipatterns previously defined in papers and books. Our\n",
      "inquiry is about detecting those in source code written in Python programming\n",
      "language, which is substantially different from all prior research, most of\n",
      "which concerns Java or C-like languages. Our approach was that of software\n",
      "engineers: we have processed existing research literature on the topic,\n",
      "extracted both the abstract definitions of nine design defects and their\n",
      "concrete implementation specifications, implemented them all in a tool we have\n",
      "programmed and let it loose on a huge test set obtained from open source code\n",
      "from thousands of GitHub projects. When it comes to knowledge, we have found\n",
      "that more than twice as many methods in Python can be considered too long\n",
      "(statistically extremely longer than their neighbours within the same project)\n",
      "than in Java, but long parameter lists are seven times less likely to be found\n",
      "in Python code than in Java code. We have also found that Functional\n",
      "Decomposition, the way it was defined for Java, is not found in the Python code\n",
      "at all, and Spaghetti Code and God Classes are extremely rare there as well.\n",
      "The grounding and the confidence in these results comes from the fact that we\n",
      "have performed our experiments on 32'058'823 lines of Python code, which is by\n",
      "far the largest test set for a freely available Python parser. We have also\n",
      "designed the experiment in such a way that it aligned with prior research on\n",
      "design defect detection in Java in order to ease the comparison if we treat our\n",
      "own actions as a replication. Thus, the importance of the work is both in the\n",
      "unique open Python grammar of highest quality, tested on millions of lines of\n",
      "code, and in the design defect detection tool which works on something else\n",
      "than Java.\n",
      "--------\n",
      "Title: Python I, II, and III CMB Anisotropy Measurement Constraints on Open and\n",
      "  Flat-Lambda CDM Cosmogonies\n",
      "Summary: We use Python I, II, and III cosmic microwave background anisotropy data to\n",
      "constrain cosmogonies. We account for the Python beamwidth and calibration\n",
      "uncertainties. We consider open and spatially-flat-Lambda cold dark matter\n",
      "cosmogonies, with nonrelativistic-mass density parameter Omega_0 in the range\n",
      "0.1--1, baryonic-mass density parameter Omega_B in the range (0.005--0.029)\n",
      "h^{-2}, and age of the universe t_0 in the range (10--20) Gyr. Marginalizing\n",
      "over all parameters but Omega_0, the combined Python data favors an open\n",
      "(spatially-flat-Lambda) model with Omega_0 simeq 0.2 (0.1). At the 2 sigma\n",
      "confidence level model normalizations deduced from the combined Python data are\n",
      "mostly consistent with those drawn from the DMR, UCSB South Pole 1994, ARGO,\n",
      "MAX 4 and 5, White Dish, and SuZIE data sets.\n",
      "--------\n",
      "Title: PyNetMet: Python tools for efficient work with networks and metabolic\n",
      "  models\n",
      "Summary: Background: The study of genome-scale metabolic models and their underlying\n",
      "networks is one of the most important fields in systems biology. The complexity\n",
      "of these models and their description makes the use of computational tools an\n",
      "essential element in their research. Therefore there is a strong need of\n",
      "efficient and versatile computational tools for the research in this area.\n",
      "  Results: In this manuscript we present PyNetMet, a Python library of tools to\n",
      "work with networks and metabolic models. These are open-source free tools for\n",
      "use in a Python platform, which adds considerably versatility to them when\n",
      "compared with their desktop software similars. On the other hand these tools\n",
      "allow one to work with different standards of metabolic models (OptGene and\n",
      "SBML) and the fact that they are programmed in Python opens the possibility of\n",
      "efficient integration with any other already existing Python tool.\n",
      "  Conclusions: PyNetMet is, therefore, a collection of computational tools that\n",
      "will facilitate the research work with metabolic models and networks.\n",
      "--------\n",
      "Title: A Python-based Post-processing Toolset For Seismic Analyses\n",
      "Summary: This paper discusses the design and implementation of a Python-based toolset\n",
      "to aid in assessing the response of the UK's Advanced Gas Reactor nuclear power\n",
      "stations to earthquakes. The seismic analyses themselves are carried out with a\n",
      "commercial Finite Element solver, but understanding the raw model output this\n",
      "produces requires customised post-processing and visualisation tools. Extending\n",
      "the existing tools had become increasingly difficult and a decision was made to\n",
      "develop a new, Python-based toolset. This comprises of a post-processing\n",
      "framework (aftershock) which includes an embedded Python interpreter, and a\n",
      "plotting package (afterplot) based on numpy and matplotlib. The new toolset had\n",
      "to be significantly more flexible and easier to maintain than the existing\n",
      "code-base, while allowing the majority of development to be carried out by\n",
      "engineers with little training in software development. The resulting\n",
      "architecture will be described with a focus on exploring how the design drivers\n",
      "were met and the successes and challenges arising from the choices made.\n",
      "--------\n",
      "Title: Rabacus: A Python Package for Analytic Cosmological Radiative Transfer\n",
      "  Calculations\n",
      "Summary: We describe Rabacus, a Python package for calculating the transfer of\n",
      "hydrogen ionizing radiation in simplified geometries relevant to astronomy and\n",
      "cosmology. We present example solutions for three specific cases: 1) a\n",
      "semi-infinite slab gas distribution in a homogeneous isotropic background, 2) a\n",
      "spherically symmetric gas distribution with a point source at the center, and\n",
      "3) a spherically symmetric gas distribution in a homogeneous isotropic\n",
      "background. All problems can accommodate arbitrary spectra and density profiles\n",
      "as input. The solutions include a treatment of both hydrogen and helium, a\n",
      "self-consistent calculation of equilibrium temperatures, and the transfer of\n",
      "recombination radiation. The core routines are written in Fortran 90 and then\n",
      "wrapped in Python leading to execution speeds thousands of times faster than\n",
      "equivalent routines written in pure Python. In addition, all variables have\n",
      "associated units for ease of analysis. The software is part of the Python\n",
      "Package Index and the source code is available on Bitbucket at\n",
      "https://bitbucket.org/galtay/rabacus . In addition, installation instructions\n",
      "and a detailed users guide are available at http://pythonhosted.org//rabacus .\n",
      "--------\n",
      "Title: Weighted graph algorithms with Python\n",
      "Summary: Python implementation of selected weighted graph algorithms is presented. The\n",
      "minimal graph interface is defined together with several classes implementing\n",
      "this interface. Graph nodes can be any hashable Python objects. Directed edges\n",
      "are instances of the Edge class. Graphs are instances of the Graph class. It is\n",
      "based on the adjacency-list representation, but with fast lookup of nodes and\n",
      "neighbors (dict-of-dict structure). Other implementations of this class are\n",
      "also possible.\n",
      "  In this work, many algorithms are implemented using a unified approach. There\n",
      "are separate classes and modules devoted to different algorithms. Three\n",
      "algorithms for finding a minimum spanning tree are implemented: the Boruvka's\n",
      "algorithm, the Prim's algorithm (three implementations), and the Kruskal's\n",
      "algorithm. Three algorithms for solving the single-source shortest path problem\n",
      "are implemented: the dag shortest path algorithm, the Bellman-Ford algorithm,\n",
      "and the Dijkstra's algorithm (two implementations). Two algorithms for solving\n",
      "all-pairs shortest path problem are implemented: the Floyd-Warshall algorithm\n",
      "and the Johnson's algorithm.\n",
      "  All algorithms were tested by means of the unittest module, the Python unit\n",
      "testing framework. Additional computer experiments were done in order to\n",
      "compare real and theoretical computational complexity. The source code is\n",
      "available from the public GitHub repository.\n",
      "--------\n",
      "***************************** Acquisition et stockage de la matière première ***********************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: arxiv\n",
      "Titre: Egg-smol Python: A Pythonic Library for E-graphs\n",
      "Auteur: Saul Shanabrook\n",
      "Date: 2023-05-07\n",
      "URL: http://arxiv.org/abs/2305.04311v1\n",
      "Texte: E-graphs have emerged as a versatile data structure with applications insynthesis, optimization, and verification through techniques such as equalitysaturation. This paper introduces Python bindings for the experimental egg-smollibrary, which aims to bring the benefits of e-graphs to the Python ecosystem.The bindings offer a high-level, Pythonic API providing an accessible andfamiliar interface for Python users. By integrating e-graph techniques withPython, we hope to enable collaboration and innovation across various domainsin the scientific computing and machine learning communities. We discuss theadvantages of using Python bindings for both Python and existing egg-smolusers, as well as possible future directions for development.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Making Python Code Idiomatic by Automatic Refactoring Non-Idiomatic\n",
      "  Python Code with Pythonic Idioms\n",
      "Auteur: Zejun Zhang\n",
      "Date: 2022-07-12\n",
      "URL: http://arxiv.org/abs/2207.05613v1\n",
      "Texte: Compared to other programming languages (e.g., Java), Python has more idiomsto make Python code concise and efficient. Although pythonic idioms are wellaccepted in the Python community, Python programmers are often faced with manychallenges in using them, for example, being unaware of certain pythonic idiomsor do not know how to use them properly. Based on an analysis of 7,638 Pythonrepositories on GitHub, we find that non-idiomatic Python code that can beimplemented with pythonic idioms occurs frequently and widely. Unfortunately,there is no tool for automatically refactoring such non-idiomatic code intoidiomatic code. In this paper, we design and implement an automatic refactoringtool to make Python code idiomatic. We identify nine pythonic idioms bysystematically contrasting the abstract syntax grammar of Python and Java. Thenwe define the syntactic patterns for detecting non-idiomatic code for eachpythonic idiom. Finally, we devise atomic AST-rewriting operations andrefactoring steps to refactor non-idiomatic code into idiomatic code. We testand review over 4,115 refactorings applied to 1,065 Python projects fromGitHub, and submit 90 pull requests for the 90 randomly sampled refactorings to84 projects. These evaluations confirm the high-accuracy, practicality andusefulness of our refactoring tool on real-world Python code. Our refactoringtool can be accessed at 47.242.131.128:5000.\n",
      "Co-auteurs: Zhenchang Xing, Xin Xia, Xiwei Xu, Liming Zhu\n",
      "Source: arxiv\n",
      "Titre: Modern Python at the Large Synoptic Survey Telescope\n",
      "Auteur: Tim Jenness\n",
      "Date: 2017-12-01\n",
      "URL: http://arxiv.org/abs/1712.00461v1\n",
      "Texte: The LSST software systems make extensive use of Python, with almost all of itinitially being developed solely in Python 2. Since LSST will be commissionedwhen Python 2 is end-of-lifed it is critical that we have all our code supportPython 3 before commissioning begins. Over the past year we have madesignificant progress in migrating the bulk of the code from the Data Managementsystem onto Python 3. This paper presents our migration methodology, and thecurrent status of the port, with our eventual aim to be running completely onPython 3 by early 2018. We also discuss recent modernizations to our Pythoncodebase.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Python GUI Scripting Interface for Running Atomic Physics Applications\n",
      "Auteur: Amani Tahat\n",
      "Date: 2011-06-05\n",
      "URL: http://arxiv.org/abs/1106.0868v1\n",
      "Texte: We create a Python GUI scripting interface working under Windows in additionto (UNIX/Linux). The GUI has been built around the Python open-sourceprogramming language. We use the Python's GUI library that so called PythonMega Widgets (PMW) and based on Tkinter Python module(http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI wasmotivated primarily by the desire of more updated operations, more flexibilityincorporating future and current improvements in producing atomic data.Furthermore it will be useful for a variety of applications of atomic physics,plasma physics and astrophysics and will help in calculating various atomicproperties.\n",
      "Co-auteurs: Mofleh Tahat\n",
      "Source: arxiv\n",
      "Titre: Towards Memory Safe Python Enclave for Security Sensitive Computation\n",
      "Auteur: Huibo Wang\n",
      "Date: 2020-05-12\n",
      "URL: http://arxiv.org/abs/2005.05996v1\n",
      "Texte: Intel SGX Guard eXtensions (SGX), a hardware-supported trusted executionenvironment (TEE), is designed to protect security-sensitive applications.However, since enclave applications are developed with memory unsafe languagessuch as C/C++, traditional memory corruption is not eliminated in SGX. Rust-SGXis the first toolkit providing enclave developers with a memory-language.However, Rust is considered a Systems language and has become the right choicefor concurrent applications and web browsers. Many application domains such asBig Data, Machine Learning, Robotics, Computer Vision are more commonlydeveloped in the python programming language. Therefore, Python applicationdevelopers cannot benefit from secure enclaves like Intel SGX and rust-SGX. Tofill this gap, we propose Python-SGX, which is a memory-safe SGX SDK providingenclave developers a memory-safe Python development environment. The key ideais to enable memory-safe Python language in SGX by solving the following keychallenges: (1) defining a memory-safe Python interpreter (2)replacing unsafeelements of Python interpreter with safe ones,(3) achieving comparableperformance to non-enclave Python applications, and (4) not introducing anyunsafe new code or libraries into SGX. We propose to build Python-SGX withPyPy, a Python interpreter written by RPython, which is a subset of Python, andtame unsafe parts in PyPy by formal verification, security hardening, andmemory safe language. We have implemented python-SGX and tested it with aseries of benchmarks programs. Our evaluation results show that Python-SGX doesnot cause significant overhead.\n",
      "Co-auteurs: Mingshen Sun, Qian Feng, Pei Wang, Tongxin Li, Yu Ding\n",
      "Source: arxiv\n",
      "Titre: Porting the LSST Data Management Pipeline Software to Python 3\n",
      "Auteur: Tim Jenness\n",
      "Date: 2016-11-02\n",
      "URL: http://arxiv.org/abs/1611.00751v1\n",
      "Texte: The LSST data management science pipelines software consists of more than100,000 lines of Python 2 code. LSST operations will begin after support forPython 2 has been dropped by the Python community in 2020, and we musttherefore plan to migrate the codebase to Python 3. During the transitionperiod we must also support our community of active Python 2 users and thiscomplicates the porting significantly. We have decided to use the Python futurepackage as the basis for our port to enable support for Python 2 and Python 3simultaneously, whilst developing with a mindset more suited to Python 3. Inthis paper we report on the current status of the port and the difficultiesthat have been encountered.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: A general approach for running Python codes in OpenFOAM using an\n",
      "  embedded pybind11 Python interpreter\n",
      "Auteur: Simon Rodriguez\n",
      "Date: 2022-03-30\n",
      "URL: http://arxiv.org/abs/2203.16394v1\n",
      "Texte: As the overlap between traditional computational mechanics and machinelearning grows, there is an increasing demand for straight-forward approachesto interface Python-based procedures with C++-based OpenFOAM. This articleintroduces one such general methodology, allowing the execution of Python codedirectly within an OpenFOAM solver without the need for Python codetranslation. The proposed approach is based on the lightweight librarypybind11, where OpenFOAM data is transferred to an embedded Python interpreterfor manipulation, and results are returned as needed. Following a review ofrelated approaches, the article describes the approach, with a particular focuson data transfer between Python and OpenFOAM, executing Python scripts andfunctions, and practical details about the implementation in OpenFOAM. Threecomplementary test cases are presented to highlight the functionality anddemonstrate the effect of different data transfer approaches: a Python-basedvelocity profile boundary condition; a Python-based solver for prototyping; anda machine learning mechanical constitutive law class for solids4foam whichperforms field calculations.\n",
      "Co-auteurs: Philip Cardiff\n",
      "Source: arxiv\n",
      "Titre: Python for education: the exact cover problem\n",
      "Auteur: Andrzej Kapanowski\n",
      "Date: 2010-10-28\n",
      "URL: http://arxiv.org/abs/1010.5890v1\n",
      "Texte: Python implementation of Algorithm X by Knuth is presented. Algorithm X findsall solutions to the exact cover problem. The exemplary results forpentominoes, Latin squares and Sudoku are given.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Teddy: Automatic Recommendation of Pythonic Idiom Usage For Pull-Based\n",
      "  Software Projects\n",
      "Auteur: Purit Phan-udom\n",
      "Date: 2020-09-05\n",
      "URL: http://arxiv.org/abs/2009.03302v1\n",
      "Texte: Pythonic code is idiomatic code that follows guiding principles and practiceswithin the Python community. Offering performance and readability benefits,Pythonic code is claimed to be widely adopted by experienced Python developers,but can be a learning curve to novice programmers. To aid with Pythoniclearning, we create an automated tool, called Teddy, that can help checking thePythonic idiom usage. The tool offers a prevention mode with Just-In-Timeanalysis to recommend the use of Pythonic idiom during code review and adetection mode with historical analysis to run a thorough scan of idiomatic andnon-idiomatic code. In this paper, we first describe our tool and an evaluationof its performance. Furthermore, we present a case study that demonstrates howto use Teddy in a real-life scenario on an Open Source project. An evaluationshows that Teddy has high precision for detecting Pythonic idiom andnon-Pythonic code. Using interactive visualizations, we demonstrate how noviceprogrammers can navigate and identify Pythonic idiom and non-Pythonic code intheir projects. Our video demo with the full interactive visualizations isavailable at https://youtu.be/vOCQReSvBxA.\n",
      "Co-auteurs: Naruedon Wattanakul, Tattiya Sakulniwat, Chaiyong Ragkhitwetsagul, Thanwadee Sunetnanta, Morakot Choetkiertikul, Raula Gaikovina Kula\n",
      "Source: arxiv\n",
      "Titre: Using Python for Model Inference in Deep Learning\n",
      "Auteur: Zachary DeVito\n",
      "Date: 2021-04-01\n",
      "URL: http://arxiv.org/abs/2104.00254v1\n",
      "Texte: Python has become the de-facto language for training deep neural networks,coupling a large suite of scientific computing libraries with efficientlibraries for tensor computation such as PyTorch or TensorFlow. However, whenmodels are used for inference they are typically extracted from Python asTensorFlow graphs or TorchScript programs in order to meet performance andpackaging constraints. The extraction process can be time consuming, impedingfast prototyping. We show how it is possible to meet these performance andpackaging constraints while performing inference in Python. In particular, wepresent a way of using multiple Python interpreters within a single process toachieve scalable inference and describe a new container format for models thatcontains both native Python code and data. This approach simplifies the modeldeployment story by eliminating the model extraction step, and makes it easierto integrate existing performance-enhancing Python libraries. We evaluate ourdesign on a suite of popular PyTorch models on Github, showing how they can bepackaged in our inference format, and comparing their performance toTorchScript. For larger models, our packaged Python models perform the same asTorchScript, and for smaller models where there is some Python overhead, ourmulti-interpreter approach ensures inference is still scalable.\n",
      "Co-auteurs: Jason Ansel, Will Constable, Michael Suo, Ailing Zhang, Kim Hazelwood\n",
      "Source: arxiv\n",
      "Titre: Machine Learning using Stata/Python\n",
      "Auteur: Giovanni Cerulli\n",
      "Date: 2021-03-03\n",
      "URL: http://arxiv.org/abs/2103.03122v1\n",
      "Texte: We present two related Stata modules, r_ml_stata and c_ml_stata, for fittingpopular Machine Learning (ML) methods both in regression and classificationsettings. Using the recent Stata/Python integration platform (sfi) of Stata 16,these commands provide hyper-parameters' optimal tuning via K-foldcross-validation using greed search. More specifically, they make use of thePython Scikit-learn API to carry out both cross-validation and outcome/labelprediction.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Python Type Hints are Turing Complete\n",
      "Auteur: Ori Roth\n",
      "Date: 2022-08-31\n",
      "URL: http://arxiv.org/abs/2208.14755v1\n",
      "Texte: Grigore showed that Java generics are Turing complete by describing areduction from Turing machines to Java subtyping. We apply Grigore's algorithmto Python type hints and deduce that they are Turing complete. In addition, wepresent an alternative reduction in which the Turing machines are simulated inreal time, resulting in significantly lower compilation times. Our work isaccompanied by a Python implementation of both reductions that compiles Turingmachines into Python subtyping machines.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: OMB-Py: Python Micro-Benchmarks for Evaluating Performance of MPI\n",
      "  Libraries on HPC Systems\n",
      "Auteur: Nawras Alnaasan\n",
      "Date: 2021-10-20\n",
      "URL: http://arxiv.org/abs/2110.10659v2\n",
      "Texte: Python has become a dominant programming language for emerging areas likeMachine Learning (ML), Deep Learning (DL), and Data Science (DS). An attractivefeature of Python is that it provides easy-to-use programming interface whileallowing library developers to enhance performance of their applications byharnessing the computing power offered by High Performance Computing (HPC)platforms. Efficient communication is key to scaling applications on parallelsystems, which is typically enabled by the Message Passing Interface (MPI)standard and compliant libraries on HPC hardware. mpi4py is a Python-basedcommunication library that provides an MPI-like interface for Pythonapplications allowing application developers to utilize parallel processingelements including GPUs. However, there is currently no benchmark suite toevaluate communication performance of mpi4py -- and Python MPI codes in general-- on modern HPC systems. In order to bridge this gap, we propose OMB-Py --Python extensions to the open-source OSU Micro-Benchmark (OMB) suite -- aimedto evaluate communication performance of MPI-based parallel applications inPython. To the best of our knowledge, OMB-Py is the first communicationbenchmark suite for parallel Python applications. OMB-Py consists of a varietyof point-to-point and collective communication benchmark tests that areimplemented for a range of popular Python libraries including NumPy, CuPy,Numba, and PyCUDA. Our evaluation reveals that mpi4py introduces a smalloverhead when compared to native MPI libraries. We plan to publicly releaseOMB-Py to benefit the Python HPC community.\n",
      "Co-auteurs: Arpan Jain, Aamir Shafi, Hari Subramoni, Dhabaleswar K Panda\n",
      "Source: arxiv\n",
      "Titre: Does Coding in Pythonic Zen Peak Performance? Preliminary Experiments of\n",
      "  Nine Pythonic Idioms at Scale\n",
      "Auteur: Pattara Leelaprute\n",
      "Date: 2022-03-28\n",
      "URL: http://arxiv.org/abs/2203.14484v1\n",
      "Texte: In the field of data science, and for academics in general, the Pythonprogramming language is a popular choice, mainly because of its libraries forstoring, manipulating, and gaining insight from data. Evidence includes theversatile set of machine learning, data visualization, and manipulationpackages used for the ever-growing size of available data. The Zen of Python isa set of guiding design principles that developers use to write acceptable andelegant Python code. Most principles revolve around simplicity. However, as theneed to compute large amounts of data, performance has become a necessity forthe Python programmer. The new idea in this paper is to confirm whether writingthe Pythonic way peaks performance at scale. As a starting point, we conduct aset of preliminary experiments to evaluate nine Pythonic code examples bycomparing the performance of both Pythonic and Non-Pythonic code snippets. Ourresults reveal that writing in Pythonic idioms may save memory and time. Weshow that incorporating list comprehension, generator expression, zip, anditertools.zip_longest idioms can save up to 7,000 MB and up to 32.25 seconds.The results open more questions on how they could be utilized in a real-worldsetting. The replication package includes all scripts, and the results areavailable at https://doi.org/10.5281/zenodo.5712349\n",
      "Co-auteurs: Bodin Chinthanet, Supatsara Wattanakriengkrai, Raula Gaikovina Kula, Pongchai Jaisri, Takashi Ishio\n",
      "Source: arxiv\n",
      "Titre: Pydelay - a python tool for solving delay differential equations\n",
      "Auteur: V. Flunkert\n",
      "Date: 2009-11-09\n",
      "URL: http://arxiv.org/abs/0911.1633v1\n",
      "Texte: pydelay is a python library which translates a system of delay differentialequations into C-code and simulates the code using scipy weave.\n",
      "Co-auteurs: E. Schoell\n",
      "Source: arxiv\n",
      "Titre: How fast can we make interpreted Python?\n",
      "Auteur: Russell Power\n",
      "Date: 2013-06-25\n",
      "URL: http://arxiv.org/abs/1306.6047v2\n",
      "Texte: Python is a popular dynamic language with a large part of its appeal comingfrom powerful libraries and extension modules. These augment the language andmake it a productive environment for a wide variety of tasks, ranging from webdevelopment (Django) to numerical analysis (NumPy). Unfortunately, Python'sperformance is quite poor when compared to modern implementations of languagessuch as Lua and JavaScript.  Why does Python lag so far behind these other languages? As we show, the verysame API and extension libraries that make Python a powerful language also makeit very difficult to efficiently execute. Given that we want to retain accessto the great extension libraries that already exist for Python, how fast can wemake it?  To evaluate this, we designed and implemented Falcon, a high-performancebytecode interpreter fully compatible with the standard CPython interpreter.Falcon applies a number of well known optimizations and introduces several newtechniques to speed up execution of Python bytecode. In our evaluation, wefound Falcon an average of 25% faster than the standard Python interpreter onmost benchmarks and in some cases about 2.5X faster.\n",
      "Co-auteurs: Alex Rubinsteyn\n",
      "Source: arxiv\n",
      "Titre: Performance of Python runtimes on a non-numeric scientific code\n",
      "Auteur: Riccardo Murri\n",
      "Date: 2014-04-25\n",
      "URL: http://arxiv.org/abs/1404.6388v2\n",
      "Texte: The Python library FatGHol FatGHoL used in Murri2012 to reckon the rationalhomology of the moduli space of Riemann surfaces is an example of a non-numericscientific code: most of the processing it does is generating graphs(represented by complex Python objects) and computing their isomorphisms (atriple of Python lists; again a nested data structure). These operations arerepeated many times over: for example, the spaces and are triangulated by4'583'322 and 747'664 graphs, respectively. This is an opportunity for everyPython runtime to prove its strength in optimization. The purpose of thisexperiment was to assess the maturity of alternative Python runtimes, in termsof: compatibility with the language as implemented in CPython 2.7, andperformance speedup. This paper compares the results and experiences fromrunning FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: A Python Extension for the Massively Parallel Multiphysics Simulation\n",
      "  Framework waLBerla\n",
      "Auteur: Martin Bauer\n",
      "Date: 2015-11-23\n",
      "URL: http://dx.doi.org/10.1080/17445760.2015.1118478\n",
      "Texte: We present a Python extension to the massively parallel HPC simulationtoolkit waLBerla. waLBerla is a framework for stencil based algorithmsoperating on block-structured grids, with the main application field beingfluid simulations in complex geometries using the lattice Boltzmann method.Careful performance engineering results in excellent node performance and goodscalability to over 400,000 cores. To increase the usability and flexibility ofthe framework, a Python interface was developed. Python extensions are used atall stages of the simulation pipeline: They simplify and automate scenariosetup, evaluation, and plotting. We show how our Python interface outperformsthe existing text-file-based configuration mechanism, providing features likeautomatic nondimensionalization of physical quantities and handling of complexparameter dependencies. Furthermore, Python is used to process and evaluateresults while the simulation is running, leading to smaller output files andthe possibility to adjust parameters dependent on the current simulation state.C++ data structures are exported such that a seamless interfacing to othernumerical Python libraries is possible. The expressive power of Python and theperformance of C++ make development of efficient code with low time effortpossible.\n",
      "Co-auteurs: Florian Schornbaum, Christian Godenschwager, Matthias Markl, Daniela Anderl, Harald Köstler, Ulrich Rüde\n",
      "Source: arxiv\n",
      "Titre: Generating Python Code From Object-Z Specifications\n",
      "Auteur: A. F. Al Azzawi\n",
      "Date: 2018-02-17\n",
      "URL: http://arxiv.org/abs/1802.06224v1\n",
      "Texte: Object-Z is an object-oriented specification language which extends the Zlanguage with classes, objects, inheritance and polymorphism that can be usedto represent the specification of a complex system as collections of objects.There are a number of existing works that mapped Object-Z to C++ and Javaprogramming languages. Since Python and Object-Z share many similarities, bothare object-oriented paradigm, support set theory and predicate calculusmoreover, Python is a functional programming language which is naturally closerto formal specifications, we propose a mapping from Object-Z specifications toPython code that covers some Object-Z constructs and express its specificationsin Python to validate these specifications. The validations are used in themapping covered preconditions, post-conditions, and invariants that are builtusing lambda function and Python's decorator. This work has found Python is anexcellent language for developing libraries to map Object-Z specifications toPython.\n",
      "Co-auteurs: M. Bettaz, H. M. Al-Refai\n",
      "Source: arxiv\n",
      "Titre: Building a scalable python distribution for HEP data analysis\n",
      "Auteur: David Lange\n",
      "Date: 2018-04-24\n",
      "URL: http://arxiv.org/abs/1804.08939v1\n",
      "Texte: There are numerous approaches to building analysis applications across thehigh-energy physics community. Among them are Python-based, or at leastPython-driven, analysis workflows. We aim to ease the adoption of aPython-based analysis toolkit by making it easier for non-expert users to gainaccess to Python tools for scientific analysis. Experimental softwaredistributions and individual user analysis have quite different requirements.Distributions tend to worry most about stability, usability andreproducibility, while the users usually strive to be fast and nimble. Wediscuss how we built and now maintain a python distribution for analysis whilesatisfying requirements both a large software distribution (in our case, thatof CMSSW) and user, or laptop, level analysis. We pursued the integration oftools used by the broader data science community as well as HEP developed(e.g., histogrammar, root_numpy) Python packages. We discuss concepts weinvestigated for package integration and testing, as well as issues weencountered through this process. Distribution and platform support areimportant topics. We discuss our approach and progress towards a sustainableinfrastructure for supporting this Python stack for the CMS user community andfor the broader HEP user community.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: The Dune Python Module\n",
      "Auteur: Andreas Dedner\n",
      "Date: 2018-07-13\n",
      "URL: http://arxiv.org/abs/1807.05252v1\n",
      "Texte: In this paper we present the new Dune-Python module which provides Pythonbindings for the Dune core, which is a C++ environment for solving partialdifferential equations. The aim of this new module is to firstly provide thegeneral infrastructure for exporting realizations of statically polymorphicinterfaces based on just-in-time compilation and secondly to provide bindingsfor the central interfaces of the dune core modules. In the first release wefocus on the grid interface. Our aim is to only introduce a thin layer whenpassing objects into Python which can be removed when the object is passed backinto a C++ algorithm. Thus no efficiency is lost and little additional codemaintenance cost is incurred. To make the transition for Dune users to thePython environment straightforward the Python classes provide a very similarinterface to their C++ counterparts. In addition, vectorized versions of manyinterfaces allow for more efficient code on the Python side. The infrastructurefor exporting these interfaces and the resulting bindings for a Dune grid areexplained in detail in this paper for both experienced Dune users and othersinterested in a flexible Python environment for implementing grid based schemesfor solving partial differential equations.\n",
      "Co-auteurs: Martin Nolte\n",
      "Source: arxiv\n",
      "Titre: Image Processing in Python With Montage\n",
      "Auteur: John Good\n",
      "Date: 2019-08-26\n",
      "URL: http://arxiv.org/abs/1908.09753v1\n",
      "Texte: The Montage image mosaic engine has found wide applicability in astronomyresearch, integration into processing environments, and is an examplarapplication for the development of advanced cyber-infrastructure. It is writtenin C to provide performance and portability. Linking C/C++ libraries to thePython kernel at run time as binary extensions allows them to run under Pythonat compiled speeds and enables users to take advantage of all the functionalityin Python. We have built Python binary extensions of the 59 ANSI-C modules thatmake up version 5 of the Montage toolkit. This has involved a turning the codeinto a C library, with driver code fully separated to reproduce the callingsequence of the command-line tools; and then adding Python and C linkage codewith the Cython library, which acts as a bridge between general C libraries andthe Python interface. We will demonstrate how to use these Python binaryextensions to perform image processing, including reprojecting and resamplingimages, rectifying background emission to a common level, creation of imagemosaics that preserve the calibration and astrometric fidelity of the inputimages, creating visualizations with an adaptive stretch algorithm, processingHEALPix images, and analyzing and managing image metadata.\n",
      "Co-auteurs: G. Bruce Berriman\n",
      "Source: arxiv\n",
      "Titre: An Analysis of Python's Topics, Trends, and Technologies Through Mining\n",
      "  Stack Overflow Discussions\n",
      "Auteur: Hamed Tahmooresi\n",
      "Date: 2020-04-14\n",
      "URL: http://arxiv.org/abs/2004.06280v1\n",
      "Texte: Python is a popular, widely used, and general-purpose programming language.In spite of its ever-growing community, researchers have not performed muchanalysis on Python's topics, trends, and technologies which provides insightsfor developers about Python community trends and main issues. In this article,we examine the main topics related to this language being discussed bydevelopers on one of the most popular Q\\&A websites, Stack Overflow, as well astemporal trends through mining 2461876 posts. To be more useful for thesoftware engineers, we study what Python provides as the alternative to populartechnologies offered by common programming languages like Java. Our resultsindicate that discussions about Python standard features, web programming, andscientific programming. Programming in areas such as mathematics, data science,statistics, machine learning, natural language processing (NLP), and so forth.are the most popular areas in the Python community. At the same time, areasrelated to scientific programming are steadily receiving more attention fromthe Python developers.\n",
      "Co-auteurs: Abbas Heydarnoori, Alireza Aghamohammadi\n",
      "Source: arxiv\n",
      "Titre: Python Workflows on HPC Systems\n",
      "Auteur: Dominik Strassel\n",
      "Date: 2020-12-01\n",
      "URL: http://arxiv.org/abs/2012.00365v1\n",
      "Texte: The recent successes and wide spread application of compute intensive machinelearning and data analytics methods have been boosting the usage of the Pythonprogramming language on HPC systems. While Python provides many advantages forthe users, it has not been designed with a focus on multi-user environments orparallel programming - making it quite challenging to maintain stable andsecure Python workflows on a HPC system. In this paper, we analyze the keyproblems induced by the usage of Python on HPC clusters and sketch appropriateworkarounds for efficiently maintaining multi-user Python softwareenvironments, securing and restricting resources of Python jobs and containingPython processes, while focusing on Deep Learning applications running on GPUclusters.\n",
      "Co-auteurs: Philipp Reusch, Janis Keuper\n",
      "Source: arxiv\n",
      "Titre: Conflict-aware Inference of Python Compatible Runtime Environments with\n",
      "  Domain Knowledge Graph\n",
      "Auteur: Wei Cheng\n",
      "Date: 2022-01-18\n",
      "URL: http://arxiv.org/abs/2201.07029v1\n",
      "Texte: Code sharing and reuse is a widespread use practice in software engineering.Although a vast amount of open-source Python code is accessible on many onlineplatforms, programmers often find it difficult to restore a successful runtimeenvironment. Previous studies validated automatic inference of Pythondependencies using pre-built knowledge bases. However, these studies do notcover sufficient knowledge to accurately match the Python code and also ignorethe potential conflicts between their inferred dependencies, thus resulting ina low success rate of inference. In this paper, we propose PyCRE, a newapproach to automatically inferring Python compatible runtime environments withdomain knowledge graph (KG). Specifically, we design a domain-specific ontologyfor Python third-party packages and construct KGs for over 10,000 popularpackages in Python 2 and Python 3. PyCRE discovers candidate libraries bymeasuring the matching degree between the known libraries and the third-partyresources used in target code. For the NP-complete problem of dependencysolving, we propose a heuristic graph traversal algorithm to efficientlyguarantee the compatibility between packages. PyCRE achieves superiorperformance on a real-world dataset and efficiently resolves nearly half moreimport errors than previous methods.\n",
      "Co-auteurs: Xiangrong Zhu, Wei Hu\n",
      "Source: arxiv\n",
      "Titre: Triangulating Python Performance Issues with Scalene\n",
      "Auteur: Emery D. Berger\n",
      "Date: 2022-12-15\n",
      "URL: http://arxiv.org/abs/2212.07597v1\n",
      "Texte: This paper proposes Scalene, a profiler specialized for Python. Scalenecombines a suite of innovations to precisely and simultaneously profile CPU,memory, and GPU usage, all with low overhead. Scalene's CPU and memoryprofilers help Python programmers direct their optimization efforts bydistinguishing between inefficient Python and efficient native execution timeand memory usage. Scalene's memory profiler employs a novel sampling algorithmthat lets it operate with low overhead yet high precision. It also incorporatesa novel algorithm that automatically pinpoints memory leaks, whether withinPython or across the Python-native boundary. Scalene tracks a new metric calledcopy volume, which highlights costly copying operations that can occur whenPython silently converts between C and Python data representations, or betweenCPU and GPU. Since its introduction, Scalene has been widely adopted, with over500,000 downloads to date. We present experience reports from developers whoused Scalene to achieve significant performance improvements and memorysavings.\n",
      "Co-auteurs: Sam Stern, Juan Altmayer Pizzorno\n",
      "Source: arxiv\n",
      "Titre: Python for education: permutations\n",
      "Auteur: Andrzej Kapanowski\n",
      "Date: 2013-07-26\n",
      "URL: http://arxiv.org/abs/1307.7042v1\n",
      "Texte: Python implementation of permutations is presented. Three classes areintroduced: Perm for permutations, Group for permutation groups, and PermErrorto report any errors for both classes. The class Perm is based on Pythondictionaries and utilize cycle notation. The methods of calculation for theperm order, parity, ranking and unranking are given. A random permutationgeneration is also shown. The class Group is very simple and it is also basedon dictionaries. It is mainly the presentation of the permutation groupsinterface with methods for the group order, subgroups (normalizer, centralizer,center, stabilizer), orbits, and several tests. The corresponding Python codeis contained in the modules perms and groups.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Python bindings for libcloudph++\n",
      "Auteur: Dorota Jarecka\n",
      "Date: 2015-04-05\n",
      "URL: http://arxiv.org/abs/1504.01161v1\n",
      "Texte: This technical note introduces the Python bindings for libcloudph++. Thelibcloudph++ is a C++ library of algorithms for representing atmospheric cloudmicrophysics in numerical models. The bindings expose the completefunctionality of the library to the Python users. The bindings are implementedusing the Boost.Python C++ library and use NumPy arrays. This note includeslistings with Python scripts exemplifying the use of selected librarycomponents. An example solution for using the Python bindings to accesslibcloudph++ from Fortran is presented.\n",
      "Co-auteurs: Sylwester Arabas, Davide Del Vento\n",
      "Source: arxiv\n",
      "Titre: Pytrec_eval: An Extremely Fast Python Interface to trec_eval\n",
      "Auteur: Christophe Van Gysel\n",
      "Date: 2018-05-04\n",
      "URL: http://dx.doi.org/10.1145/3209978.3210065\n",
      "Texte: We introduce pytrec_eval, a Python interface to the tree_eval informationretrieval evaluation toolkit. pytrec_eval exposes the reference implementationsof trec_eval within Python as a native extension. We show that pytrec_eval isaround one order of magnitude faster than invoking trec_eval as a sub processfrom within Python. Compared to a native Python implementation of NDCG,pytrec_eval is twice as fast for practically-sized rankings. Finally, wedemonstrate its effectiveness in an application where pytrec_eval is combinedwith Pyndri and the OpenAI Gym where query expansion is learned usingQ-learning.\n",
      "Co-auteurs: Maarten de Rijke\n",
      "Source: arxiv\n",
      "Titre: Yaps: Python Frontend to Stan\n",
      "Auteur: Guillaume Baudart\n",
      "Date: 2018-12-06\n",
      "URL: http://arxiv.org/abs/1812.04125v1\n",
      "Texte: Stan is a popular probabilistic programming language with a self-containedsyntax and semantics that is close to graphical models. Unfortunately, existingembeddings of Stan in Python use multi-line strings. That approach forces usersto switch between two different language styles, with no support for syntaxhighlighting or simple error reporting within the Stan code. This paper tacklesthe question of whether Stan could use Python syntax while retaining itsself-contained semantics. The answer is yes, that can be accomplished byreinterpreting the Python syntax. This paper introduces Yaps, a new frontend toStan based on reinterpreted Python. We tested Yaps on over a thousand Stanmodels and made it available open-source.\n",
      "Co-auteurs: Martin Hirzel, Kiran Kate, Louis Mandel, Avraham Shinnar\n",
      "Source: arxiv\n",
      "Titre: Nonparametric Estimation of the Random Coefficients Model in Python\n",
      "Auteur: Emil Mendoza\n",
      "Date: 2021-08-08\n",
      "URL: http://arxiv.org/abs/2108.03582v2\n",
      "Texte: We present $\\textbf{PyRMLE}$, a Python module that implements RegularizedMaximum Likelihood Estimation for the analysis of Random Coefficient models.$\\textbf{PyRMLE}$ is simple to use and readily works with data formats that aretypical to Random Coefficient problems. The module makes use of Python'sscientific libraries $\\textbf{NumPy}$ and $\\textbf{SciPy}$ for computationalefficiency. The main implementation of the algorithm is executed purely inPython code which takes advantage of Python's high-level features.\n",
      "Co-auteurs: Fabian Dunker, Marco Reale\n",
      "Source: arxiv\n",
      "Titre: Running HMC Simulation with Python via QUDA\n",
      "Auteur: Shuhei Yamamoto\n",
      "Date: 2022-12-13\n",
      "URL: http://arxiv.org/abs/2212.06657v1\n",
      "Texte: Lyncs-API is a Python API for Lattice QCD applications. It is designed as aPython toolkit that allows the user to use and run various lattice QCDlibraries while programming in Python. The goal is to provide the user an easyprogramming experience without scarifying performance across multipleplatforms, by preparing a common framework for various softwares for latticeQCD calculations. As such, it contains interfaces to, e.g., c-lime, DDalphaAMG,tmLQCD, and QUDA. In this proceeding, we focus on a Lyncs interface to QUDA,named Lyncs-QUDA, and present a small tutorial on how to use this Pythoninterface to perform a HMC simulation using QUDA.\n",
      "Co-auteurs: Simone Bacchio, Jacob Finenrath\n",
      "Source: arxiv\n",
      "Titre: Python client for Isabelle server\n",
      "Auteur: Boris Shminke\n",
      "Date: 2022-12-09\n",
      "URL: http://arxiv.org/abs/2212.11173v1\n",
      "Texte: We contribute a Python client for the Isabelle server, which givesresearchers and students using Python as their primary programming language anopportunity to communicate with the Isabelle server through TCP directly from aPython script. Such an approach helps avoid the complexities of integrating theexisting Python script with languages used for Isabelle development (ML andScala). We also describe new features that appeared since the announcement ofthe first version of the client a year ago. Finally, we give examples of theclient's applications in research and education and discuss known limitationsand possible directions for future development.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: ePython: An implementation of Python for the many-core Epiphany\n",
      "  coprocessor\n",
      "Auteur: Nick Brown\n",
      "Date: 2020-10-28\n",
      "URL: http://dx.doi.org/10.1109/PyHPC.2016.012\n",
      "Texte: The Epiphany is a many-core, low power, low on-chip memory architecture andone can very cheaply gain access to a number of parallel cores which isbeneficial for HPC education and prototyping. The very low power nature ofthese architectures also means that there is potential for their use in futureHPC machines, however there is a high barrier to entry in programming them dueto the associated complexities and immaturity of supporting tools.  In this paper we present our work on ePython, a subset of Python for theEpiphany and similar many-core co-processors. Due to the limited on-chip memoryper core we have developed a new Python interpreter and this, combined withadditional support for parallelism, has meant that novices can take advantageof Python to very quickly write parallel codes on the Epiphany and exploreconcepts of HPC using a smaller scale parallel machine. The high level natureof Python opens up new possibilities on the Epiphany, we examine acomputationally intensive Gauss-Seidel code from the programmability andperformance perspective, discuss running Python hybrid on both the host CPU andEpiphany, and interoperability between a full Python interpreter on the CPU andePython on the Epiphany. The result of this work is support for developingPython on the Epiphany, which can be applied to other similar architectures,that the community have already started to adopt and use to explore concepts ofparallelism and HPC.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Characterizing Bugs in Python and R Data Analytics Programs\n",
      "Auteur: Shibbir Ahmed\n",
      "Date: 2023-06-14\n",
      "URL: http://arxiv.org/abs/2306.08632v1\n",
      "Texte: R and Python are among the most popular languages used in many critical dataanalytics tasks. However, we still do not fully understand the capabilities ofthese two languages w.r.t. bugs encountered in data analytics tasks. What typeof bugs are common? What are the main root causes? What is the relation betweenbugs and root causes? How to mitigate these bugs? We present a comprehensivestudy of 5,068 Stack Overflow posts, 1,800 bug fix commits from GitHubrepositories, and several GitHub issues of the most used libraries tounderstand bugs in R and Python. Our key findings include: while both R andPython have bugs due to inexperience with data analysis, Python seesignificantly larger data preprocessing bugs compared to R. Developersexperience significantly more data flow bugs in R because intermediate resultsare often implicit. We also found changes and bugs in packages and librariescause more bugs in R compared to Python while package or library misselectionand conflicts cause more bugs in Python than R. While R has a slightly higherreadability barrier for data analysts, the statistical power of R leads to aless number of bad performance bugs. In terms of data visualization, R packageshave significantly more bugs than Python libraries. We also identified a strongcorrelation between comparable packages in R and Python despite theirlinguistic and methodological differences. Lastly, we contribute a largedataset of manually verified R and Python bugs.\n",
      "Co-auteurs: Mohammad Wardat, Hamid Bagheri, Breno Dantas Cruz, Hridesh Rajan\n",
      "Source: arxiv\n",
      "Titre: Simplifying Parallelization of Scientific Codes by a Function-Centric\n",
      "  Approach in Python\n",
      "Auteur: Jon K. Nilsen\n",
      "Date: 2010-02-03\n",
      "URL: http://dx.doi.org/10.1088/1749-4699/3/1/015003\n",
      "Texte: The purpose of this paper is to show how existing scientific software can beparallelized using a separate thin layer of Python code where all parallelcommunication is implemented. We provide specific examples on such layers ofcode, and these examples may act as templates for parallelizing a wide set ofserial scientific codes. The use of Python for parallelization is motivated bythe fact that the language is well suited for reusing existing serial codesprogrammed in other languages. The extreme flexibility of Python with regard tohandling functions makes it very easy to wrap up decomposed computational tasksof a serial scientific application as Python functions. Manyparallelization-specific components can be implemented as generic Pythonfunctions, which may take as input those functions that perform concretecomputational tasks. The overall programming effort needed by thisparallelization approach is rather limited, and the resulting parallel Pythonscripts have a compact and clean structure. The usefulness of theparallelization approach is exemplified by three different classes ofapplications in natural and social sciences.\n",
      "Co-auteurs: Xing Cai, Bjorn Hoyland, Hans Petter Langtangen\n",
      "Source: arxiv\n",
      "Titre: DockerizeMe: Automatic Inference of Environment Dependencies for Python\n",
      "  Code Snippets\n",
      "Auteur: Eric Horton\n",
      "Date: 2019-05-27\n",
      "URL: http://arxiv.org/abs/1905.11127v1\n",
      "Texte: Platforms like Stack Overflow and GitHub's gist system promote the sharing ofideas and programming techniques via the distribution of code snippets designedto illustrate particular tasks. Python, a popular and fast-growing programminglanguage, sees heavy use on both sites, with nearly one million questions askedon Stack Overflow and 400 thousand public gists on GitHub. Unfortunately,around 75% of the Python example code shared through these sites cannot bedirectly executed. When run in a clean environment, over 50% of public Pythongists fail due to an import error for a missing library.  We present DockerizeMe, a technique for inferring the dependencies needed toexecute a Python code snippet without import error. DockerizeMe starts withoffline knowledge acquisition of the resources and dependencies for popularPython packages from the Python Package Index (PyPI). It then builds Dockerspecifications using a graph-based inference procedure. Our inference procedureresolves import errors in 892 out of nearly 3,000 gists from the Gistabledataset for which Gistable's baseline approach could not find and install alldependencies.\n",
      "Co-auteurs: Chris Parnin\n",
      "Source: arxiv\n",
      "Titre: OpenML-Python: an extensible Python API for OpenML\n",
      "Auteur: Matthias Feurer\n",
      "Date: 2019-11-06\n",
      "URL: http://arxiv.org/abs/1911.02490v2\n",
      "Texte: OpenML is an online platform for open science collaboration in machinelearning, used to share datasets and results of machine learning experiments.In this paper we introduce OpenML-Python, a client API for Python, opening upthe OpenML platform for a wide range of Python-based tools. It provides easyaccess to all datasets, tasks and experiments on OpenML from within Python. Italso provides functionality to conduct machine learning experiments, upload theresults to OpenML, and reproduce results which are stored on OpenML.Furthermore, it comes with a scikit-learn plugin and a plugin mechanism toeasily integrate other machine learning libraries written in Python into theOpenML ecosystem. Source code and documentation is available athttps://github.com/openml/openml-python/.\n",
      "Co-auteurs: Jan N. van Rijn, Arlind Kadra, Pieter Gijsbers, Neeratyoy Mallik, Sahithya Ravi, Andreas Müller, Joaquin Vanschoren, Frank Hutter\n",
      "Source: arxiv\n",
      "Titre: Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations\n",
      "  and visualizations via ParaMonte::Python library\n",
      "Auteur: Amir Shahmoradi\n",
      "Date: 2020-10-01\n",
      "URL: http://arxiv.org/abs/2010.00724v1\n",
      "Texte: ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serialand MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines forsampling mathematical objective functions, in particular, the posteriordistributions of parameters in Bayesian modeling and analysis in data science,Machine Learning, and scientific inference in general. In addition to providingaccess to fast high-performance serial/parallel Monte Carlo and MCMC samplingroutines, the ParaMonte::Python library provides extensive post-processing andvisualization tools that aim to automate and streamline the process of modelcalibration and uncertainty quantification in Bayesian data analysis.Furthermore, the automatically-enabled restart functionality ofParaMonte::Python samplers ensure seamless fully-deterministic into-the-futurerestart of Monte Carlo simulations, should any interruptions happen. TheParaMonte::Python library is MIT-licensed and is permanently maintained onGitHub athttps://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.\n",
      "Co-auteurs: Fatemeh Bagheri, Joshua Alexander Osborne\n",
      "Source: arxiv\n",
      "Titre: Productivity, Portability, Performance: Data-Centric Python\n",
      "Auteur: Alexandros Nikolaos Ziogas\n",
      "Date: 2021-07-01\n",
      "URL: http://dx.doi.org/10.1145/1122445.1122456\n",
      "Texte: Python has become the de facto language for scientific computing. Programmingin Python is highly productive, mainly due to its rich science-orientedsoftware ecosystem built around the NumPy module. As a result, the demand forPython support in High Performance Computing (HPC) has skyrocketed. However,the Python language itself does not necessarily offer high performance. In thiswork, we present a workflow that retains Python's high productivity whileachieving portable performance across different architectures. The workflow'skey features are HPC-oriented language extensions and a set of automaticoptimizations powered by a data-centric intermediate representation. We showperformance results and scaling across CPU, GPU, FPGA, and the Piz Daintsupercomputer (up to 23,328 cores), with 2.47x and 3.75x speedups overprevious-best solutions, first-ever Xilinx and Intel FPGA results of annotatedPython, and up to 93.16% scaling efficiency on 512 nodes.\n",
      "Co-auteurs: Timo Schneider, Tal Ben-Nun, Alexandru Calotoiu, Tiziano De Matteis, Johannes de Fine Licht, Luca Lavarini, Torsten Hoefler\n",
      "Source: arxiv\n",
      "Titre: PyTracer: Automatically profiling numerical instabilities in Python\n",
      "Auteur: Yohan Chatelain\n",
      "Date: 2021-12-21\n",
      "URL: http://arxiv.org/abs/2112.11508v2\n",
      "Texte: Numerical stability is a crucial requirement of reliable scientificcomputing. However, despite the pervasiveness of Python in data science,analyzing large Python programs remains challenging due to the lack of scalablenumerical analysis tools available for this language. To fill this gap, wedeveloped PyTracer, a profiler to quantify numerical instability in Pythonapplications. PyTracer transparently instruments Python code to producenumerical traces and visualize them interactively in a Plotly dashboard. Wedesigned PyTracer to be agnostic to numerical noise model, allowing for toolevaluation through Monte-Carlo Arithmetic, random rounding, random dataperturbation, or structured noise for a particular application. We illustratePyTracer's capabilities by testing the numerical stability of key functions inboth SciPy and Scikit-learn, two dominant Python libraries for mathematicalmodeling. Through these evaluations, we demonstrate PyTracer as a scalable,automatic, and generic framework for numerical profiling in Python.\n",
      "Co-auteurs: Nigel Yong, Gregory Kiar, Tristan Glatard\n",
      "Source: arxiv\n",
      "Titre: GAP-Gen: Guided Automatic Python Code Generation\n",
      "Auteur: Junchen Zhao\n",
      "Date: 2022-01-19\n",
      "URL: http://arxiv.org/abs/2201.08810v2\n",
      "Texte: Automatic code generation from natural language descriptions can be highlybeneficial during the process of software development. In this work, we proposeGAP-Gen, a Guided Automatic Python Code Generation method based on Pythonsyntactic constraints and semantic constraints. We first introduce Pythonsyntactic constraints in the form of Syntax-Flow, which is a simplified versionof Abstract Syntax Tree (AST) reducing the size and high complexity of AbstractSyntax Tree but maintaining crucial syntactic information of Python code. Inaddition to Syntax-Flow, we introduce Variable-Flow which abstracts variableand function names consistently through out the code. In our work, rather thanpretraining, we focus on modifying the finetuning process which reducescomputational requirements but retains high generation performance on automaticPython code generation task. GAP-Gen fine-tunes the transformer based languagemodels T5 and CodeT5 using the Code-to-Docstring datasets CodeSearchNet,CodeSearchNet AdvTest and Code-Docstring Corpus from EdinburghNLP. Ourexperiments show that GAP-Gen achieves better results on automatic Python codegeneration task than previous works.\n",
      "Co-auteurs: Yurun Song, Junlin Wang, Ian G. Harris\n",
      "Source: arxiv\n",
      "Titre: Approaches to the Parallelization of Merge Sort in Python\n",
      "Auteur: Alexandra Yang\n",
      "Date: 2022-11-26\n",
      "URL: http://arxiv.org/abs/2211.16479v1\n",
      "Texte: The theory of divide-and-conquer parallelization has been well-studied in thepast, providing a solid basis upon which to explore different approaches to theparallelization of merge sort in Python. Python's simplicity and extensiveselection of libraries make it the most popular scientific programminglanguage, so it is a fitting language in which to implement and analyze thesealgorithms.  In this paper, we use Python packages multiprocessing and mpi4py to implementseveral different parallel merge sort algorithms. Experiments are conducted onan academic supercomputer, upon which benchmarks are performed using Cloudmesh.We find that hybrid multiprocessing merge sort outperforms several otheralgorithms, achieving a 1.5x speedup compared to the built-in Python sorted()and a 34x speedup compared to sequential merge sort. Our results provideinsight into different approaches to implementing parallel merge sort in Pythonand contribute to the understanding of general divide-and-conquerparallelization in Python on both shared and distributed memory systems.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Faster or Slower? Performance Mystery of Python Idioms Unveiled with\n",
      "  Empirical Evidence\n",
      "Auteur: Zejun Zhang\n",
      "Date: 2023-01-30\n",
      "URL: http://arxiv.org/abs/2301.12633v1\n",
      "Texte: The usage of Python idioms is popular among Python developers in a formativestudy of 101 performance-related questions of Python idioms on Stack Overflow,we find that developers often get confused about the performance impact ofPython idioms and use anecdotal toy code or rely on personal project experiencewhich is often contradictory in performance outcomes. There has been nolarge-scale, systematic empirical evidence to reconcile these performancedebates. In the paper, we create a large synthetic dataset with 24,126 pairs ofnon-idiomatic and functionally-equivalent idiomatic code for the nine uniquePython idioms identified in Zhang et al., and reuse a large real-projectdataset of 54,879 such code pairs provided by Zhang et al. We develop areliable performance measurement method to compare the speedup or slowdown byidiomatic code against non-idiomatic counterpart, and analyze the performancediscrepancies between the synthetic and real-project code, the relationshipsbetween code features and performance changes, and the root causes ofperformance changes at the bytecode level. We summarize our findings as someactionable suggestions for using Python idioms.\n",
      "Co-auteurs: Zhenchang Xing, Xin Xia, Xiwei Xu, Liming Zhu, Qinghua Lu\n",
      "Source: arxiv\n",
      "Titre: Rapid Development of Interferometric Software Using MIRIAD and Python\n",
      "Auteur: Peter K. G. Williams\n",
      "Date: 2012-03-01\n",
      "URL: http://dx.doi.org/10.1086/666604\n",
      "Texte: New and upgraded radio interferometers produce data at massive rates and willrequire significant improvements in analysis techniques to reach their promisedlevels of performance in a routine manner. Until these techniques are fullydeveloped, productivity and accessibility in scientific programmingenvironments will be key bottlenecks in the pipeline leading from data-takingto research results. We present an open-source software package, miriad-python,that allows access to the MIRIAD interferometric reduction system in the Pythonprogramming language. The modular design of MIRIAD and the high productivityand accessibility of Python provide an excellent foundation for rapiddevelopment of interferometric software. Several other projects with similargoals exist and we describe them and compare miriad-python to them in detail.Along with an overview of the package design, we present sample code andapplications, including the detection of millisecond astrophysical transients,determination and application of nonstandard calibration parameters,interactive data visualization, and a reduction pipeline using a directedacyclic graph dependency model analogous to that of the traditional Unix tool\"make\". The key aspects of the miriad-python software project are documented.We find that miriad-python provides an extremely effective environment forprototyping new interferometric software, though certain existing packagesprovide far more infrastructure for some applications. While equivalentsoftware written in compiled languages can be much faster than Python, thereare many situations in which execution time is profitably exchanged for speedof development, code readability, accessibility to nonexpert programmers, quickinterlinking with foreign software packages, and other virtues of the Pythonlanguage.\n",
      "Co-auteurs: Casey J. Law, Geoffrey C. Bower\n",
      "Source: arxiv\n",
      "Titre: Toward Efficient Interactions between Python and Native Libraries\n",
      "Auteur: Jialiang Tan\n",
      "Date: 2021-06-11\n",
      "URL: http://dx.doi.org/10.1145/3468264.3468541\n",
      "Texte: Python has become a popular programming language because of its excellentprogrammability. Many modern software packages utilize Python for high-levelalgorithm design and depend on native libraries written in C/C++/Fortran forefficient computation kernels. Interaction between Python code and nativelibraries introduces performance losses because of the abstraction lying on theboundary of Python and native libraries. On the one side, Python code,typically run with interpretation, is disjoint from its execution behavior. Onthe other side, native libraries do not include program semantics to understandalgorithm defects.  To understand the interaction inefficiencies, we extensively study a largecollection of Python software packages and categorize them according to theroot causes of inefficiencies. We extract two inefficiency patterns that arecommon in interaction inefficiencies. Based on these patterns, we developPieProf, a lightweight profiler, to pinpoint interaction inefficiencies inPython applications. The principle of PieProf is to measure the inefficienciesin the native execution and associate inefficiencies with high-level Pythoncode to provide a holistic view. Guided by PieProf, we optimize 17 real-worldapplications, yielding speedups up to 6.3$\\times$ on application level.\n",
      "Co-auteurs: Yu Chen, Zhenming Liu, Bin Ren, Shuaiwen Leon Song, Xipeng Shen, Xu Liu\n",
      "Source: arxiv\n",
      "Titre: Improving Tese Case Generation for Python Native Libraries Through\n",
      "  Constraints on Input Data Structures\n",
      "Auteur: Xin Zhang\n",
      "Date: 2022-06-28\n",
      "URL: http://arxiv.org/abs/2206.13828v1\n",
      "Texte: Modern Python projects execute computational functions using native librariesand give Python interfaces to boost execution speed; hence, testing theselibraries becomes critical to the project's robustness. One challenge is thatexisting approaches use coverage to guide generation, but native libraries runas black boxes to Python code with no execution information. Another is thatdynamic binary instrumentation reduces testing performance as it needs tomonitor both native libraries and the Python virtual machine.  To address these challenges, in this paper, we propose an automated test casegeneration approach that works at the Python code layer. Our insight is thatmany path conditions in native libraries are for processing input datastructures through interacting with the VM. In our approach, we instrument thePython Interpreter to monitor the interactions between native libraries and VM,derive constraints on the structures, and then use the constraints to guidetest case generation. We implement our approach in a tool named PyCing andapply it to six widely-used Python projects. The experimental results revealthat with the structure constraint guidance, PyCing can cover more executionpaths than existing test cases and state-of-the-art tools. Also, with thecheckers in the testing framework Pytest, PyCing can identify segmentationfaults in 10 Python interfaces and memory leaks in 9. Our instrumentationstrategy also has an acceptable influence on testing efficiency.\n",
      "Co-auteurs: Xutong Ma, Jiwen Yan, Baoquan Cui, Jun Yan, Jian Zhang\n",
      "Source: arxiv\n",
      "Titre: binary_c-python: A Python-based stellar population synthesis tool and\n",
      "  interface to binary_c\n",
      "Auteur: D. D. Hendriks\n",
      "Date: 2023-06-05\n",
      "URL: http://dx.doi.org/10.21105/joss.04642\n",
      "Texte: We present the software package binary_c-python which provides a convenientand easy-to-use interface to the binary_c framework, allowing the user torapidly evolve individual systems and populations of stars. binary_c-python isavailable on Pip and on GitLab. binary_c-python contains many useful featuresto control and process the output of binary_c, like by providingbinary_c-python with logging statements that are dynamically compiled andloaded into binary_c. Moreover, we have recently added standardised output ofevents like Roche-lobe overflow or double compact-object formation to binary_c,and automatic parsing and managing of that output in binary_c-python.binary_c-python uses multiprocessing to utilise all the cores on a particularmachine, and can run populations with HPC cluster workload managers likeHTCondor and Slurm, allowing the user to run simulations on large computingclusters. We provide documentation that is automatically generated based ondocstrings and a suite of Jupyter notebooks. These notebooks consist oftechnical tutorials on how to use binary_c-python and use-case scenarios aimedat doing science. Much of binary_c-python is covered by unit tests to ensurereliability and correctness, and the test coverage is continually increased asthe package is improved.\n",
      "Co-auteurs: R. G. Izzard\n",
      "Source: arxiv\n",
      "Titre: PyMsOfa: A Python Package for the Standards of Fundamental Astronomy\n",
      "  (SOFA) Service\n",
      "Auteur: Jianghui Ji\n",
      "Date: 2023-10-12\n",
      "URL: http://arxiv.org/abs/2310.08673v2\n",
      "Texte: The Standards of Fundamental Astronomy (SOFA) is a service provided by theInternational Astronomical Union (IAU) that offers algorithms and software forastronomical calculations, which was released in two versions by FORTRAN 77 andANSI C, respectively. In this work, we implement the python package PyMsOfa forSOFA service by three ways: (1) a python wrapper package based on a foreignfunction library for Python (ctypes), (2) a python wrapper package with theforeign function interface for Python calling C code (cffi), and (3) a pythonpackage directly written in pure python codes from SOFA subroutines. Thepackage PyMsOfa has fully implemented 247 functions of the original SOFAroutines. In addition, PyMsOfa is also extensively examined, which is exactlyconsistent with those test examples given by the original SOFA. This pythonpackage can be suitable to not only the astrometric detection of habitableplanets of the Closeby Habitable Exoplanet Survey (CHES) mission (Ji et al.2022), but also for the frontiers themes of black holes and dark matter relatedto astrometric calculations and other fields. The source codes are availablevia https://github.com/CHES2023/PyMsOfa.\n",
      "Co-auteurs: Dongjie Tan, Chunhui Bao, Xiumin Huang, Shoucun Hu, Yao Dong, Su Wang\n",
      "Source: arxiv\n",
      "Titre: Python for Education: Computational Methods for Nonlinear Systems\n",
      "Auteur: Christopher R. Myers\n",
      "Date: 2007-04-24\n",
      "URL: http://arxiv.org/abs/0704.3182v1\n",
      "Texte: We describe a novel, interdisciplinary, computational methods course thatuses Python and associated numerical and visualization libraries to enablestudents to implement simulations for a number of different course modules.Problems in complex networks, biomechanics, pattern formation, and generegulation are highlighted to illustrate the breadth and flexibility ofPython-powered computational environments.\n",
      "Co-auteurs: James. P. Sethna\n",
      "Source: arxiv\n",
      "Titre: Implementation of Kalman Filter with Python Language\n",
      "Auteur: Mohamed Laaraiedh\n",
      "Date: 2012-04-02\n",
      "URL: http://arxiv.org/abs/1204.0375v1\n",
      "Texte: In this paper, we investigate the implementation of a Python code for aKalman Filter using the Numpy package. A Kalman Filtering is carried out in twosteps: Prediction and Update. Each step is investigated and coded as a functionwith matrix input and output. These different functions are explained and anexample of a Kalman Filter application for the localization of mobile inwireless networks is given.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: A Framework for Distributed Deep Learning Layer Design in Python\n",
      "Auteur: Clay McLeod\n",
      "Date: 2015-10-25\n",
      "URL: http://arxiv.org/abs/1510.07303v1\n",
      "Texte: In this paper, a framework for testing Deep Neural Network (DNN) design inPython is presented. First, big data, machine learning (ML), and ArtificialNeural Networks (ANNs) are discussed to familiarize the reader with theimportance of such a system. Next, the benefits and detriments of implementingsuch a system in Python are presented. Lastly, the specifics of the system areexplained, and some experimental results are presented to prove theeffectiveness of the system.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Want Drugs? Use Python\n",
      "Auteur: Michał Nowotka\n",
      "Date: 2016-07-01\n",
      "URL: http://arxiv.org/abs/1607.00378v1\n",
      "Texte: We describe how Python can be leveraged to streamline the curation, modellingand dissemination of drug discovery data as well as the development ofinnovative, freely available tools for the related scientific community. Welook at various examples, such as chemistry toolkits, machine-learningapplications and web frameworks and show how Python can glue it all together tocreate efficient data science pipelines.\n",
      "Co-auteurs: George Papadatos, Mark Davies, Nathan Dedman, Anne Hersey\n",
      "Source: arxiv\n",
      "Titre: Geoplotlib: a Python Toolbox for Visualizing Geographical Data\n",
      "Auteur: Andrea Cuttone\n",
      "Date: 2016-08-05\n",
      "URL: http://arxiv.org/abs/1608.01933v1\n",
      "Texte: We introduce geoplotlib, an open-source python toolbox for visualizinggeographical data. geoplotlib supports the development of hardware-acceleratedinteractive visualizations in pure python, and provides implementations of dotmaps, kernel density estimation, spatial graphs, Voronoi tesselation,shapefiles and many more common spatial visualizations. We describe geoplotlibdesign, functionalities and use cases.\n",
      "Co-auteurs: Sune Lehmann, Jakob Eg Larsen\n",
      "Source: arxiv\n",
      "Titre: Powerbox: A Python package for creating structured fields with isotropic\n",
      "  power spectra\n",
      "Auteur: Steven G. Murray\n",
      "Date: 2018-08-27\n",
      "URL: http://dx.doi.org/10.21105/joss.00850\n",
      "Texte: Powerbox is a pure-Python package for creating and measuring structuredfields with homogeneous and isotropic power spectra.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: TimeGym: Debugging for Time Series Modeling in Python\n",
      "Auteur: Diogo Seca\n",
      "Date: 2021-05-04\n",
      "URL: http://arxiv.org/abs/2105.01404v1\n",
      "Texte: We introduce the TimeGym Forecasting Debugging Toolkit, a Python library fortesting and debugging time series forecasting pipelines. TimeGym simplifies thetesting forecasting pipeline by providing generic tests for forecastingpipelines fresh out of the box. These tests are based on common modelingchallenges of time series. Our library enables forecasters to apply aTest-Driven Development approach to forecast modeling, using specified oraclesto generate artificial data with noise.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: MontePython: Implementing Quantum Monte Carlo using Python\n",
      "Auteur: J. K. Nilsen\n",
      "Date: 2006-09-22\n",
      "URL: http://dx.doi.org/10.1016/j.cpc.2007.06.013\n",
      "Texte: We present a cross-language C++/Python program for simulations of quantummechanical systems with the use of Quantum Monte Carlo (QMC) methods. Wedescribe a system for which to apply QMC, the algorithms of variational MonteCarlo and diffusion Monte Carlo and we describe how to implement theses methodsin pure C++ and C++/Python. Furthermore we check the efficiency of theimplementations in serial and parallel cases to show that the overhead usingPython can be negligible.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: HOOMD-blue: A Python package for high-performance molecular dynamics and\n",
      "  hard particle Monte Carlo simulations\n",
      "Auteur: Joshua A. Anderson\n",
      "Date: 2013-08-26\n",
      "URL: http://arxiv.org/abs/1308.5587v2\n",
      "Texte: HOOMD-blue is a particle simulation engine designed for nano- andcolloidal-scale molecular dynamics and hard particle Monte Carlo simulations.It has been actively developed since March 2007 and available open source sinceAugust 2008. HOOMD-blue is a Python package with a high performance C++/CUDAbackend that we built from the ground up for GPU acceleration. The Pythoninterface allows users to combine HOOMD-blue with with other packages in thePython ecosystem to create simulation and analysis workflows. We employsoftware engineering practices to develop, test, maintain, and expand the code.\n",
      "Co-auteurs: Jens Glaser, Sharon C. Glotzer\n",
      "Source: arxiv\n",
      "Titre: Plyades: A Python Library for Space Mission Design\n",
      "Auteur: Helge Eichhorn\n",
      "Date: 2016-07-01\n",
      "URL: http://arxiv.org/abs/1607.00849v1\n",
      "Texte: Plyades: A Python Library for Space Mission Design Designing a space missionis a computation-heavy task. Software tools that conduct the necessarynumerical simulations and optimizations are therefore indispensable. Theusability of existing software, written in Fortran and MATLAB, suffers becauseof high complexity, low levels of abstraction and out-dated programmingpractices. We propose Python as a viable alternative for astrodynamics toolsand demonstrate the proof-of-concept library Plyades which combines powerfulfeatures with Pythonic ease of use.\n",
      "Co-auteurs: Reiner Anderl\n",
      "Source: arxiv\n",
      "Titre: A Practical Python API for Querying AFLOWLIB\n",
      "Auteur: Conred W. Rosenbrock\n",
      "Date: 2017-09-28\n",
      "URL: http://arxiv.org/abs/1710.00813v1\n",
      "Texte: Large databases such as aflowlib.org provide valuable data sources fordiscovering material trends through machine learning. Although a REST API andquery language are available, there is a learning curve associated with theAFLUX language that acts as a barrier for new users. Additionally, the data isstored using non-standard serialization formats. Here we present a high-levelAPI that allows immediate access to the aflowlib data using standard pythonoperators and language features. It provides an easy way to integrate aflowlibdata with other python materials packages such as ase and quippy, and providesautomatic deserialization into numpy arrays and python objects. This package isavailable via \"pip install aflow\".\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: salmon: A Symbolic Linear Regression Package for Python\n",
      "Auteur: Alex Boyd\n",
      "Date: 2019-11-02\n",
      "URL: http://arxiv.org/abs/1911.00648v3\n",
      "Texte: One of the most attractive features of R is its linear modeling capabilities.We describe a Python package, salmon, that brings the best of R's linearmodeling functionality to Python in a Pythonic way -- by providing composableobjects for specifying and fitting linear models. This object-oriented designalso enables other features that enhance ease-of-use, such as automaticvisualizations and intelligent model building.\n",
      "Co-auteurs: Dennis L. Sun\n",
      "Source: arxiv\n",
      "Titre: pySiDR: Python Event Reconstruction for SiD\n",
      "Auteur: C. T. Potter\n",
      "Date: 2020-02-13\n",
      "URL: http://arxiv.org/abs/2002.05804v1\n",
      "Texte: Event reconstruction in the ILC community has typically relied on algorithmsimplemented in C++, a fast compiled language. However, the Python packagepyLCIO provides a full interface to tracker and calorimeter hits stored in LCIOfiles, opening up the possibility to implement reconstruction algorithms in alanguage uniquely well suited to working with large lists of hits built withlist comprehensions. Python, an interpreted language which can perform complextasks with minimal code, also allows seamless integration with powerful machinelearning tools developed recently. We discuss pySiDR, a Python package for SiDevent reconstruction.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: FitsGeo -- Python package for PHITS geometry development and\n",
      "  visualization\n",
      "Auteur: Ivan Gordeev\n",
      "Date: 2020-08-08\n",
      "URL: http://arxiv.org/abs/2008.03298v1\n",
      "Texte: An easy way to define and visualize geometry for PHITS input filesintroduced. Suggested FitsGeo Python package helps to define surfaces as Pythonobjects and manipulate them conveniently. VPython assists to view definedgeometry interactively which boosts geometry development and helps withcomplicated cases. Every class that sets the surface object has methods withsome extra properties. As well as geometry generation for PHITS input,additional modules developed for material and cell definition. Any user with avery basic knowledge of Python can define the geometry in a convenient way anduse it in further research related to particle transport.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: HDPython: A High Level Python Based Object-Oriented HDL Framework\n",
      "Auteur: R. Peschke\n",
      "Date: 2020-11-05\n",
      "URL: http://arxiv.org/abs/2011.02626v2\n",
      "Texte: We present a High-Level Python-based Hardware Description Language(HDPython), It uses Python as its source language and converts it to standardVHDL. Compared to other approaches of building converters from a high-levelprogramming language into a hardware description language, this new approachaims to maintain an object-oriented paradigm throughout the entire process.Instead of removing all the high-level features from Python to make it into anHDL, this approach goes the opposite way. It tries to show how certain featuresfrom a high-level language can be implemented in an HDL, providing thecorresponding benefits of high-level programming for the user.\n",
      "Co-auteurs: K. Nishimura, G. Varner\n",
      "Source: arxiv\n",
      "Titre: cellanneal: A User-Friendly Deconvolution Software for Omics Data\n",
      "Auteur: Lisa Buchauer\n",
      "Date: 2021-10-15\n",
      "URL: http://arxiv.org/abs/2110.08209v1\n",
      "Texte: We introduce cellanneal, a python-based software for deconvolving bulk RNAsequencing data. cellanneal relies on the optimization of Spearman's rankcorrelation coefficient between experimental and computational mixture geneexpression vectors using simulated annealing. cellanneal can be used as apython package or via a command line interface, but importantly also provides asimple graphical user interface which is distributed as a single executablefile for user convenience. The python package is available athttps://github.com/LiBuchauer/cellanneal , the graphical software can bedownloaded at http://shalevlab.weizmann.ac.il/resources .\n",
      "Co-auteurs: Shalev Itzkovitz\n",
      "Source: arxiv\n",
      "Titre: Asgl: A Python Package for Penalized Linear and Quantile Regression\n",
      "Auteur: Álvaro Méndez Civieta\n",
      "Date: 2021-10-31\n",
      "URL: http://arxiv.org/abs/2111.00472v1\n",
      "Texte: Asg is a Python package that solves penalized linear regression and quantileregression models for simultaneous variable selection and prediction, for bothhigh and low dimensional frameworks. It makes very easy to set up and solvedifferent types of lasso-based penalizations among which the asgl (adaptivesparse group lasso, that gives name to the package) is remarked. This packageis built on top of cvxpy, a Python-embedded modeling language for convexoptimization problems and makes extensive use of multiprocessing, a Pythonmodule for parallel computing that significantly reduces computation times ofasgl.\n",
      "Co-auteurs: M. Carmen Aguilera-Morillo, Rosa E. Lillo\n",
      "Source: arxiv\n",
      "Titre: Scalpel: The Python Static Analysis Framework\n",
      "Auteur: Li Li\n",
      "Date: 2022-02-24\n",
      "URL: http://arxiv.org/abs/2202.11840v1\n",
      "Texte: Despite being the most popular programming language, Python has not yetreceived enough attention from the community. To the best of our knowledge,there is no general static analysis framework proposed to facilitate theimplementation of dedicated Python static analyzers. To fill this gap, wedesign and implement such a framework (named Scalpel) and make it publiclyavailable as an open-source project. The Scalpel framework has alreadyintegrated a number of fundamental static analysis functions (e.g., call graphconstructions, control-flow graph constructions, alias analysis, etc.) that areready to be reused by developers to implement client applications focusing onstatically resolving dedicated Python problems such as detecting bugs or fixingvulnerabilities.\n",
      "Co-auteurs: Jiawei Wang, Haowei Quan\n",
      "Source: arxiv\n",
      "Titre: Modernizing the ESRF beamline application software architecture with\n",
      "  generic Python modules\n",
      "Auteur: Jorg Klora\n",
      "Date: 2002-10-16\n",
      "URL: http://arxiv.org/abs/cond-mat/0210344v1\n",
      "Texte: We report on the modernization of the ESRF beamline application software withPython modules. The current building blocks used around the SPEC dataacquisition software together with the new elements are presented.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Multi-Agent Programming Contest 2011 - The Python-DTU Team\n",
      "Auteur: Jørgen Villadsen\n",
      "Date: 2011-10-01\n",
      "URL: http://arxiv.org/abs/1110.0105v1\n",
      "Texte: We provide a brief description of the Python-DTU system, including theoverall design, the tools and the algorithms that we plan to use in the agentcontest.\n",
      "Co-auteurs: Mikko Berggren Ettienne, Steen Vester\n",
      "Source: arxiv\n",
      "Titre: Proceedings of the 6th European Conference on Python in Science\n",
      "  (EuroSciPy 2013)\n",
      "Auteur: Pierre de Buyl\n",
      "Date: 2014-05-01\n",
      "URL: http://arxiv.org/abs/1405.0166v1\n",
      "Texte: These are the proceedings of the 6th European Conference on Python inScience, EuroSciPy 2013, that was held in Brussels (21-25 August 2013).\n",
      "Co-auteurs: Nelle Varoquaux\n",
      "Source: arxiv\n",
      "Titre: Py-oopsi: the python implementation of the fast-oopsi algorithm\n",
      "Auteur: Benyuan Liu\n",
      "Date: 2014-05-06\n",
      "URL: http://arxiv.org/abs/1405.6181v1\n",
      "Texte: Fast-oopsi was developed by Joshua Vogelstein in 2009, which is now widelyused to extract neuron spike activities from calcium fluorescence signals.Here, we propose detailed implementation of the fast-oopsi algorithm in pythonprogramming language. Some corrections are also made to the original fast-oopsipaper.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Proceedings of the 7th European Conference on Python in Science\n",
      "  (EuroSciPy 2014)\n",
      "Auteur: Pierre de Buyl\n",
      "Date: 2014-12-22\n",
      "URL: http://arxiv.org/abs/1412.7030v1\n",
      "Texte: These are the proceedings of the 7th European Conference on Python inScience, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).\n",
      "Co-auteurs: Nelle Varoquaux\n",
      "Source: arxiv\n",
      "Titre: PythonFOAM: In-situ data analyses with OpenFOAM and Python\n",
      "Auteur: Romit Maulik\n",
      "Date: 2021-03-17\n",
      "URL: http://arxiv.org/abs/2103.09389v2\n",
      "Texte: We outline the development of a general-purpose Python-based data analysistool for OpenFOAM. Our implementation relies on the construction of OpenFOAMapplications that have bindings to data analysis libraries in Python. Doubleprecision data in OpenFOAM is cast to a NumPy array using the NumPy C-API andPython modules may then be used for arbitrary data analysis and manipulation onflow-field information. We highlight how the proposed wrapper may be used foran in-situ online singular value decomposition (SVD) implemented in Python andaccessed from the OpenFOAM solver PimpleFOAM. Here, `in-situ' refers to aprogramming paradigm that allows for a concurrent computation of the dataanalysis on the same computational resources utilized for the partialdifferential equation solver. In addition, to demonstrate data-parallelanalyses, we deploy a distributed SVD, which collects snapshot data across theranks of a distributed simulation to compute the global left singular vectors.Crucially, both OpenFOAM and Python share the same message passing interface(MPI) communicator for this deployment which allows Python objects andfunctions to exchange NumPy arrays across ranks. Subsequently, we providescaling assessments of this distributed SVD on multiple nodes of IntelBroadwell and KNL architectures for canonical test cases such as the large eddysimulations of a backward facing step and a channel flow at friction Reynoldsnumber of 395. Finally, we demonstrate the deployment of a deep neural networkfor compressing the flow-field information using an autoencoder to demonstratean ability to use state-of-the-art machine learning tools in the Pythonecosystem.\n",
      "Co-auteurs: Dimitrios Fytanidis, Bethany Lusch, Venkatram Vishwanath, Saumil Patel\n",
      "Source: arxiv\n",
      "Titre: Python Crypto Misuses in the Wild\n",
      "Auteur: Anna-Katharina Wickert\n",
      "Date: 2021-09-02\n",
      "URL: http://dx.doi.org/10.1145/3475716.3484195\n",
      "Texte: Background: Previous studies have shown that up to 99.59 % of the Java appsusing crypto APIs misuse the API at least once. However, these studies havebeen conducted on Java and C, while empirical studies for other languages aremissing. For example, a controlled user study with crypto tasks in Python hasshown that 68.5 % of the professional developers write a secure solution for acrypto task. Aims: To understand if this observation holds for real-world code,we conducted a study of crypto misuses in Python. Method: We developed a staticanalysis tool that covers common misuses of 5 different Python crypto APIs.With this analysis, we analyzed 895 popular Python projects from GitHub and 51MicroPython projects for embedded devices. Further, we compared our resultswith the findings of previous studies. Results: Our analysis reveals that 52.26% of the Python projects have at least one misuse. Further, some Python cryptolibraries API design helps developers from misusing crypto functions, whichwere much more common in studies conducted with Java and C code. Conclusion: Weconclude that we can see a positive impact of the good API design on cryptomisuses for Python applications. Further, our analysis of MicroPython projectsreveals the importance of hybrid analyses.\n",
      "Co-auteurs: Lars Baumgärtner, Florian Breitfelder, Mira Mezini\n",
      "Source: arxiv\n",
      "Titre: An array-oriented Python interface for FastJet\n",
      "Auteur: Aryan Roy\n",
      "Date: 2022-02-08\n",
      "URL: http://dx.doi.org/10.1088/1742-6596/2438/1/012011\n",
      "Texte: Analysis on HEP data is an iterative process in which the results of one stepoften inform the next. In an exploratory analysis, it is common to perform onecomputation on a collection of events, then view the results (often withhistograms) to decide what to try next. Awkward Array is a Scikit-HEP Pythonpackage that enables data analysis with array-at-a-time operations to implementcuts as slices, combinatorics as composable functions, etc. However, most C++HEP libraries, such as FastJet, have an imperative, one-particle-at-a-timeinterface, which would be inefficient in Python and goes against the grain ofthe array-at-a-time logic of scientific Python. Therefore, we developedfastjet, a pip-installable Python package that provides FastJet C++ binaries,the classic (particle-at-a-time) Python interface, and the new array-orientedinterface for use with Awkward Array.  The new interface streamlines interoperability with scientific Pythonsoftware beyond HEP, such as machine learning. In one case, adopting thislibrary along with other array-oriented tools accelerated HEP analysis code bya factor of 20. It was designed to be easily integrated with libraries in theScikit-HEP ecosystem, including Uproot (file I/O), hist (histogramming), Vector(Lorentz vectors), and Coffea (high-level glue). We discuss the design of thefastjet Python library, integrating the classic interface with the arrayoriented interface and with the Vector library for Lorentz vector operations.The new interface was developed as open source.\n",
      "Co-auteurs: Jim Pivarski, Chad Wells Freer\n",
      "Source: arxiv\n",
      "Titre: Deep Learning: From Basics to Building Deep Neural Networks with Python\n",
      "Auteur: Milad Vazan\n",
      "Date: 2022-04-22\n",
      "URL: http://arxiv.org/abs/2205.01069v1\n",
      "Texte: This book is intended for beginners who have no familiarity with deeplearning. Our only expectation from readers is that they already have the basicprogramming skills in Python.\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: The Awkward World of Python and C++\n",
      "Auteur: Manasvi Goyal\n",
      "Date: 2023-03-03\n",
      "URL: http://arxiv.org/abs/2303.02205v1\n",
      "Texte: There are undeniable benefits of binding Python and C++ to take advantage ofthe best features of both languages. This is especially relevant to the HEP andother scientific communities that have invested heavily in the C++ frameworksand are rapidly moving their data analyses to Python. Version 2 of AwkwardArray, a Scikit-HEP Python library, introduces a set of header-only C++libraries that do not depend on any application binary interface. Users candirectly include these libraries in their compilation rather than linkingagainst platform-specific libraries. This new development makes the integrationof Awkward Arrays into other projects easier and more portable as theimplementation is easily separable from the rest of the Awkward Array codebase.The code is minimal, it does not include all of the code needed to use AwkwardArrays in Python, nor does it include references to Python or pybind11. The C++users can use it to make arrays and then copy them to Python without anyspecialized data types - only raw buffers, strings, and integers. This C++ codealso simplifies the process of just-in-time (JIT) compilation in ROOT. Thisimplementation approach solves some of the drawbacks, like packaging projectswhere native dependencies can be challenging. In this paper, we demonstrate thetechnique to integrate C++ and Python by using a header-only approach. We alsodescribe the implementation of a new LayoutBuilder and a GrowableBuffer.Furthermore, examples of wrapping the C++ data into Awkward Arrays and exposingAwkward Arrays to C++ without copying them are discussed.\n",
      "Co-auteurs: Ianna Osborne, Jim Pivarski\n",
      "Source: arxiv\n",
      "Titre: SlipCover: Near Zero-Overhead Code Coverage for Python\n",
      "Auteur: Juan Altmayer Pizzorno\n",
      "Date: 2023-05-04\n",
      "URL: http://dx.doi.org/10.1145/3597926.3598128\n",
      "Texte: Coverage analysis is widely used but can suffer from high overhead. Thisoverhead is especially acute in the context of Python, which is alreadynotoriously slow (a recent study observes a roughly 30x slowdown vs. nativecode). We find that the state-of-the-art coverage tool for Python,coverage$.$py, introduces a median overhead of 180% with the standard Pythoninterpreter. Slowdowns are even more extreme when using PyPy, a JIT-compiledPython implementation, with coverage$.$py imposing a median overhead of 1,300%.This performance degradation reduces the utility of coverage analysis in mostuse cases, including testing and fuzzing, and precludes its use in deployment.This paper presents SlipCover, a novel, near-zero overhead coverage analyzerfor Python. SlipCover works without modifications to either the Pythoninterpreter or PyPy. It first processes a program's AST to accurately identifyall branches and lines. SlipCover then dynamically rewrites Python bytecodes toadd lightweight instrumentation to each identified branch and line. At runtime, SlipCover periodically de-instruments already-covered lines and branches.The result is extremely low overheads -- a median of just 5% -- makingSlipCover suitable for use in deployment. We show its efficiency can translateto significant increases in the speed of coverage-based clients. As a proof ofconcept, we integrate SlipCover into TPBT, a targeted property-based testingsystem, and observe a 22x speedup.\n",
      "Co-auteurs: Emery D Berger\n",
      "Source: arxiv\n",
      "Titre: Cosmic Microwave Background Anisotropy Measurement From Python V\n",
      "Auteur: K. Coble\n",
      "Date: 2001-12-21\n",
      "URL: http://dx.doi.org/10.1086/345714\n",
      "Texte: We analyze observations of the microwave sky made with the Python experimentin its fifth year of operation at the Amundsen-Scott South Pole Station inAntarctica. After modeling the noise and constructing a map, we extract thecosmic signal from the data. We simultaneously estimate the angular powerspectrum in eight bands ranging from large (l ~ 40) to small (l ~ 260) angularscales, with power detected in the first six bands. There is a significant risein the power spectrum from large to smaller (l ~ 200) scales, consistent withthat expected from acoustic oscillations in the early Universe. We compare thisPython V map to a map made from data taken in the third year of Python. PythonIII observations were made at a frequency of 90 GHz and covered a subset of theregion of the sky covered by Python V observations, which were made at 40 GHz.Good agreement is obtained both visually (with a filtered version of the map)and via a likelihood ratio test.\n",
      "Co-auteurs: S. Dodelson, M. Dragovan, K. Ganga, L. Knox, J. Kovac, B. Ratra, T. Souradeep\n",
      "Source: arxiv\n",
      "Titre: Solve the Master Equation by Python-An Introduction to the Python\n",
      "  Computing Environment\n",
      "Auteur: Wei Fan\n",
      "Date: 2011-03-02\n",
      "URL: http://arxiv.org/abs/1103.0325v4\n",
      "Texte: A brief introduction to the Python computing environment is given. By solvingthe master equation encountered in quantum transport, we give an example of howto solve the ODE problems in Python. The ODE solvers used are the ZVODE routinein Scipy and the bsimp solver in GSL. For the former, the equation can be inits complex-valued form, while for the latter, it has to be rewritten to areal-valued form. The focus is on the detailed workflow of the implementationprocess, rather than on the syntax of the python language, with the hope tohelp readers simulate their own models in Python.\n",
      "Co-auteurs: Yan Xu, Bing Chen, Qianqian Ye\n",
      "Source: arxiv\n",
      "Titre: FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC\n",
      "  libraries\n",
      "Auteur: Ashwin Vishnu Mohanan\n",
      "Date: 2018-07-03\n",
      "URL: http://dx.doi.org/10.5334/jors.238\n",
      "Texte: The Python package fluidfft provides a common Python API for performing FastFourier Transforms (FFT) in sequential, in parallel and on GPU with differentFFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFTframework which allows Python users to easily and efficiently perform FFT andthe associated tasks, such as as computing linear operators and energy spectra.We describe the architecture of the package composed of C++ and Cython FFTclasses, Python \"operator\" classes and Pythran functions. The package suppliesutilities to easily test itself and benchmark the different FFT solutions for aparticular case and on a particular machine. We present a performance scalinganalysis on three different computing clusters and a microbenchmark showingthat fluidfft is an interesting solution to write efficient Python applicationsusing FFT.\n",
      "Co-auteurs: Cyrille Bonamy, Pierre Augier\n",
      "Source: arxiv\n",
      "Titre: Speeding simulation analysis up with yt and Intel Distribution for\n",
      "  Python\n",
      "Auteur: Salvatore Cielo\n",
      "Date: 2019-10-17\n",
      "URL: http://arxiv.org/abs/1910.07855v1\n",
      "Texte: As modern scientific simulations grow ever more in size and complexity, eventheir analysis and post-processing becomes increasingly demanding, calling forthe use of HPC resources and methods. yt is a parallel, open sourcepost-processing python package for numerical simulations in astrophysics, madepopular by its cross-format compatibility, its active community of developersand its integration with several other professional Python instruments. TheIntel Distribution for Python enhances yt's performance and parallelscalability, through the optimization of lower-level libraries Numpy and Scipy,which make use of the optimized Intel Math Kernel Library (Intel-MKL) and theIntel MPI library for distributed computing. The library package yt is used forseveral analysis tasks, including integration of derived quantities, volumetricrendering, 2D phase plots, cosmological halo analysis and production ofsynthetic X-ray observation. In this paper, we provide a brief tutorial for theinstallation of yt and the Intel Distribution for Python, and the execution ofeach analysis task. Compared to the Anaconda python distribution, using theprovided solution one can achieve net speedups up to 4.6x on Intel XeonScalable processors (codename Skylake).\n",
      "Co-auteurs: Luigi Iapichino, Fabio Baruffa\n",
      "Source: arxiv\n",
      "Titre: Scalene: Scripting-Language Aware Profiling for Python\n",
      "Auteur: Emery D. Berger\n",
      "Date: 2020-06-06\n",
      "URL: http://arxiv.org/abs/2006.03879v2\n",
      "Texte: Existing profilers for scripting languages (a.k.a. \"glue\" languages) likePython suffer from numerous problems that drastically limit their usefulness.They impose order-of-magnitude overheads, report information at too coarse agranularity, or fail in the face of threads. Worse, pastprofilers---essentially variants of their counterparts for C---are oblivious tothe fact that optimizing code in scripting languages requires information aboutcode spanning the divide between the scripting language and libraries writtenin compiled languages.  This paper introduces scripting-language aware profiling, and presentsScalene, an implementation of scripting-language aware profiling for Python.Scalene employs a combination of sampling, inference, and disassembly ofbyte-codes to efficiently and precisely attribute execution time and memoryusage to either Python, which developers can optimize, or library code, whichthey cannot. It includes a novel sampling memory allocator that reportsline-level memory consumption and trends with low overhead, helping developersreduce footprints and identify leaks. Finally, it introduces a new metric, copyvolume, to help developers root out insidious copying costs across thePython/library boundary, which can drastically degrade performance. Scaleneworks for single or multi-threaded Python code, is precise, reporting detailedinformation at the line granularity, while imposing modest overheads(26%--53%).\n",
      "Co-auteurs: inexistant\n",
      "Source: arxiv\n",
      "Titre: Extending Python for Quantum-Classical Computing via Quantum\n",
      "  Just-in-Time Compilation\n",
      "Auteur: Thien Nguyen\n",
      "Date: 2021-05-10\n",
      "URL: http://arxiv.org/abs/2105.04671v1\n",
      "Texte: Python is a popular programming language known for its flexibility,usability, readability, and focus on developer productivity. The quantumsoftware community has adopted Python on a number of large-scale efforts due tothese characteristics, as well as the remote nature of near-term quantumprocessors. The use of Python has enabled quick prototyping for quantum codethat directly benefits pertinent research and development efforts in quantumscientific computing. However, this rapid prototyping ability comes at the costof future performant integration for tightly-coupled CPU-QPU architectures withfast-feedback. Here we present a language extension to Python that enablesheterogeneous quantum-classical computing via a robust C++ infrastructure forquantum just-in-time (QJIT) compilation. Our work builds off the QCOR C++language extension and compiler infrastructure to enable a single-source,quantum hardware-agnostic approach to quantum-classical computing that retainsthe performance required for tightly coupled CPU-QPU compute models. We detailthis Pythonic extension, its programming model and underlying softwarearchitecture, and provide a robust set of examples to demonstrate the utilityof our approach.\n",
      "Co-auteurs: Alexander J. McCaskey\n",
      "Source: arxiv\n",
      "Titre: An Empirical Study of Automated Unit Test Generation for Python\n",
      "Auteur: Stephan Lukasczyk\n",
      "Date: 2021-11-09\n",
      "URL: http://arxiv.org/abs/2111.05003v2\n",
      "Texte: Various mature automated test generation tools exist for statically typedprogramming languages such as Java. Automatically generating unit tests fordynamically typed programming languages such as Python, however, issubstantially more difficult due to the dynamic nature of these languages aswell as the lack of type information. Our Pynguin framework provides automatedunit test generation for Python. In this paper, we extend our previous work onPynguin to support more aspects of the Python language, and by studying alarger variety of well-established state of the art test-generation algorithms,namely DynaMOSA, MIO, and MOSA. Furthermore, we improved our Pynguin tool togenerate regression assertions, whose quality we also evaluate. Our experimentsconfirm that evolutionary algorithms can outperform random test generation alsoin the context of Python, and similar to the Java world, DynaMOSA yields thehighest coverage results. However, our results also demonstrate that there arestill fundamental remaining issues, such as inferring type information for codewithout this information, currently limiting the effectiveness of testgeneration for Python.\n",
      "Co-auteurs: Florian Kroiß, Gordon Fraser\n",
      "Source: arxiv\n",
      "Titre: An Exploratory Study on the Predominant Programming Paradigms in Python\n",
      "  Code\n",
      "Auteur: Robert Dyer\n",
      "Date: 2022-09-05\n",
      "URL: http://dx.doi.org/10.1145/3540250.3549158\n",
      "Texte: Python is a multi-paradigm programming language that fully supportsobject-oriented (OO) programming. The language allows writing code in anon-procedural imperative manner, using procedures, using classes, or in afunctional style. To date, no one has studied what paradigm(s), if any, arepredominant in Python code and projects. In this work, we first define atechnique to classify Python files into predominant paradigm(s). We thenautomate our approach and evaluate it against human judgements, showing over80% agreement. We then analyze over 100k open-source Python projects,automatically classifying each source file and investigating the paradigmdistributions. The results indicate Python developers tend to heavily favor OOfeatures. We also observed a positive correlation between OO and proceduralparadigms and the size of the project. And despite few files or projects beingpredominantly functional, we still found many functional feature uses.\n",
      "Co-auteurs: Jigyasa Chauhan\n",
      "Source: arxiv\n",
      "Titre: A Data Set of Generalizable Python Code Change Patterns\n",
      "Auteur: Akalanka Galappaththi\n",
      "Date: 2023-04-11\n",
      "URL: http://arxiv.org/abs/2304.04983v1\n",
      "Texte: Mining repetitive code changes from version control history is a common wayof discovering unknown change patterns. Such change patterns can be used incode recommender systems or automated program repair techniques. While thereare such tools and datasets exist for Java, there is little work on finding andrecommending such changes in Python. In this paper, we present a data set ofmanually vetted generalizable Python repetitive code change patterns. We createa coding guideline to identify generalizable change patterns that can be usedin automated tooling. We leverage the mined change patterns from recent workthat mines repetitive changes in Python projects and use our coding guidelineto manually review the patterns. For each change, we also record a descriptionof the change and why it is applied along with other characteristics such asthe number of projects it occurs in. This review process allows us to identifyand share 72 Python change patterns that can be used to build and advancePython developer support tools.\n",
      "Co-auteurs: Sarah Nadi\n",
      "Source: arxiv\n",
      "Titre: Scalable Demand-Driven Call Graph Generation for Python\n",
      "Auteur: Yixuan Yan\n",
      "Date: 2023-05-10\n",
      "URL: http://arxiv.org/abs/2305.05949v1\n",
      "Texte: Call graph generation is the foundation of inter-procedural static analysis.PyCG is the state-of-the-art approach for generating call graphs for Pythonprograms. Unfortunately, PyCG does not scale to large programs when adapted towhole-program analysis where dependent libraries are also analyzed. Further,PyCG does not support demand-driven analysis where only the reachable functionsfrom given entry functions are analyzed. Moreover, PyCG is flow-insensitive anddoes not fully support Python's features, hindering its accuracy. To overcomethese drawbacks, we propose a scalable demand-driven approach for generatingcall graphs for Python programs, and implement it as a prototype tool Jarvis.Jarvis maintains an assignment graph (i.e., points-to relations between programidentifiers) for each function in a program to allow reuse and improvescalability. Given a set of entry functions as the demands, Jarvis generatesthe call graph on-the-fly, where flow-sensitive intra-procedural analysis andinter-procedural analysis are conducted in turn. Our evaluation on amicro-benchmark of 135 small Python programs and a macro-benchmark of 6real-world Python applications has demonstrated that Jarvis can significantlyimprove PyCG by at least 67% faster in time, 84% higher in precision, and atleast 10% higher in recall.\n",
      "Co-auteurs: Kaifeng Huang, Bihuan Chen, Zixin Tao, Xin Peng\n",
      "Source: arxiv\n",
      "Titre: Py-Tetrad and RPy-Tetrad: A New Python Interface with R Support for\n",
      "  Tetrad Causal Search\n",
      "Auteur: Joseph D. Ramsey\n",
      "Date: 2023-08-13\n",
      "URL: http://arxiv.org/abs/2308.07346v1\n",
      "Texte: We give novel Python and R interfaces for the (Java) Tetrad project forcausal modeling, search, and estimation. The Tetrad project is a mainstay inthe literature, having been under consistent development for over 30 years.Some of its algorithms are now classics, like PC and FCI; others are recentdevelopments. It is increasingly the case, however, that researchers need toaccess the underlying Java code from Python or R. Existing methods for doingthis are inadequate. We provide new, up-to-date methods using the JPypePython-Java interface and the Reticulate Python-R interface, directly solvingthese issues. With the addition of some simple tools and the provision ofworking examples for both Python and R, using JPype and Reticulate to interfacePython and R with Tetrad is straightforward and intuitive.\n",
      "Co-auteurs: Bryan Andrews\n",
      "Source: arxiv\n",
      "Titre: High performance Python for direct numerical simulations of turbulent\n",
      "  flows\n",
      "Auteur: Mikael Mortensen\n",
      "Date: 2016-02-11\n",
      "URL: http://dx.doi.org/10.1016/j.cpc.2016.02.005\n",
      "Texte: Direct Numerical Simulations (DNS) of the Navier Stokes equations is aninvaluable research tool in fluid dynamics. Still, there are few publiclyavailable research codes and, due to the heavy number crunching implied,available codes are usually written in low-level languages such as C/C++ orFortran. In this paper we describe a pure scientific Python pseudo-spectral DNScode that nearly matches the performance of C++ for thousands of processors andbillions of unknowns. We also describe a version optimized through Cython, thatis found to match the speed of C++. The solvers are written from scratch inPython, both the mesh, the MPI domain decomposition, and the temporalintegrators. The solvers have been verified and benchmarked on the Shaheensupercomputer at the KAUST supercomputing laboratory, and we are able to showvery good scaling up to several thousand cores.  A very important part of the implementation is the mesh decomposition (weimplement both slab and pencil decompositions) and 3D parallel Fast FourierTransforms (FFT). The mesh decomposition and FFT routines have been implementedin Python using serial FFT routines (either NumPy, pyFFTW or any other serialFFT module), NumPy array manipulations and with MPI communications handled byMPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFTin Python for a slab mesh decomposition using 4 lines of compact Python code,for which the parallel performance on Shaheen is found to be slightly betterthan similar routines provided through the FFTW library. For a pencil meshdecomposition 7 lines of code is required to execute a transform.\n",
      "Co-auteurs: Hans Petter Langtangen\n",
      "Source: arxiv\n",
      "Titre: PyArmadillo: a streamlined linear algebra library for Python\n",
      "Auteur: Jason Rumengan\n",
      "Date: 2021-04-22\n",
      "URL: http://dx.doi.org/10.21105/joss.03051\n",
      "Texte: PyArmadillo is a linear algebra library for the Python language, with the aimof closely mirroring the programming interface of the widely used Armadillo C++library, which in turn is deliberately similar to Matlab. PyArmadillo hencefacilitates algorithm prototyping with Matlab-like syntax directly in Python,and relatively straightforward conversion of PyArmadillo-based Python code intoperformant Armadillo-based C++ code. The converted code can be used forpurposes such as speeding up Python-based programs in conjunction withpybind11, or the integration of algorithms originally prototyped in Python intolarger C++ codebases. PyArmadillo provides objects for matrices and cubes, aswell as over 200 associated functions for manipulating data stored in theobjects. Integer, floating point and complex numbers are supported. Variousmatrix factorisations are provided through integration with LAPACK, or one ofits high performance drop-in replacements such as Intel MKL or OpenBLAS.PyArmadillo is open-source software, distributed under the Apache 2.0 license;it can be obtained at https://pyarma.sourceforge.io or via the Python PackageIndex in precompiled form.\n",
      "Co-auteurs: Terry Yue Zhuo, Conrad Sanderson\n",
      "Source: arxiv\n",
      "Titre: PyCG: Practical Call Graph Generation in Python\n",
      "Auteur: Vitalis Salis\n",
      "Date: 2021-02-28\n",
      "URL: http://arxiv.org/abs/2103.00587v1\n",
      "Texte: Call graphs play an important role in different contexts, such as profilingand vulnerability propagation analysis. Generating call graphs in an efficientmanner can be a challenging task when it comes to high-level languages that aremodular and incorporate dynamic features and higher-order functions.  Despite the language's popularity, there have been very few tools aiming togenerate call graphs for Python programs. Worse, these tools suffer fromseveral effectiveness issues that limit their practicality in realisticprograms. We propose a pragmatic, static approach for call graph generation inPython. We compute all assignment relations between program identifiers offunctions, variables, classes, and modules through an inter-proceduralanalysis. Based on these assignment relations, we produce the resulting callgraph by resolving all calls to potentially invoked functions. Notably, theunderlying analysis is designed to be efficient and scalable, handling severalPython features, such as modules, generators, function closures, and multipleinheritance.  We have evaluated our prototype implementation, which we call PyCG, using twobenchmarks: a micro-benchmark suite containing small Python programs and a setof macro-benchmarks with several popular real-world Python packages. Ourresults indicate that PyCG can efficiently handle thousands of lines of code inless than a second (0.38 seconds for 1k LoC on average). Further, itoutperforms the state-of-the-art for Python in both precision and recall: PyCGachieves high rates of precision ~99.2%, and adequate recall ~69.9%. Finally,we demonstrate how PyCG can aid dependency impact analysis by showcasing apotential enhancement to GitHub's \"security advisory\" notification serviceusing a real-world example.\n",
      "Co-auteurs: Thodoris Sotiropoulos, Panos Louridas, Diomidis Spinellis, Dimitris Mitropoulos\n",
      "Source: arxiv\n",
      "Titre: Python for Smarter Cities: Comparison of Python libraries for static and\n",
      "  interactive visualisations of large vector data\n",
      "Auteur: Gregor Herda\n",
      "Date: 2022-02-26\n",
      "URL: http://arxiv.org/abs/2202.13105v1\n",
      "Texte: Local governments, as part of 'smart city' initiatives and to promoteinteroperability, are increasingly incorporating open-source software intotheir data management, analysis, and visualisation workflows. Python, with itsconcise and natural syntax, presents a low barrier to entry for municipal staffwithout computer science backgrounds. However, with regard to geospatialvisualisations in particular, the range of available Python libraries hasdiversified to such an extent that identifying candidate libraries for specificuse cases is a challenging undertaking. This study therefore assessesprominent, actively-developed visualisation libraries in the Python ecosystemwith respect to their suitability for producing visualisations of large vectordatasets. A simple visualisation task common in urban development is used toproduce near-identical thematic maps across static and an interactive 'tracks'of comparison. All short-listed libraries were able to generate the sample mapproducts for both a small and larger dataset. Code complexity differed morestrongly for interactive visualisations. Formal and informal documentationchannels are highlighted to outline available resources for flattening learningcurves. CPU runtimes for the Python-based portion of the process chain differedstarkly for both tracks, pointing to avenues for further research. Theseresults demonstrate that the Python ecosystem offers local governments powerfultools, free of vendor lock-in and licensing fees, to produce performant andconsistently formatted visualisations for both internal and publicdistribution.\n",
      "Co-auteurs: Robert McNabb\n",
      "Source: arxiv\n",
      "Titre: An Empirical Study of Fault Localization in Python Programs\n",
      "Auteur: Mohammad Rezaalipour\n",
      "Date: 2023-05-31\n",
      "URL: http://arxiv.org/abs/2305.19834v2\n",
      "Texte: Despite its massive popularity as a programming language, especially in noveldomains like data science programs, there is comparatively little researchabout fault localization that targets Python. Even though it is plausible thatseveral findings about programming languages like C/C++ and Java -- the mostcommon choices for fault localization research -- carry over to otherlanguages, whether the dynamic nature of Python and how the language is used inpractice affect the capabilities of classic fault localization approachesremain open questions to investigate.  This paper is the first large-scale empirical study of fault localization onreal-world Python programs and faults. Using Zou et al.'s recent large-scaleempirical study of fault localization in Java as the basis of our study, weinvestigated the effectiveness (i.e., localization accuracy), efficiency (i.e.,runtime performance), and other features (e.g., different entity granularities)of seven well-known fault-localization techniques in four families(spectrum-based, mutation-based, predicate switching, and stack-trace based) on135 faults from 13 open-source Python projects from the BugsInPy curatedcollection.  The results replicate for Python several results known about Java, and shedlight on whether Python's peculiarities affect the capabilities of faultlocalization. The replication package that accompanies this paper includesdetailed data about our experiments, as well as the tool FauxPy that weimplemented to conduct the study.\n",
      "Co-auteurs: Carlo A. Furia\n",
      "Source: arxiv\n",
      "Titre: Does Python Smell Like Java? Tool Support for Design Defect Discovery in\n",
      "  Python\n",
      "Auteur: Nicole Vavrová\n",
      "Date: 2017-03-31\n",
      "URL: http://dx.doi.org/10.22152/programming-journal.org/2017/1/11\n",
      "Texte: The context of this work is specification, detection and ultimately removalof detectable harmful patterns in source code that are associated with defectsin design and implementation of software. In particular, we investigate fivecode smells and four antipatterns previously defined in papers and books. Ourinquiry is about detecting those in source code written in Python programminglanguage, which is substantially different from all prior research, most ofwhich concerns Java or C-like languages. Our approach was that of softwareengineers: we have processed existing research literature on the topic,extracted both the abstract definitions of nine design defects and theirconcrete implementation specifications, implemented them all in a tool we haveprogrammed and let it loose on a huge test set obtained from open source codefrom thousands of GitHub projects. When it comes to knowledge, we have foundthat more than twice as many methods in Python can be considered too long(statistically extremely longer than their neighbours within the same project)than in Java, but long parameter lists are seven times less likely to be foundin Python code than in Java code. We have also found that FunctionalDecomposition, the way it was defined for Java, is not found in the Python codeat all, and Spaghetti Code and God Classes are extremely rare there as well.The grounding and the confidence in these results comes from the fact that wehave performed our experiments on 32'058'823 lines of Python code, which is byfar the largest test set for a freely available Python parser. We have alsodesigned the experiment in such a way that it aligned with prior research ondesign defect detection in Java in order to ease the comparison if we treat ourown actions as a replication. Thus, the importance of the work is both in theunique open Python grammar of highest quality, tested on millions of lines ofcode, and in the design defect detection tool which works on something elsethan Java.\n",
      "Co-auteurs: Vadim Zaytsev\n",
      "Source: arxiv\n",
      "Titre: Python I, II, and III CMB Anisotropy Measurement Constraints on Open and\n",
      "  Flat-Lambda CDM Cosmogonies\n",
      "Auteur: Graca Rocha\n",
      "Date: 1999-05-11\n",
      "URL: http://dx.doi.org/10.1086/307886\n",
      "Texte: We use Python I, II, and III cosmic microwave background anisotropy data toconstrain cosmogonies. We account for the Python beamwidth and calibrationuncertainties. We consider open and spatially-flat-Lambda cold dark mattercosmogonies, with nonrelativistic-mass density parameter Omega_0 in the range0.1--1, baryonic-mass density parameter Omega_B in the range (0.005--0.029)h^{-2}, and age of the universe t_0 in the range (10--20) Gyr. Marginalizingover all parameters but Omega_0, the combined Python data favors an open(spatially-flat-Lambda) model with Omega_0 simeq 0.2 (0.1). At the 2 sigmaconfidence level model normalizations deduced from the combined Python data aremostly consistent with those drawn from the DMR, UCSB South Pole 1994, ARGO,MAX 4 and 5, White Dish, and SuZIE data sets.\n",
      "Co-auteurs: Radoslaw Stompor, Ken Ganga, Bharat Ratra, Stephen R. Platt, Naoshi Sugiyama, Krzysztof M. Gorski\n",
      "Source: arxiv\n",
      "Titre: PyNetMet: Python tools for efficient work with networks and metabolic\n",
      "  models\n",
      "Auteur: D. Gamermann\n",
      "Date: 2012-11-30\n",
      "URL: http://arxiv.org/abs/1211.7196v1\n",
      "Texte: Background: The study of genome-scale metabolic models and their underlyingnetworks is one of the most important fields in systems biology. The complexityof these models and their description makes the use of computational tools anessential element in their research. Therefore there is a strong need ofefficient and versatile computational tools for the research in this area.  Results: In this manuscript we present PyNetMet, a Python library of tools towork with networks and metabolic models. These are open-source free tools foruse in a Python platform, which adds considerably versatility to them whencompared with their desktop software similars. On the other hand these toolsallow one to work with different standards of metabolic models (OptGene andSBML) and the fact that they are programmed in Python opens the possibility ofefficient integration with any other already existing Python tool.  Conclusions: PyNetMet is, therefore, a collection of computational tools thatwill facilitate the research work with metabolic models and networks.\n",
      "Co-auteurs: A. Montagud, R. A. Jaime Infante, J. Triana, P. F. de Córdoba, J. F. Urchueguía\n",
      "Source: arxiv\n",
      "Titre: A Python-based Post-processing Toolset For Seismic Analyses\n",
      "Auteur: Steve Brasier\n",
      "Date: 2014-12-19\n",
      "URL: http://arxiv.org/abs/1412.6410v1\n",
      "Texte: This paper discusses the design and implementation of a Python-based toolsetto aid in assessing the response of the UK's Advanced Gas Reactor nuclear powerstations to earthquakes. The seismic analyses themselves are carried out with acommercial Finite Element solver, but understanding the raw model output thisproduces requires customised post-processing and visualisation tools. Extendingthe existing tools had become increasingly difficult and a decision was made todevelop a new, Python-based toolset. This comprises of a post-processingframework (aftershock) which includes an embedded Python interpreter, and aplotting package (afterplot) based on numpy and matplotlib. The new toolset hadto be significantly more flexible and easier to maintain than the existingcode-base, while allowing the majority of development to be carried out byengineers with little training in software development. The resultingarchitecture will be described with a focus on exploring how the design driverswere met and the successes and challenges arising from the choices made.\n",
      "Co-auteurs: Fred Pollard\n",
      "Source: arxiv\n",
      "Titre: Rabacus: A Python Package for Analytic Cosmological Radiative Transfer\n",
      "  Calculations\n",
      "Auteur: Gabriel Altay\n",
      "Date: 2015-02-10\n",
      "URL: http://dx.doi.org/10.1016/j.ascom.2015.01.004\n",
      "Texte: We describe Rabacus, a Python package for calculating the transfer ofhydrogen ionizing radiation in simplified geometries relevant to astronomy andcosmology. We present example solutions for three specific cases: 1) asemi-infinite slab gas distribution in a homogeneous isotropic background, 2) aspherically symmetric gas distribution with a point source at the center, and3) a spherically symmetric gas distribution in a homogeneous isotropicbackground. All problems can accommodate arbitrary spectra and density profilesas input. The solutions include a treatment of both hydrogen and helium, aself-consistent calculation of equilibrium temperatures, and the transfer ofrecombination radiation. The core routines are written in Fortran 90 and thenwrapped in Python leading to execution speeds thousands of times faster thanequivalent routines written in pure Python. In addition, all variables haveassociated units for ease of analysis. The software is part of the PythonPackage Index and the source code is available on Bitbucket athttps://bitbucket.org/galtay/rabacus . In addition, installation instructionsand a detailed users guide are available at http://pythonhosted.org//rabacus .\n",
      "Co-auteurs: John Wise\n",
      "Source: arxiv\n",
      "Titre: Weighted graph algorithms with Python\n",
      "Auteur: A. Kapanowski\n",
      "Date: 2015-04-29\n",
      "URL: http://arxiv.org/abs/1504.07828v1\n",
      "Texte: Python implementation of selected weighted graph algorithms is presented. Theminimal graph interface is defined together with several classes implementingthis interface. Graph nodes can be any hashable Python objects. Directed edgesare instances of the Edge class. Graphs are instances of the Graph class. It isbased on the adjacency-list representation, but with fast lookup of nodes andneighbors (dict-of-dict structure). Other implementations of this class arealso possible.  In this work, many algorithms are implemented using a unified approach. Thereare separate classes and modules devoted to different algorithms. Threealgorithms for finding a minimum spanning tree are implemented: the Boruvka'salgorithm, the Prim's algorithm (three implementations), and the Kruskal'salgorithm. Three algorithms for solving the single-source shortest path problemare implemented: the dag shortest path algorithm, the Bellman-Ford algorithm,and the Dijkstra's algorithm (two implementations). Two algorithms for solvingall-pairs shortest path problem are implemented: the Floyd-Warshall algorithmand the Johnson's algorithm.  All algorithms were tested by means of the unittest module, the Python unittesting framework. Additional computer experiments were done in order tocompare real and theoretical computational complexity. The source code isavailable from the public GitHub repository.\n",
      "Co-auteurs: Ł. Gałuszka\n",
      "Source: reddit\n",
      "Titre: i use chatgpt to learn python\n",
      "Auteur: Clinnkk_\n",
      "Date: 2023-06-01\n",
      "URL: https://www.reddit.com/r/ChatGPT/comments/13xcy1j/i_use_chatgpt_to_learn_python/\n",
      "Texte: i had the idea to ask chatgpt to set up a study plan for me to learn python, within 6 months. It set up a daily learning plan, asks me questions, tells me whats wrong with my code, gives me resources to learn and also clarifies any doubts i have, its like the best personal tuitor u could ask for. You can ask it to design a study plan according to ur uni classes and syllabus and it will do so. Its basically everything i can ask for.\n",
      "Nombre de commentaires: 646.0\n",
      "Source: reddit\n",
      "Titre: Practical uses for Python for an average user ?\n",
      "Auteur: NomadJago\n",
      "Date: 2023-02-07\n",
      "URL: https://www.reddit.com/r/learnpython/comments/10w01cs/practical_uses_for_python_for_an_average_user/\n",
      "Texte: I am struggling to find a reason to continue learning Python, as I am not looking to code for a career. Are there any practical uses for learning Python for everyday use? Yes I know about the book/website for 'Automate the Boring Stuff', but even that is not all that practical for me. One project I did find very practical was using Python to code a command line terminal based interface to chatGPT to avoid their web-based site (this came in handy yesterday when their website was overloaded, too busy, and I could not do a chatGPT session--- but I ran my console version using Python and was able to connect and do a session with chatGPT (that did not use the overloaded web port). So I am wondering about practical uses like that.\n",
      "Nombre de commentaires: 135.0\n",
      "Source: reddit\n",
      "Titre: I want to start to learn Python, I am completely new to programming. Should I start with the book \"Automate the Boring Stuff with Python\" or with the official tutorial on Python website? Also along this should I use \"freecodecamp\" or \"codecademy\" or do you have some other recommendation?\n",
      "Auteur: AlternativeThink98\n",
      "Date: 2022-02-26\n",
      "URL: https://www.reddit.com/r/learnprogramming/comments/t22sil/i_want_to_start_to_learn_python_i_am_completely/\n",
      "Texte: Hi, I am new to programming. I want to learn programming for the career opportunities and because I started to get interested in it. I have a lot of free time and I can dedicate like 6 hours a day to learn. I read the \"New? READ ME FIRST\" and I see that many recommend the \"Automate the Boring Stuff with Python\". I also see that someone recommends to start with Python's official tutorial on their website but I hear that the tutorial there is for someone who already knows some programming. What do you recommend between the two?Also along side that should I use \"freecodecamp\"? I heard that some learned to code only using that and also they give certification and have a curriculum to follow so it would be easier. Do you recommend this or do you have other preferences like \"codecademy\"?Any additional advice or recommendation would be welcome. Thanks!\n",
      "Nombre de commentaires: 53.0\n",
      "Source: reddit\n",
      "Titre: Recommendations for most effective way to learn Python from scratch?\n",
      "Auteur: HeroOfIvalice\n",
      "Date: 2018-03-11\n",
      "URL: https://www.reddit.com/r/learnprogramming/comments/83oes2/recommendations_for_most_effective_way_to_learn/\n",
      "Texte: Title. I have a basic understanding of how programming works, just looking for some resources on how to get started on my own. Also if anyone has any advice in regards to most effective methods to study and learn in the least amount of time possible that would be very much appreciated. Thanks in advance\n",
      "Nombre de commentaires: 24.0\n",
      "Source: reddit\n",
      "Titre: I want to learn Python but have no idea where to start.\n",
      "Auteur: Kimy_tel\n",
      "Date: 2023-05-26\n",
      "URL: https://www.reddit.com/r/learnpython/comments/13s7q5y/i_want_to_learn_python_but_have_no_idea_where_to/\n",
      "Texte: Just like i Said in the title, I want to learn coding (python), but I have absolutely no idea where to start. To anyone who learned or is learning python, how’d you learn it? Did you follow a course on YouTube? Or maybe a (free) program on a website? Or even from books? I want to know if I should just start learning it on my own or if you know of any resources online. I did. find courses on YouTube, but only singular videos with no continuation, and I’d prefer something, anything, that will ‘walk” me through the whole process and that’ll help me to gradually learn the language I want to learn. (I do have some rudimentary knowledge about python since I’ve followed some tutorials but nothing more than that. I also have a hard time coming up with projects I can try to make so if you could, some suggestions would be great)\n",
      "Nombre de commentaires: 89.0\n",
      "Source: reddit\n",
      "Titre: My finished ball python embroidery!\n",
      "Auteur: Florally\n",
      "Date: 2023-10-03\n",
      "URL: https://i.redd.it/drhkme0020sb1.jpg\n",
      "Texte: I finished this guy a while ago but I just remembered to share him here! I used a brick stitch for his scales. It was fun to create a texture that wasn’t fur! All stitched with DMC embroidery thread and displayed in an ACMS Needlework shop hoop frame.\n",
      "Nombre de commentaires: 221.0\n",
      "Source: reddit\n",
      "Titre: Learn Python with the NBA Giveaway!\n",
      "Auteur: NukishPhilosophy\n",
      "Date: 2022-12-08\n",
      "URL: https://www.reddit.com/r/nba/comments/zg2i87/learn_python_with_the_nba_giveaway/\n",
      "Texte: Hi everyone,I recently came out with a course on learning Python with NBA data for complete beginners. (some of you may know me from /r/fantasyfootball)[Link to the course here](https://www.fantasydatapros.com/basketball)This is a giveaway I'm doing for lifetime access. **Just upvote and comment anything below to enter**. For those who don't know, Python is a beginner friendly programming language that's very popular for data analysis. As a first programming language, it's a perfect fit for a beginner who wants to learn a programming language and is obsessed with basketball.The overall goal of the course is to introduce coding to you through a fun and engaging subject matter you probably enjoy if you're on this sub - basketball. A lot of people have reported back to me that my courses are the thing that finally got programming to \"click\" for them after countless udemy courses and e-books. I dont think thats because I'm the best coding educator out there. There's some great out ones there, prob better than me, who I've learned a ton from and owe a lot to like Brad Traversy, Corey Schafer, and Sentdex. I actually think the reason is because the best and most engaging way to learn to code is through subject matters that interest you. For example, a lot of beginner data science courses start you out by predicting housing prices.  That's fine, but wouldn't it be more interesting and engaging to introduce you to predictive analysis by teaching you to make a model to predict the NBA MVP this season? With this in mind, each section of the course has some sort of basketball/NBA focus, all along the way introducing you to more and more complex programming/data science topics. The course walks you through the set up of Python, all the way to writing machine learning models to predict points scored for the season for certain players, predict who will be MVP, and rank players into tiers for fantasy basketball. It comes with 10 sections of material, 8 hours of video, and access to a Slack channel where you can personally ask me questions when you get stuck (I'm on Slack all day so I usually respond pretty quickly).Anyway, the mods ok'd it, so I figured id do a giveaway - **just upvote and comment anything below, and I'll randomly select (with a python script, of course) 10 people to get free lifetime access to the course after the Nuggets game tonight.** (Will select more if a lot of people enter)Thanks for reading. You guys are awesomeAnd good luck!edit:Some ppl asked about cost. It’s $55, but you can use the code `NBA` for $15 off**Winners posted below. Congrats and thank you to everyone!! If you won will be reaching out tmrw.**/u/vlrBielzera/u/close2storm/u/claudioo2/u/g-fresh/u/AltruisticExternal19/u/3ToedGiraffe/u/waleoh/u/No_Pizza7855/u/anontss/u/StevePerry4L/u/xongz/u/Donton615/u/hightops16/u/bullet50000/u/Jaerba/u/booyakuhhsha/u/Far-Consequence9800/u/imaleftyyy/u/Deca-Dence-Fan/u/osherg\n",
      "Nombre de commentaires: 2562.0\n",
      "Source: reddit\n",
      "Titre: Learn Python with Fantasy Football Giveaway!\n",
      "Auteur: NukishPhilosophy\n",
      "Date: 2022-01-17\n",
      "URL: https://www.reddit.com/r/fantasyfootball/comments/s67clq/learn_python_with_fantasy_football_giveaway/\n",
      "Texte: Hi everyone,This is the second giveaway I'm doing for a course I teach on learning Python with Fantasy Football!**[Link to the course](https://www.fantasyfootballdatapros.com/)****Upvote and comment anything below to enter! Winners will be randomly chosen after the Rams-Cardinals game tonight** Below is what I wrote last year when I did this same giveaway with a brief description of what the course is about, why I made it, and what makes it different than your average programming course (the feedback last year was so amazing with close to 5000 entries that we're doing 10 winners this year):For those that don't know, Python is a beginner-friendly programming language that's really popular for data analysis. As a first programming language, it's a perfect fit for a beginner who wants to learn a programming language and is obsessed with fantasy football.The overall goal of the course is to introduce coding to you through a fun and engaging topic you all enjoy, fantasy football. A lot of people have reported back to me that this course was the thing that finally got programming to \"click\" for them after going through countless udemy courses and e-books. I don't think that's because I'm the best coding educator out there. There's some great educators out there, especially on YouTube (Brad Traversy, Cody Schafer, etc). I think it's because the best, fastest, and most enjoyable way to learn to code is to apply it to something you enjoy and can be useful to you right away. For example, most beginner machine learning with Python courses introduce you to predictive analysis by having you predict housing prices. That's fine, but wouldn't it be more interesting and engaging to get introduced to predictive analysis by predicting WR fantasy football performance?With this in mind, each section of my course has some sort of fantasy football focus, all along the way introducing you to more and more complex programming/data science topics. My course walks you through the set up of Python, all the way to writing machine learning models to rank players in to tiers for your draft. It comes with 16 sections of material, 14 hours of video, and access to a Slack channel where you can personally ask me questions when you get stuck.Anyway - you all have been super supportive of my content since my first ever post here, so I figure why not do a giveaway to mark the end of the season!Just upvote and comment anything below, and I'll randomly select (with a python script, of course :)) ten people to get free lifetime access to the course.Just as last year, I'll make the selection tonight and post the results at the bottom here. If you win, I'll also be sending you a PM on how to access the course!Also, some people will want to order before the giveaway is over. If you want to order it already that's cool, you'll get a full refund if you're randomly selected by the draw. You'll just have to let me know after what email you used at checkout.**Winners are posted below. Thank you to everyone who participated in the giveaway!!**/u/kidddo598/u/rgcl360 /u/vmack2280/u/Kopwnicus/u/Marauder32/u/retriverslovewater/u/njb98x/u/fiv5/u/MIkeyday14/u/Dolzilla\n",
      "Nombre de commentaires: 2668.0\n"
     ]
    }
   ],
   "source": [
    "import script_acquisition_donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15d5854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04ad861439f4b8482c6875856a8af83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='python', description='Mot-clé:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d774b7827bf4220a08649efe411be7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, continuous_update=False, description=\"Nombre d'articles:\", max=1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d5aa2359394b17b08dd9404da8bab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Exécuter', icon='check', style=ButtonStyle(), tooltip='Cliquez ici pour lancer la recherch…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche avec le mot-clé: python pour 100 articles\n",
      "Recherche avec le mot-clé:  pour 213 articles\n",
      "Recherche avec le mot-clé:  pour 415 articles\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Créer des widgets pour la configuration\n",
    "mot_cle_widget = widgets.Text(\n",
    "    value='python',\n",
    "    description='Mot-clé:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "nombre_articles_widget = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='Nombre d\\'articles:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "# Créer un bouton pour lancer la recherche\n",
    "bouton_executer = widgets.Button(\n",
    "    description='Exécuter',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Cliquez ici pour lancer la recherche',\n",
    "    icon='check' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "# Fonction pour gérer l'événement de clic sur le bouton\n",
    "def on_bouton_executer_clicked(b):\n",
    "    mot_cle = mot_cle_widget.value\n",
    "    nombre_articles = nombre_articles_widget.value\n",
    "    # Ici, vous pouvez ajouter le code pour lancer la recherche\n",
    "    # et afficher les résultats, par exemple :\n",
    "    print(f\"Recherche avec le mot-clé: {mot_cle} pour {nombre_articles} articles\")\n",
    "\n",
    "# Attacher la fonction au bouton\n",
    "bouton_executer.on_click(on_bouton_executer_clicked)\n",
    "\n",
    "# Afficher les widgets\n",
    "display(mot_cle_widget, nombre_articles_widget, bouton_executer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834d2e42",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m on_bouton_executer_clicked(\u001b[43mb\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8b62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_cle_widget = widgets.Text(\n",
    "    value='',  # valeur initiale vide\n",
    "    placeholder='Entrez votre mot-clé',\n",
    "    description='Recherche:',\n",
    "    disabled=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb05f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c25d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addd680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
